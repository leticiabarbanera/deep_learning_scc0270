{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "717dfe5c-7327-4ec1-96a3-7d6737ded619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "69ee8c0e-1b36-45d2-8738-32fe4cf2583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torchxrayvision as xrv\n",
    "import time\n",
    "from collections import Counter\n",
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e1ed872f-a384-42cd-b0e1-ded570387680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ieee8023/covid-chestxray-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "af04fc5c-dddf-41b8-bf03-7877c4bd86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xrv.datasets.COVID19_Dataset(imgpath=\"covid-chestxray-dataset/images/\",csvpath=\"covid-chestxray-dataset/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0a1797b8-7016-4fce-893b-755187bca2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspergillosis': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Aspiration': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Bacterial': {np.float32(0.0): 487, np.float32(1.0): 48},\n",
      " 'COVID-19': {np.float32(0.0): 193, np.float32(1.0): 342},\n",
      " 'Chlamydophila': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Fungal': {np.float32(0.0): 512, np.float32(1.0): 23},\n",
      " 'H1N1': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Herpes ': {np.float32(0.0): 532, np.float32(1.0): 3},\n",
      " 'Influenza': {np.float32(0.0): 531, np.float32(1.0): 4},\n",
      " 'Klebsiella': {np.float32(0.0): 526, np.float32(1.0): 9},\n",
      " 'Legionella': {np.float32(0.0): 526, np.float32(1.0): 9},\n",
      " 'Lipoid': {np.float32(0.0): 527, np.float32(1.0): 8},\n",
      " 'MERS-CoV': {np.float32(0.0): 527, np.float32(1.0): 8},\n",
      " 'MRSA': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Mycoplasma': {np.float32(0.0): 530, np.float32(1.0): 5},\n",
      " 'No Finding': {np.float32(0.0): 520, np.float32(1.0): 15},\n",
      " 'Nocardia': {np.float32(0.0): 531, np.float32(1.0): 4},\n",
      " 'Pneumocystis': {np.float32(0.0): 513, np.float32(1.0): 22},\n",
      " 'Pneumonia': {np.float32(0.0): 26, np.float32(1.0): 509},\n",
      " 'SARS': {np.float32(0.0): 519, np.float32(1.0): 16},\n",
      " 'Staphylococcus': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Streptococcus': {np.float32(0.0): 518, np.float32(1.0): 17},\n",
      " 'Tuberculosis': {np.float32(0.0): 524, np.float32(1.0): 11},\n",
      " 'Varicella': {np.float32(0.0): 530, np.float32(1.0): 5},\n",
      " 'Viral': {np.float32(0.0): 157, np.float32(1.0): 378}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COVID19_Dataset num_samples=535 views=['PA', 'AP'] data_aug=None"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "59441a60-b50c-4b9e-8745-3730864cb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ad8c2f1c-0b7f-4346-9429-31b9075e106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(data)):\n",
    "    pd.Series(dict(zip(data.pathologies,data[i][\"lab\"])))\n",
    "    labels.append(pd.Series(dict(zip(data.pathologies,data[i][\"lab\"]))))\n",
    "\n",
    "labels = pd.DataFrame(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "af69fab8-d002-434e-b1fd-60007ce0e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels['COVID-19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "95f433a0-dc61-4910-b0bd-2ef099fdc53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "text_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fe897313-be5d-4540-b570-b0cbf801b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "187b8bb1-660e-4616-a0b3-c1005903c66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XRV-DenseNet121-densenet121-res224-all"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2147d7-e63a-438e-8784-fde5218222c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723e382-b1da-4d09-a47f-a5294887ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "536c7ebd-33ad-4e0b-8f58-9111b0550157",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "943e4eef-e2b3-4bdd-95b3-69e752471f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_and_prepare_data(data, save_dir=\"covid_images_organized\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    image_paths = []\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        #obtem imagem (normalizada entre 0-1)\n",
    "        img = data[i][\"img\"]\n",
    "        img = np.squeeze(img)\n",
    "\n",
    "        #converte para uint8 e PIL\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        pil_img = Image.fromarray(img_uint8)\n",
    "\n",
    "        #obtem filename do DataFrame\n",
    "        filename = data.csv.iloc[i]['filename']\n",
    "        if not isinstance(filename, str):  #pula se for NaN ou inválido\n",
    "            continue\n",
    "\n",
    "        #caminho completo para salvar\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        pil_img.save(filepath)\n",
    "        image_paths.append(filepath)\n",
    "\n",
    "        # Texto clínico associado, string ou vazio\n",
    "        clinical_note = data.csv.iloc[i]['clinical_notes']\n",
    "        texts.append(clinical_note if isinstance(clinical_note, str) else \"\")\n",
    "\n",
    "        # Label binária para COVID-19\n",
    "        lab_series = pd.Series(dict(zip(data.pathologies, data[i][\"lab\"])))\n",
    "        labels.append(lab_series['COVID-19'])\n",
    "\n",
    "    return image_paths, texts, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "42bd1561-9c42-4f05-89cb-73b04790e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, texts, labels = save_images_and_prepare_data(data, save_dir=\"covid_images_organized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cde10ab0-aea2-45ed-864f-86e461a61bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando dataset multimodal, ou seja, que comparta as imagens e os textos\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, image_paths, texts, labels, tokenizer, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #imagem\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('L')  #abre imagem em greyscale\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Texto\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'image': image,\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "98f868fe-c5d0-4fda-9ca4-1b21b1558251",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultimodalTextImageDataset(\n",
    "    image_paths, texts, labels,\n",
    "    tokenizer=tokenizer,\n",
    "    image_transform=image_transforms['test'],\n",
    "    max_len=128\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=335, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "35f60800-0880-41c8-9434-14e28d0da2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "da579f59-5d66-499c-9cb3-c6e9dc9ecc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_interesse = img_model.pathologies.index(\"Pneumonia\")  #não é covid, mas é só para experimentação gera;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4fdc9604-3465-4f1c-a7aa-542c76cbdc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    #inputs para os dois modelos\n",
    "    ids = batch[\"input_ids\"].to(device)\n",
    "    mask = batch[\"attention_mask\"].to(device)\n",
    "    imgs = batch[\"image\"].to(device)\n",
    "    labels = batch[\"label\"].to(device)\n",
    "\n",
    "    #texto -> BlueBERT\n",
    "    with torch.no_grad():\n",
    "        output_text = text_model(input_ids=ids, attention_mask=mask)\n",
    "        probs_text = torch.softmax(output_text.logits, dim=1)\n",
    "        preds_text = torch.argmax(probs_text, dim=1)\n",
    "\n",
    "    #imagem -> DenseNet\n",
    "    with torch.no_grad():\n",
    "        output_img = img_model(imgs)\n",
    "        probs_img = torch.sigmoid(output_img[:, index_interesse])  # ex: pneumonia\n",
    "        preds_img = (probs_img > 0.5).long()\n",
    "\n",
    "    #comparar erros\n",
    "    erro_texto = preds_text != labels\n",
    "    erro_img = preds_img != labels\n",
    "    erros_comuns = erro_texto & erro_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "83515d75-f064-44ac-9a4c-146325bd96c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de erros no texto: 92\n",
      "Total de erros na imagem: 116\n",
      "Total de erros comuns: 19\n",
      "Índices dos exemplos com erros em ambos (texto e imagem): [ 69  70  71  72  73  98  99 113 118 119 135 136 137 138 145 164 176 178\n",
      " 197]\n"
     ]
    }
   ],
   "source": [
    "preds_text_np = preds_text.cpu().numpy()\n",
    "preds_img_np = preds_img.cpu().numpy()\n",
    "labels_np = labels.cpu().numpy()\n",
    "\n",
    "erro_texto = preds_text_np != labels_np\n",
    "erro_img = preds_img_np != labels_np\n",
    "erros_comuns = erro_texto & erro_img\n",
    "\n",
    "print(f\"Total de erros no texto: {erro_texto.sum()}\")\n",
    "print(f\"Total de erros na imagem: {erro_img.sum()}\")\n",
    "print(f\"Total de erros comuns: {erros_comuns.sum()}\")\n",
    "\n",
    "indices_erros_comuns = np.where(erros_comuns)[0]\n",
    "print(\"Índices dos exemplos com erros em ambos (texto e imagem):\", indices_erros_comuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbd338-c8ae-44d0-a706-8634f054df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pouco correlacionados! a intersecção é pequena!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecdec9d-270e-4537-bea9-8729aa68be35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6c717-211c-4c17-b257-d4007187cead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab0963-6853-4cc7-83ca-7f4cb4214601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
