{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-8ucXnAWjjBl",
    "outputId": "dd4b17e7-31d5-4214-bb21-04d1b30c3c66"
   },
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkZ-mtQ0PbJl",
    "outputId": "57e73ac9-7c31-42c3-d730-b6866ea07091"
   },
   "outputs": [],
   "source": [
    "#pip -q install torchxrayvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "SrL47MttOLS3",
    "outputId": "8b00f3a5-1943-470d-96e6-5ba3c55d2f36"
   },
   "outputs": [],
   "source": [
    "#%env CUDA_VISIBLE_DEVICES=2\n",
    "\n",
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import torchxrayvision as xrv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS9qUNIRPbXn"
   },
   "source": [
    "##Baixando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0DhmsSSPh9f",
    "outputId": "457d585f-2350-4672-c803-8f1684028610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'covid-chestxray-dataset' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ieee8023/covid-chestxray-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TyBtbzLiPh_k"
   },
   "outputs": [],
   "source": [
    "data = xrv.datasets.COVID19_Dataset(imgpath=\"covid-chestxray-dataset/images/\",csvpath=\"covid-chestxray-dataset/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dU6FpIG5PnFG",
    "outputId": "dc7463ba-6e69-41b4-8a6f-d103352a290f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aspergillosis': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Aspiration': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Bacterial': {np.float32(0.0): 487, np.float32(1.0): 48},\n",
      " 'COVID-19': {np.float32(0.0): 193, np.float32(1.0): 342},\n",
      " 'Chlamydophila': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Fungal': {np.float32(0.0): 512, np.float32(1.0): 23},\n",
      " 'H1N1': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Herpes ': {np.float32(0.0): 532, np.float32(1.0): 3},\n",
      " 'Influenza': {np.float32(0.0): 531, np.float32(1.0): 4},\n",
      " 'Klebsiella': {np.float32(0.0): 526, np.float32(1.0): 9},\n",
      " 'Legionella': {np.float32(0.0): 526, np.float32(1.0): 9},\n",
      " 'Lipoid': {np.float32(0.0): 527, np.float32(1.0): 8},\n",
      " 'MERS-CoV': {np.float32(0.0): 527, np.float32(1.0): 8},\n",
      " 'MRSA': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Mycoplasma': {np.float32(0.0): 530, np.float32(1.0): 5},\n",
      " 'No Finding': {np.float32(0.0): 520, np.float32(1.0): 15},\n",
      " 'Nocardia': {np.float32(0.0): 531, np.float32(1.0): 4},\n",
      " 'Pneumocystis': {np.float32(0.0): 513, np.float32(1.0): 22},\n",
      " 'Pneumonia': {np.float32(0.0): 26, np.float32(1.0): 509},\n",
      " 'SARS': {np.float32(0.0): 519, np.float32(1.0): 16},\n",
      " 'Staphylococcus': {np.float32(0.0): 534, np.float32(1.0): 1},\n",
      " 'Streptococcus': {np.float32(0.0): 518, np.float32(1.0): 17},\n",
      " 'Tuberculosis': {np.float32(0.0): 524, np.float32(1.0): 11},\n",
      " 'Varicella': {np.float32(0.0): 530, np.float32(1.0): 5},\n",
      " 'Viral': {np.float32(0.0): 157, np.float32(1.0): 378}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COVID19_Dataset num_samples=535 views=['PA', 'AP'] data_aug=None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0MhTzpwcPnHt"
   },
   "outputs": [],
   "source": [
    "df = data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RyL8m-V2PqaZ"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "imgs = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    pd.Series(dict(zip(data.pathologies,data[i][\"lab\"])))\n",
    "    labels.append(pd.Series(dict(zip(data.pathologies,data[i][\"lab\"]))))\n",
    "    imgs.append(data[i][\"img\"])\n",
    "\n",
    "labels = pd.DataFrame(labels)\n",
    "imgs = [i[0] for i in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egjiDeMAPqcd",
    "outputId": "ae494ab4-e387-48df-835f-b64a63087f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices where all records are zero: []\n"
     ]
    }
   ],
   "source": [
    "# prompt: encontrar casos onde todos os registros s√£o 0\n",
    "\n",
    "zeros = []\n",
    "for index, row in labels.iterrows():\n",
    "    if row.sum() == 0:\n",
    "        zeros.append(index)\n",
    "print(f\"Indices where all records are zero: {zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6W-DCtuzPuTn"
   },
   "outputs": [],
   "source": [
    "labels = labels['COVID-19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "5RgjBHhnPwFM",
    "outputId": "17fc29a5-d2c6-4155-ca7a-7d7b0f19ce0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COVID-19\n",
       "1.0    342\n",
       "0.0    193\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "LP6IWrUSRafi",
    "outputId": "2e6959ca-a8bb-4131-a338-59b3e13429ec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAGFCAYAAAAbyE8yAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs/Tuvblt21m/vXQcX2IDtctkuYyNxFAF8DBJCEgIyEr4SERkZAQiRERIQIEgREkLCgE2d7DJl8KFce79qS+ta+tXNmKv2tufmr1deXXr0zDmeMfqh9Xa4W+ut9/Hxp59++ulHH8qH8qF8KB/Kn8rypf+vO/ChfCgfyofyofx/Vz4YgQ/lQ/lQPpQ/xeWDEfhQPpQP5UP5U1w+GIEP5UP5UD6UP8XlgxH4UD6UD+VD+VNcPhiBD+VD+VA+lD/F5YMR+FA+lA/lQ/lTXD4YgQ/lQ/lQPpQ/xeUrn/XG73znOx99/PHHr9r47VO7Ou/bnrXXbuP/n8vS4rVo5PmnfYLm46U2flLbnn/p3qe2tx99bn976ptr7xsXHuuz72vn85SX6PjH+e3zzMdLtO71l+p4eu59/Wkd7+OPrfclHt7vp+df+rv3vtTn7edP6u/nKe8b/9PvP4lm+2yfebre/99Xz1e+8pWPvv71r7+eEfhX/+pfffSa5Tr5pS996aNPPvnko3/zb/7NR//lv/yXN///JEb8vOX/pVF5rbYotCeF9XT98yrso/N9ltFeqvPu3X59+ctffnft/lbXMd6VH/3oRx997Wtfe/O5v11X7t67/sMf/vANDxASPFFw4Nrd3+tV/j/1Uz/15nN/331/+Id/+Ob3e+7auI8xqR+/uU8/fpLAfRYl8PT/k6HqGK59c4Pm/r770PxpjnZezK9xPinSpeH2/SX+eFL0VXQ311/96lffzRt+uM//+T//56M/+IM/+OiP/uiP3nyW9qWF0vnyf5/dfuOZo8X1BX/2Pm1+/BNASfuzoLX9MdY1bkeHk4HSqPc88Ur7eDQrv7+Pv7b8jb/xNz76x//4H3/0akbgp3/6p19doarvGOPb3/72q9b//9qjeE0DVWVbAX1J6N6HCF+q/xTmEzpWKsBVKCdQhGo/dz/BYxAYgSv3/wmv/ynsu1alfAq7Su++7z5Cyxjol7pvTC0EnbHRbpW9/qygPSHOz0Jb9z/9r8/X1xrijmXb6PWnNms8a+RWYZjLNQpVrm33aN5xV/H5dt2c/5k/82fezMH9z/iewv/f//t/v/n83u/93hvjbF46hlXKnT/9wyt99n00fp8B6P2fvG33SdE/ycIajyda39/H+3/2z/7ZN+Puvb3/JSOGb/Fsf3+a3y3Xv1/4hV/46LOUz2wE2sGnBn/SM+sSPVnerfulej+La/WT7tl+rNDvb4sOto0yxn6/j2ZP/azQr8D+JMPROtdIrIDtuPf/otGlwaLbotArJ4DquudPIWwbNR4VQvVXAFYol5cYievD/X4IjIKnTBiXRWB3P0PwkxD80mfp+NJcX38oJQrKb0WUxlX0+xJibdvGWWW9AAE6Lo8sn9TzuMIY9Pnee0r/lD+6u37K/8DdD37wg49+//d//43y5/UtytfOlQIE3zXk+9uOpeh/jdtTe5++pVW9wpWJnWP1Lmov7958nwG474KMJx3xkn5cz2jl7yVQ8PT3qxiBJ2Xx1JG99pP+f6p7yyrq9ynCvfdJyX+Wdn+SQXrqy9MEr5u4jFtGfVL+Twr4fWhxXc1t+0lwXhobNI8JeQFP/b1CsVFyJwD6AB2uQiW47e9d403ofz2BCsYTTe7+UzyniE75QI8v8YI5elIaq/zQ2v1oXoPVOVxadN71v+EQ49z58HtDb9u3Rb2rtF4CE5QgBcpg6luNh3sYNchf34/ukP/Rvnxc3qF8q4xrAJ8M3M5PlbExXX8aelydgJ+rwD+e/tUoq7/93rlZMHi0uciJ8KTSOcTbNT6VAf144tk15O3bT9Klr+IJtCzDvc86PSmb/f3Jcn0Wa/akiF/6f63tE8pb4XlyyX8SsVdhrBJ/mugK61Pb65k8GYBFeFBIFc26veqkSK4UfUJ8q3i1fc+IAVMKFMspEwL2kmvbep/GsaXCtAU9hQ7qUq8SKQ0Yqf2tY2rfaxSM72ignRp/tC/dr29tq9+dvyc+0b572+bOaen+Ej0pR6i19IWqKa67h6LV1in8//W//tdH3/ve996gfzxX/qyCZeCv9N67R2hQv/2+3t/OeftasPCkm5701pXKXJVy576G4Uk33b3nGd0HX3eOdv3L3FxZENfSPl1hrBcwvAQWvzAj0MZemqDPooRfuvd99fTa02Qs2qyQ7MLbk2J/QqxPCKrj2nv9/6RcXmKi9ndR9xO9amgw2FPctn0s85SpiyYtvtWAlWYVateLcK40/g8R37VFhEV6pYt+NtTwkqfXe+t91LBClUvDRYVPC5wU4P1tUVI9EHFRK9qVvvdbefBJYJ94+smTQ/sa7yewoH8vhUbuHqiewrvPxbOrwG98dx/63vgO9f/2b//2m895XeUh9VPiXZg3P0/gq+N7Moq9X2GA3XdhGHPa9YRF7Iv4vzTIm6I1r086btu4fpwBqKFbo1x+w08bMqrRewo5ts8/aW3l1YzAIsy1sE+xy6eJe6lz77PyL3kDa90XmUEddZP3/k4iIj7FnN9n6BaZFQn6bdEtWj0pAiiraLB9eskQVeEtrZ9c5xWuMjPlT3grNOiLxg0T1fsgSOK5VaaN71aJqbNjXre84+v8lf5QeZGX/vT6InTzdYJcmnWtoUh5PQTz3DUGdQsJFXg8hX5a385paday3urWU8WsD8ZZ46j/EH/DP/fMhXgg//vcoidalF9XX2ypHCwQWaO8tPFtPso7F4YhbwsA8NON4T68RWXl+0nH1UMosLjCAN3H8zyT5TG/r44rrdaDXa+i97ePn7f8sT2BVYqrkP+kqP+JKGXwVUQs74ZHiiKLfl1bxOa+9xmeKvAyShFx73ethqH1F32v8ehi3zKf/9W9DPESs1RoKekiJ2GB+50yfDKoa6CPllXgba8Ch34MwRMiWx7YhdKO0++luz4/gRF9ap1+u7FDxovOPFNe2xAeZXT3UTSL/Fp2fsqr5qfGcD0jz5YHagT8DSk/oVLpvNryW8NgN3cX6vmt3/qtj37nd37nXQouo7q8tzz8ZOz0u2nFnZv3AcjrZ3nzZ37mZ978z/sAAu6Zpmg2dHRj+J3f+Z034yqfNmxpMbtG29wXoFy5ds4I7Zw+8V3Lk67Z0NHSoWHU8ujquv9nawJHzH/37/7dO6HGHD//8z//0V/5K3/lzQS9pPSLnJdxO3G9b0M5nZR1vbugeKULcHtt+1gm7CQuqm48uWihjL7529oliEXE237b2j71t9K0Ssu13rfhlw0P+Y1iN4YKib4/pYx6pvSv8i+yKsOXmavYn9x0tKQ8mnVTo9kF6o15l7+03dBC+0R5GEONj99bnzE3LIZulZ+lu+8NtZXXnwBVARHer4zVyJeeNfLG05j/KclTlve5EJB7noDTesHGtkq9hrHjWIPxpCDPOAlX3d9//s//+Xcpzzcv7XujAv63b+Tnfu7n3qRRGtfpsd/93d99Q7dd7GbQC1iqN3ghZ4gWwD4p64bKdh43gtB5wr/4fEFXy2f1Cv5EnoByBP3n//yfv0kHa6rX/f3X//pf/+gf/aN/9NHP/uzP/thzRZNnJP7CX/gL7/6vwiuz+F7F/tS3CpNrK0BV6ou0V9Gro4q96Kz31FB0sdBzva+T3tjt1udvbXXsayzWSK6yVFczPnZ8nhP/3hTPE7rOVelFCIsiq+jbz7sX2iKwRTI12r6LkrXXBTmK196AGoAa20Wi90z3NqwBredZuqOvkIn7hY6uT+7Xpxq68uNTCAptSm/P1fA0u6f8tAoRMm79xgJdX4z/FOIpSGmeLyn5GquntZk1su5bEFNDWbr3c3x34ZYbw/X1DIAFZcoRnRjzek5ocPNw4/upn/qpd17qfa7eegXCYhcCOxo05bhyWrp2XB3L7lNZXbX8VtqWBgs0dw4/b/ljGYGXEPMR4h/8g3/w0Te/+c2P/ut//a8f/ct/+S8/+k//6T999O///b//6O/8nb/zf9VRFPpS3LcWdJ9fpbUKqfW9hJZf+s1zXRxq3TehmzFTZNCxrfGhtCALYZJ6Cy9Z8/f1+4k2rWMRYJFGGcwzhG6NXV3uFW51MgTy9TsfDTUUMTfXvyh6aaroExq795SDNYgTXEZGWa/MhwEoOq6x6nzfuA4dms/WJZRUw9s1hRounlV5p0auXkeV/o6lpZ6Jce59Mny0e4rVeE853jExl+1DiTO4eGF5sfO/SmwR8Bq7J8/mCeRIvby+nPIXYdhYOVrXwzEn3a2sD7/3e7/3zsg1NGUcd+3o49mVTTzHO3lS1rsm03h/PaAFuP19QbH6ll6dhy88HLRI9jr8a7/2a29CQH/1r/7Vj/7Df/gPH/3n//yf36CJTYXq8zaWVPje5/L2We26p4y9z/e31lVCVkmqo7+5tzFHaKIbpNRb44YpIBYM152uNTZlsoYwSv+O/SWD08VQfS+CuNJ0vPajiKp0ouCqcNbt7j337AmJunbXcOcRPWWcrAJcQGDcJ8j3+wl1w11oVS9gDYB+rndkUbQpf09C2OcquOvSU/z+hjw3ZLk8vPPab7xdb7OL9trrnoUas1Os9/fRTbbP0ZJntMp+vbPSQz/LrytTRcQFUOWv5dlF/zKAOrfdW2L8NXbGe89SuD/11rADEat7eJTkgBHouK+tq5McP9Fk5293qVfuF3gWwLTO0rQ8sVGQL8wItPO9Jl/4v/23//bRt771rTfW+m/9rb/17vdFjh14FU/vVdbtqZAXOfl/LSFictuvNHy1Su7Jqt43JNEJWosO7a7bhg7b5yKsKqg+uwam9Fu3mwKQrtY+H1M3JFChEy9tH9FF/VU4jZOuALqnx0XUbbcAq6/6cn27PthsZM6N+X6rMDaMJAV1vakusu98bry9fFQDoD/Xv6vrjFT5BbpHu7uPEq7X4PnSrPxRINR1FfPCCwNEGLA9jqJeWRXiGr8L9wj7oOvde39XVvS1/dxjHErXyuny7HoDfd58GJdF36PbhY3vgx43BwBMQ3ulp3i+Om0grIfzU2/PnjLGeg3kyFzwOPW7HmSN9q6dVT+UP3m81Qn1ut2DNuT4faB8ZeDVUkRbFh1cuUH/k3/yT9504Ah41vHv/b2/98YreEIwrWuRb5VqEVz7U7d5kVAZvfU07l7i11Xf+LTSe+seV/mJA2MiKWyewxBlomvjmGzz8p/cRtfL5GtgKFiK1f0QoN+eUBjlInbdRbJl3s5Jwzj6WwXdxUZ0uv9PwB0pQLlfXSeQFuTwVmP6235j45Q2A0J51pUvz1UhMd4N8ZQ/Gm64vluIXAXe58Sxa8yeNrHhHc82NdNY8FUBA3qW79Hs2rN7tYe6SfU85e9MH2NUur5Qg18EXzmol4AnqitqGPxW3tpyivXP/bk/945XLtHkDMA9g2dqfMt/RfCd9yaMVF98KbxitzneZyCuP/fbRS3MEw9hNxRWTta7rv4oHQpS9fUpTKivC8C3PBmKP/GxEU+VLrL/1V/91TdM9/3vf/+j3/iN3/joX//rf/3m2l/7a3/t0TIV9aivCrhZPJ1kbXLBquRLoPU02ibFVeI2K4DSWze7rnCRn34VkSz6wXwV/IZlKLZFEfUOnuZDu2XGMszW0c0sDQkZM8Z2rQp49wG4doJDgXbNo2EjfT5hUz9kph7PQaOQF2VbwagQ3+9nAC7rg1dAUVwbNcCLOBv26Tybe8JOGIVyKvhVROW39RDMS1Nmy1e7QFrv8mSL8YFKawjbjhBKjy84BXbeOtSP1sJSxrJIvUi65+H0fn3t8xvyqPx1bPXWrlyf5fzfczen6E151uMu/+6u44bH9On44ejzM29peesgzjoqTeiYu/eecSpoT7/F83RP13lq/Dr+Gkyfl+pY0KiOl4ynOfms5U9sBPxGCP7+3//7b9YEjmD/9J/+04/+7b/9t28MwRmBIoE+V6EmIFCpjRcb7kCkumaNx1bx121DwIaSyiRFWM1IcS+m4jX4rUaliqKGb0MSxlUF2T60Lx2/a1cg932WsK5Ao3uR7t0LNZV+V47hmyFUZq4Lfvd1Aw6FfAIitHOfLq51odrcNE7euHbRZMffdk5pnLKQjXN9uboINuFeL7H55vhGCOtK6ec3RrSbpeqq1+vBa1UGPJYai8aJi7h77Wk/TBMM7v6jQ9df7prNXUf/zmPTbVfZ1AjcOCy21yNcGW6/i5YLctTp/j5zv1POfmPMKkdbV8dRb+aerX5iAK6g/+/93u+9O+9oPbHO4fXpjAWe1LY9FvUur40FrJWd6tTlc0ag8r86o3VsG5/HALwZ50d/grJKvYM8ofzFX/zFN//fQtMT41Tx7aAQowpxmVRsuSixAtI6XavCr5U2AVzyjeNhZIJmsuup9Lmi/lV2HQflWu9BH69UcTUFsSGI0rJjub+rlIyD4tTnelqL7iBgY9uTHOvWtj/XrrDMfZ9iOiG7/9VBcXO/zTXDTwHU0NbTQzNG+UIFUleFC4zxPs3/X6+oAANyrsdkvIwuGhdlM/IEmrJZ1IanNqtI+55nfCtf6sMbDV91fUVow+5e9IVwuzgrc2Z5YAGJPvLO1uPezJZV+PXA1OmbPPF00OLmn1EzppcW1Sl89JDxg2/xA6/v2vm9t5lBpU/7zDvEV+tRkMvKHB6izJWG1tpvHg790nWW9aIK9pafVqc+RV6+sOygTvh//I//8U162YWD7mUxd88v//Iv/5hSXUVTFOC6WKvvupeN/3qGssMgVZhXqkjbbhVxn++YGoai2PSz/a6RaNx9UVvXFhYtqsfv1x5kQ8ibxYDRajg6Jw1LlVHKIFWQ7qOAargpXYiwymtRDCQq5NDNPcahTSEYhvP+P8T1pISNoUjpvs0Lg6pt6wynIIrUS+/yUj2Qnbsi/HcC9LCIV4W6gKRKpnStcPvdvbsm075UFimqU2x2wuLH9qVAxXyVHxjdrpEV4DSMtjzlW9/qQRrvggbXbbYyNzdn1gRKs83l1zdzc/+f8SMnaEXBdq/B7/7u774xkmSgfI9Hq+BXsTbisKjcswscK7M9tqORjdbTOV4vsPK5hqDP/j85QE4n/8W/+BfvCHbEuTDQ3/27f/exQ7VuHRBiqcdEY0pKyLPQGVTzFD5A4Jt08byGeZQyssU0b8iirLim6q/SXG9FXHLHV9RUtE7JC7FUuZcxFxmUZqXNEx3rft53hbQopILav7s9v/Nab+YE+gTN4q71gipv4762N5+fApP2WQXcBVVz30wsBv2ev7ZtIqtXhV/RqV4Yw4M+DbfVIyS4+LGob9Nn8ROl0cVEfWoYpXNa5F+e09/jk6Pvfc4A9D0K5ZuuA5UWTx5KkX+9mGaxGHuvuX8VYuP9xqEvxycLdu5zPNRU7HqCVx8vsXIs9EgveBZ/3N9nWO5zuuB334KNgsPyhtRP9CoN8UrDgxs98MzuGgfwrg67sLVbvnypVLbNFQNT3fCFrAks+mex/+E//If/10aKI/Sv/Mqv/NhbyfpdBFHrhhhVXg1trJLTJ0Tt4goFZLW/irh9waQdpwXLU0iUgbcFnSsJ3XZCCV/RYQ1DvYylpfuv/rr3RcRdWC7ieLL+DWNdQZsndFrPaENRRTNFRL6Lzqv0rAPUiKHh/e3s+So+m7DsEXjHqHlRCLffWCjVgom7dnVQFpR0w2hohNaef9oEZ4xCCsIH0PF6Z30OP3vDlLEIh/WNXJ55nzvftYob0/Hn1X19cv3aOPkTBinP8JT0UzYYWlhsNpc11vUYr9wcou3yePmOfHWB+e6V999n8VznHD8aC3kQKfC7uTQe47zP0fob3/jGu41fdgF/OZ7NkzG4PkoH7uK0sVX2CvhqiNdTbp/NIyNRneh39VSHltfan97z/+zYiCPc3/7bf/tFxbZuzZVF4CV6EUwV213v6+vEtpt9QWnb7FLXvMhAnSVa0bH+mIzGWXkU4oXQAgZsWp9+9/WGSgXC2HuQV9vXp64vQJNtp8azit3zDRvUNW16KuXWhWx9qTvacEXnWkrdLcjKqOh4zN0ZUgLQUz9t5yd0nZsq/tLu2kF7yoTAutdiYz2fhhJKO/VYyK6yoWT1r0ZgvQHztCEYgOHGerwKXJyisisW35T2zQbqgjua6l+9WR7RKqvOG7rU4145rsHXjrllmPB0QdACQHN5yt9ZOwVolc16l4xS+d7Y3Wts+nrXpMieUeSdXsj6wkBfetjDUH1ELqxTHT90TaU6w/ifIgINJXmmnhSe3efw45O3ZZ5Xr2hvdewXkh1UQXpClp38urIldK1gmbJusm8IuTFbqYk+RfPrypuECrvSBeMagSqgnYT7hloxK2FmFCgx+wBMdl12CgSjiWtj4m5iafyYsi1KaFyx2VG+q/S5yY0tdwFZX3YDVgVgi4wuC7PoZt467xAaBQuRSmus97fezPIMAyyEBwEyGJ6FfMu397sXoDPW+IsBMN4mItQTVXeNAaFeo9XQgs+Vep0ATg2lkzvvPp5tNz3pS9GjHcH2Aux6hXlG/12UrPLpt/4yAEWlvhsCwoPm78bVzL/KQ3WEOVV/5+yuXT13rQe8kRl/XztncO45u6IPoKj/h2/5tPQzVv8LTd3fZzwsOlfXlGc6ZrxTz0ukoeNtWLgL932myt/v1dGVr89aPpcRaNigRGrjFdg+u4uWVbK19os2TaJsliOUuGetaMMAJfxLoaP+vWmWi0iewlUmtVb9foPOrCH4m3JUt35Xmamvi0VXSrvS5ckt9TxFJEwgxt5QTw3fE90YmuZEd71g27/7oaQNDwgzVKHWm6B8ze3yXcNYlAFhMaZrG9pnaBs+6kF15vKuSfM8QTfGo1mVeb2Qrq08KYJVfkXkxtJwR+eSd3CFl1ujbfzGXM+nc4FGaA2M9P0QVeg11sIs/u9aRZFtFfUauCfQdf9bK6pS3zDiFmCO4u27e3cuaoDI4BUvuj/lf16Ao2y+mk2VjMnqIPLKoziDItJgvunCAh3PboYf8Nixrh55Ckt1Ib4evt9f8mZedcdwlV4tUhX6egt9/um37WiZU2rhDf6sN7RQwSsqKEovE+pbXb8+20yixq/9v/3uxHfyyzTXxjFKM5xu4hs2oqjOTYW61NWQF7e7bnHHQCCKNo7ZT5kUMRadeZZLuiiuxpkSw5gEoPev14JpeUFXmv5WPjKmZqXUS4K8PXeloT1tUVzQs77ZfawvxgdZ398MdXPIa7zKw0JVaAlB12u1mKivDWPikYbb1oBL7+TpFaE/eTkNSaFJU2S7sa2GED/Xq78izKWuTV1UR0OaEhrMY+WPR3IKHBjAryujNfZSfwveChjRh9LvmLcU6fv7D98q44ZqOrdNNOHBnDExzva5nmm9sa6vWKvqesHq0Cr2/V4Q0yMkSs/36eJXXxhWnmJZT/c9XUNgfxPwG+CdQ/TSdv8q4/bxpZCO0onusQ7uewoNVdG7t1a/hTLUVuPWDAKGuCO2HZ1AuVyfLPIVbTWE8OTyHZ0gHl5SQwsY0/iuVIlvPLc7bhvW6BrMMrz9ARSfuTP2De8YI/ddP2to0Nh4GuunnPT3xk7R6CtF2zHXSMh2kqHUrB0gpPz1xFM9D4gwNgsI/cxbvVhKv0biPLej2de//vV3Cs4cFfV1PanK07X736ImY9yX3dRouL9eB37Gc9B7N0OhqUXoKvi750CO5BD8YF5aP9lDQ/SRTEABX/0MYRH1InF8WlpZD6oM/CjKHF83HNuQ1H1fP2485c8FJf1bvQ27LqKvLLRf5hxNOl+Vja3H/V+YEdhO+P3J+rZsJ6u0G0pqZogJWZS/4YsKZ4lQj6FIct3xov62V8Gq8lu3X3s1Tvqz4aUrlP7VdYi9aOaK9Q/IsPFcLvHdf0x9CkOGCMapgSzK8Xxph/51z69QPBis3krPwqnyuv/PC7Eeoq4aFKGxdWtrZGUQXeH2l1dqrH3E0CkM58BQCOpa/qgA7bt08Rrl0bWAyoFrpcl6o/f39UefoNIrEGzj/Pd31zislVR2rjC+wl6dMwZGX68eG6TqOVR5bZir3kDpXn6ph4bvvGqxG6f0ab2ap6wa4JDsoVN1UHcHo6nwUTdEohkj1HDLV/Me6bZbXuUZGte9jIa8lWYNTS1QZdjIp09DWO1v9Z8xd9HefDyFADfc9ypGoEzfkMHe8xSHegoX9b66RuqBPDzX61VsRV81Jp7rtc2v78JcJ0W7tdxVDFs/2jTNsELUv/X5XFxhixq9+1vaHIFYt1M7DrO6Z2THMCKea+pZww7rxUD01g1200wNgbh1hUcIx/O24cv+KMKWGrlCA026VtoSoAqYGG2VrjgwHvXcKvwNgTXeX6+LgrOwz9hA2JvJ1bDgU/aVxXwpitYjGiJRx/1/i5DXBo+kIa7jnyLnPfoD73VzVdNTS+fyh75IkS7CrtIrKLsi1t8sOXyh7tIHz1WGFfKkzq6zVf5OBvS99fZU0Mb5CyoLeK50cZ0hMY6u510/Tj7vc/OzHh0aCGddqYJu+/VUK58LQOvdPRlr10pDc/ZqRuAWU8pY68K0g37r5L5kle56d+uucSnKaqph7ytz+Z9AF9W3TvWZ6DJ0BbHPdwFLPYSyC8vuqTVu7rW1DpPf9wk0fNDUP32VPuiAvlMiUPPGY40LkkVnc1IBrXfU9YVFbphWXFN/lTXOkFdDbzyM5p/jH/eWdvq4az/qsKBGgQulmS9Ktjxao1+e7rybB0X6rgVbyNu49ZHg73lJ97e3dKGN34zJWU3417qF8EtRpHfjmoMCAMa6NMRL+LNrMvi5oRJGu0bT27WMuZ+ufaB5Uzi7rlPkXc/O/HeeqxS7waqx/YKbZrxVNmvc8cLHDycMbNs1dPjy5PBONW3qd4FQ2zFmdOiem9KigGw9ObRa3bk6rXrqs5bPbAT+2T/7Zz/WkU5gO9SOdrD9VFmrp2iq9RVlL2JZ5qn7vSiydUIKhLp9EfurYaknodRtfEPIOUCKENdd09emm1FcncjWb7ey1FPuoPCPkBDhLeO13T2Eq0IDEWEeY2n8vp6De8y9hVF0OITbM156VESZvgaiSBU/NHWUwn9q33xv6mfb7xny6miqZullnL0XDZxrXyXae5Vr7+bn5ukM9il/mU/ue1qjqQLBr92kaKz1YCVMADRVwktXMlsFtwqmdXY9xJ4YYzNPlH9P86Qc8ZZ7AZbNrPF3vcPKPM+LTFg/U1fDcEJB6qtHg3fq/X1pdlTXcJKDhm/v//v71vN4vDxddRel87q6XmJM9QrKu+XBXn8CTE+ewU8Kzf+xjACm6AJRwwxVzKxqs0KK3J4WMRBjB1jl2gXReiVV9nWHakDa3k1KN5n12ebd91mC1EKREMiOo8qlyFPMmmD0zUaeR1fhnTJKkYe4ej0vrq96Cf4hp+7WrRLkja0wub7K1u81DpR+Q0LNhGq2jLEZTwW/81f6ca0XdFAe/UiHlOnTfvXZKt6n+qBaCogSqzGtUaMw7l6x/+5WX0F/8nQarrK5SdhnX3hOwTQsB9yQHR7Bhglcb8gCLz1l4BW5i5HLuKrBqvEo32sH+KmSr4ddBda1hwJG+3K6kbAeOXBXcHh/C7W6fxf8v5KzhzpPHfvS4U6tNccWvzuPQIwEBp5A10kaFiovFciQsU2S0c8ajz7zqkbgGJE1JRDdks2yV/BNBktsQghkEUNRMMVqIP7GPFVSncQyehlewZBQ1dZRtF6EoA+txySb2M0OUHcFFpKioBgKufhXVxdNy8ToIstGaKXKV/u8mSqF1uG+ejzXjxPqQ3hFZWXKK0VThJ0yqPEvXQhWEdDGQWt0zHOf7aF1aNLjFvRZZhJkjNZNO627jA4UVFG5OQAadl1ohbVplDYl4eVT6Azhplt24fauyaZxv4V2BqDhjvsN7dDsvA9ouAYLHzfGXF6pfFYRlu/7zPXTWOmAbvoqEFGXs5wqT/gAv5L1J0+hHqv5aMSBka7cU7p49fYI9ITXKwvEXO+LaboJ0fjupOSr69YGeAMN4TTraaMZT2sBG57zvYDoKdS+z7r+qp5ABc3uSo157ychMvkmhiW+wlpz1RpjXoJVWZVIGwKqa/vkTlVI1FcFYMKq/K7sjlrupz6WBttm48P3TWjuY8FU/Zi5GUHQcRGw+u0tcFpiGaaMQ4kVLT2lJl6RK88QnCLq6/tksLxjnrdIE28saheeqGdVY2DMRZEMY+PCV64v2vTb7u9oOMxc9Zm+7c1z+um+zrljHPDWItyCCIrv+PkWzR2bXSNqDI3Z3+eUNqVxYGvfiXB1Fc3eNVk3vY8cXVsyxngKwiN4cQFK5acx84bsfOzsVtc9e8bIs+t5k496ZgVY/l4veoFdwY7+NQQoLIUXWxjPi+Pf747X/vhh/VE/GI/S4tq4Obo5MX5rA/c7rw0NK3cFtQVT7UdDcxtOKz0YrQ3labMg8tWMQDu7u3gv0+WMACRgMA0bsdqyWAjy1QHlOYxqGaKoq1azE7ZewKK0CnoPaLv7ihxKwI3zV4nVfYNMGgvsM8Z5BQpqKKXIencKUhStyzNedwcJcStrhBsLN6ZVxARHO/eRj13kS2k7dEufd02H56FuyB4vlL6U1BWpsl1kZxDLU0WKaNcF2yt9W9k9YzFWPLl8Vs+1yg66NScWac1bkfwpXIaycoLnF4T4vme81OTavzhzkfHdYy3g6jjjj86QNg9Kn4rky0v1WGtg3ceId+9Ms3GU8gJgd8oPDTbcpd6nME09cPSugtt1KXwOkdeDaXivvKwP5q8JFp++Z03THBWx8+xuvI6p8e5jhsE+FbzS/Q431/Vs8Aa9WVkSRiIzPSG1Y9dOw8Lm+1WNALfSxB0Rjhh3Sugx7rm+BK8vaK7iJIB+9/8N9ozILaBhKs9uyKd/19qWEGvR1wo3ZOX/IrZFIpi0wtlUOROBebtAJxxDmGygohgrjPWYeEjrmlO8nrHLlcJwveO1ICV8tB4CBVAj07DBxhzFutGiaLphjXoYVfxdHCRE4rxdmL9yisVxv02zFAqioPGZ368OoTPKxIL8hhnN1xXhmp68uVlC5puxvP4RdHNLWI0X/fTH6x3Ni9di3n2OjSiiBRCEeNBeaBA6rwKpN60wVOi3RgJdWg8e0ffKiWLuhEXIVhU4pYsf0aoGE+8UVFzhJZOPyvtTFljDtYDUnp20ivOTeW+zutGlYaKud5oX/eblk+Fmi+H9hsi7NlKw6RvdzUWz33bdovrw1cNBjgSWoXJG4OJhh0x+67d+691WaiGQKpcO+AqhN3mO0z0h+PVf//V3SKqxsCtVyk/hj6ItTLEZBkIeFMX9bkGn2THLKOt+YeYiEAzAQF6pN9T4ZZVmGc7iXxV/PYsqU4b16pCvfMX4a5AJIhSKFoyK9iuY+kdxYjhen5BDkTo0R6iurqPHpuB5frNgmlboNNhdT7AJzNqOMJs56FyjWT2/ggN9LH+he4005NlYrzOZFEJ5zwkj1TuwI3lpTGGUFygwBl47NyZv2gIs7jd1oV33EdTLxNf4qru6xePxrusFIvpLKZlvMiI0gp+MwzHaDRcXWJE/PIbGnaeGC6v8Oo/l2yYdNARaj/iPsjazEYjKXYv7Tg6Ewex0t3YEBOMB/G1tyjjKMzWCNQTqKH3WYNaYb3jo1YzA7ZCjLLl2FDxEgdEwj1z4G2xji4TJgqJy9fzSL/3SR9/+9rd/bLC1bIvy63oS1i5Ieb7CLJ2tuzHfEGPWITATwjYs4toxAqWPNpQcgSFUlCkmap0MAOPoujWHZoEwqgzZeWInfF6Sgd5V7BgGmpLDXiFwv/+bUtndvnePXbmUtP6fS0w5UIA2REHVPanz6Hd1SZ/kBaGb9af1nJo6q49ddOVZNNzDCHTtYkN+VSoFM8IA+KJZUMbWhcNTzOcd92U55rS581U01nf0Ff2qCOxSvTq6UarraTynejJVHEfTM5w3f8c793fvv78h2wMXlGuVo/8lASxI6pvN6hnyvN8poIRk0KLrOs3oaui1wKmGu97Tk/dWxbrhoi8HXDYMVD1QfWBT582zMDOvoO92UA9+rELfhAX3ow0aVBcUDCr11Lt4/qpG4BjFwg5Gly98nTslJIOBlTVBkJrNLYTp4mgY+wZ6RDzv4gh4zKc0FFTU2biu+2rJ676ZAGgHkqrrt+GZuoLLaBYNZftg1p4P1Lb1qe8TxWjQv4/xXdGOXHebZCxyGsvNyb3GU8raKZSjdxmK0DDcRRBo2awf4+8CcMdlnJBOUcnGTdGMEqySBwoYJO3t+UGMUJX6oskqCllsPWKjXp06zXnnqXUvErz+eyFJ58IO4BpYc7lCrg88T542dMoAu68hCYvJwJe+98wez9QLFEY5eeSJHZL1pi1Ag7wd393ZRcJWSo2a+dFWvdgCiipcesEcVOmbV/Wusq5SXf1QBF2l2HtLmyrZL7+Qr18dsxEJ4R2hbAZgQ6k1lK3b/2QAz9gw6JmCF7Sr8cP/5enW/6rZQSbfpF4RXz+BOEa6AXDze991yNnfRboWw46Qzbb5H//jf7xTYhVaTEKxlEgNRRGGKuKe9e/vKmOhJGPkIfBw+hylJabLkFg74S4TTJMEUUKrDddUoDCPRUGLpqXrhjT2TVpQP4SpbUisiuc+lCUlLaOEYjDGuv911etil26QP6Pi8K0qZHXtkcfGUvcaHxRZ2gxXNIkf1NcFcjxR9FdF0ZBB+emU/IU/uwv4rgmHrtKoV0WRuqcJBejBIFSJMZJ9dgW/ivQKg2dhXkoyQFFDWnRqjp1gqv0FDOs9Aj/6fe301aCrAKvYC/Ca2NDwTz2RelP6sGcqoW+9jEYkGIJPH9ZEOm/4U+xf/XiW3DDM5L5GpQieXFSnWato5pNxN4y+oKRhzBqpgotXNQLdOHOFwJkgSs3/FE7DHZB443cmT2z+LOr9fp7F/d+4sIH5JmyNN5vMRfbWMVjqhhGM5x1REqfWZwtBd38XmBpOMEHG3MwGk+WaWCKXv7REOwq8B8P57kFnpY2wxHo9Unob5tBvClaBtjGXNhrqq+FhNIrASgeG5cohSxlhPEChJWPWN+l8DaXUwxPSYzy6wKsvFHWVv3kr0i49apz2VMzzUC1+ypRq7FuYk5D2RTDlmcZzr4gpUxr+1jdjJmeL9Ix3PY0uvkP71oLqldn8ZU1LW1d2XeZKvUYG0XWK8OT3+Ly0LyKuEq5BILtPxmJDIJ5nsGt81b876kvbn5ojvut1FbG3jwUjELmzsHiC9Iz1mot6eK2l0NHJtpfbLC3uw9Oup0sH6eMaMTqlRufVjABlQGFAX/f3ISMCXATJpblOCT90MrmnxzDSDq/OUxTf+ta3fgyJdFW/LnsnpNavbqHNN9C8BTUKs+5iLarUL6628lJcTqlQlC73jPDIlbq8aGWTUY8YqIAbl3CLtZkypcW+Gm6ImfK8whhAh8ZJgBrm2VBVF//6N/qUNv6vR9XrwECNiHmlyIV2rgirMap1p+0DaL+rMKuA1NU5RcNu5rvfbKTzykx0qmH23BrKej0NkZhLHpm+MSo3xoYXfRprb8iyRgFf3D19raawlWIdw7xInYRu0aphGf3rGUgUPUQrDNfDERt6NScNJ3Z+8XTpctfIT9dAWhcak5vKbL3ZhrQ/jt7o3Ox31y8Kdho6FN615uJ3m/iOf47++nDh2+4Cx1NowQNZIEkOjachMnJVvfYqRmDDOEWPGAhhKCJ/I2TjuJ0YjCYWdsS7hegjznkGu4Bcd6dGAAMhAnRoxd7CjWdKQH24QhgaHlGqHNfiFj1hSK63w8P6WjvoHHq8j12mhA29GNO6l07pZJCbsXLjtMkIEznC2AmIvJvOHWOkvnomhL7eQZF+F2/NU2O8BP7udV6+uKqF5cZBhV9k1vAWu55T1F4U3HWpLrRW0VfBUKhVWBWko7mF9y6mkw1jZLTqHTS8YA4LVvTp5kmIsPx1Y94FxcaQGXN8BYWqS2ZO91/gde/cvftvTckmRO95Rmey2pi5Pq78kQ+eWcGOZ1pHvfiGt6wXFnStjONPYyhqr0fQ6+a1612fDN90QbrrBw25rPdLFk9nHf0uzH3P3RjOe/zud7/7Lqyr/kYneNoN3XYhvPqGF8MjXRrVc3nVo6QhMIOHNns++g3qygk519KAoae7TjEjNIY+JjwiFsEcMU55NmxShA2JtK9S5Li7m0myE4nBr0+H/sWtN73S5Cjd9IMppeYRnMuUuJfj3Of+vgLlYUZuZD0F3gdG73oCZHcfqI+3I+OgAs87E2oo+hRegPD1R0465VFjUaHFcDwQ/TN3FbAi4TL8FUbBvDIAcuEtwjHOnZcFCTXu7sNvDf/gn4a+PK9/FlEdj2AsDYGYJ/U3zo83KpiOGEBLc4DGfeUl40zgG8d/I8RvFVlRqUwtBgWQqHeDb0/mDnRB/6eoeOVCbU8hrNZRdN/QmtBfkfv2vWEsdF8w0XAI+ts8hZcaRqUn6qV1M+qi5q+8pRte2fWC8k37UF2AtofuhQmF+Rz5vuErBwsK7wKqAJeEEP3mGZYWnYM10q9uBBqWuXKD8masKgdMe0x4cd27534/5d4MjYYyoKCmj7F2R9RmNHSRrEzCje1RDN0XQBEIS2AcTHHPXCiqC9Ti70/KpLsvMQPGuIm98f7P//k/373YujsqT5lVWWDohpI6xqZrFlUxUhS4tx5BCXevkFePiMCk3RZfhr96TxncfXaHYzYKuO7oxiAJsTF27wYkXC8HX3RcgESPbja/dcWL0up5dix12Wuc9LUhhyvqIcAMBaPf7A1hCvNXxSMchGbdrIcOlKaQl3CrEF7nz1yVNxh3Bocip/T0p7J5/x/YOfR/PHPXD60CDEJsDbOVz/VD37VRoOj30lcfamirWIuuyWzbqw7qfDeiYH7I+PIqg6ZfP4rnXWPVNtG74UvAZwEI+vXeKwcCGfka5J4bdu3fvEgzdY/+NnHCNaH3hiYbjn01IyAjRgNl0L/8l//ym9z+7liEhgnLDeoMwilDi0mQAuFCRIidZYfSrk7uqvzrukvq6RuF1k2q0HeCrhwausLyqpewEqCGErjfkPkJH3fwN3/zN998Q7SNJ0L8FANl4VpDazVU9/d6YwwopGrhu4tkR68T8p7BUxe/CpzwCiPpOyCwSqjC4Xl0vlJw4P8Kob97xETDQvpCAVHqDQtCSesZVEk1DNi4MxpsaM/YzU/7boz4oQofzasICWfXC/xmDu//m6MDPdJrqwSq9LVz/bGRrN5WjfUVSBFQ+NVf/dV3yv/aoVzQjWd+AKZhITIPXBWlN0ymH50jfTKPZLf0RPfKHr43P+L40DEaWajXL/PbNYuGgorm/+jtPQtWXNu++a7M1MCtsXtak2jYjJ68cvN5ILFp4eShgKLyVi+sQOdVjcApD24i4iDKDeKOj7iYF/TR83hMzv1/hqAhliu1bmdsjvFMksFS1t0p2Zd2uK9pXArmLSNuHPc2qR3xrOyXaeox1PW6vp7VltJ6L97Rp1ssP3o0hoshhHG6IAYNSH1zbxWqSXXvIjEKgYvPFW3GCoGiCMXji8yKprvoap2gIbQrmBVDl1YErQZnjUjPLrqCXj23pjxnvErbu6KdGhljX/6t8GiXIO3xBvrRoygawmj4p6GizjNa1NDrB+Nuru7386YbgiRXDZ9II5ZYYLzlk6v/ZPgMTI1MPSl9FY4F9Ko47QMiJz3qfOPmDQtSgIr1v9KcMa9RrRwU7Rtj+4838e96AEq9jy+Hll3fKLhQV9t4Kg0x9f/qIQage4n83cyv65fF5fvtdO96KQ1jdq1iQder7hMgrItC7tqh6L/0l/7Su7QnTKSTjVmxrFe42xQqxj0m4Vmw7DUGd/2IBK1S4EILXUjZ7AaMQnhPKMThmi1UdFPlceO6yREDvzE7nvbqoPzrtqnPPZQcpbK7dysA3P2GiboIhh5XalyuHYvGdR2LnMs41goY1TPYFXLMqv1uy19Ep70uhLbtKnFzwgg27mkto4q5aL5omyeB92p8rxCeKiWCVcWMP2qQ8ZUPVO8+/WgIRVsNJ6BTvRXrOF4hWVQorGfNiMe0G8WqYK5YDPYK0/t2fMfVd6EJoZ9VuDytrtn5XTi0i/onhzX09VTqYZbmBSLrae1CbGX3JW/M9fKTOqsLAMVV2F+ZhJWXlP8i/crPlsono1J+xUPAqfEyBvji9NPR2flsT5GNXQPAh69qBChqbqBJYY1OEUIah6qvOFbXG7BMGBTBxW8si+D3/yIICgAz9qx89RDYulFlkCs1LF5Krh2MtwpHm5SYzSFXxxnBm7gLAdnk1tDR3ScjRh+Nrbtli2KMfz0Ri8FlwsY79ZPwViDrpkKJFv5snpOiqu3WX9RcJVrE1nALZaVPNdruYUy8MxmfUKrWBPa4AYtovda2Gd2GA67UMBURVjAZIh+FsBb945lea0jBPKkHz/PEzvXHJzJM0KXjoIg9V88Nvbz56+hya3GObjF2hvwA1xWpyAwX5YLWF56yt4ABkmF3/VaaZlw61QhUhutRU9gFE73PmD0jJII/ydGi/4YvNztsQ4FffnilZXm012sInkqNhVLj2LpqoBrKsz4qsnL0vbm7+agMmnelXs+rrwm0Ue/IbchEGOIY4+4T+zcJRQHrznWC7/+rQy5tmQgKr4dR989vQhx7UF0VAQOGecVf63pXeDYeWQbByFb3D2UV1TNK3R0s3syKV5CfLDmFUtRcZFHFLsZrHF0rsLOVASa4VW5CZ1eKPo2l4TJz0PUHtLFeQkCL/DrmZgRVULo4Z25qjCnVpiMbSzOrKog1tEVpjfXWEHRRGQ27T+DpqI8nxMhAUfSUqgXEq+t40d6P+xyAwpdeVUnRC800LFpeRHfhhYanru/nufKejRl/Gf8eI9H9F+a7Yczrf88Xa+gELzeUV5ri3dKv3kJlrgu+aFojQkaMY0OS6qtBuLJAYe/HH/UYfJeXXvIK1nDt9YYwLe6X34XwZGPqRz3fp/DXqxmB65BdvBpf4hxDnPI/BhP2sejVjvltszzqfjmpsii5WT4ldgW3xxY7EwWjs7LaKJp5ctOb5XBl87IhTGfJEORDYLdQboL6WsAqykWNRTKYuJNaVFmErh3My+DUCNR46rcQD/e7hse9wh08g7v3/j5FdONsiJCSXiMHsRfJdVG/KI2ioRC6wF1EaB70VV2N09eL069dS6hnZD2jxroLup0XHlwVKOX89IKk7ojmEd19t3Ykd/zk5u47lH5ZamgvBMB7rcGuR0c+zB1v+J7lXduLInzGiFQhtW7yha/MY49Stk535cbQfjyBGmG7ynC9WnNX4KPU6yTDT55+PbwCUW113q9UERcE9pn1Ijzjd6XGv3+vjiloqCIvWBE1OZk73cKDsxO5bVSG27dXMwKEVmerkL0XQBYMAYCidodqXTETUEEhiAZHICnMhgU62ZRW1wKg2CqPxtcJM+SoL2XKIgxprSbJsQ42aV09N1EnDNL0qlSKUCjjjqdM0XBMURpG9OnZPnXthUy031TeonP1FV2VgeoSU0LWG6zLFJkI+eh7F5s9r431cChJY2j/egbLepQ1PmsY1Yd2VTQV2i5Idr4oQHU3oeCeE0ar8qsxh+5vHmSO3ac8Z3H93P377cCUsJC57JHZgBUecjJo4/UNdQIqNhDep8kC5YcmIKzC6m9HF4ZTHrzQBSXJ0DwdhVEPEhCsR1AZfFKy+KL9wxuerwFpfeWdr4Y/mlGzoR/z+VnDLG23kQg8r72GperJWOg31xJneF7ovzJkfl89O0jDfa2akMI1KCX0lF/z/y0g9q1NjIiBS0HjSkLuFAKiW1AtQlvErt0ivxoE6whFihQK1FgL3fBQlRYDcEjO/wzg3X9e0wk0123Rfz2TMm2tO6aA1hse2nhq00KvMHSUjf4KP3RcQkg1lgx29y3Urb46+rrQIpkrdeOrsDuOIrQKteed59QwgXtWeMxfkRnQAHUvIrxSQ9BFXygMrRmyKgJKuQaB8jXO+83Lkhw011RrdBOr1+8LKXpXQkNh+sWAnMzYQHd19awp4R5gBF3wfwvlQ/asA+DZ8mDBSxMJyDsZVWfrqhyYy1WQvW4uFqxQgIv4u8C6HkTHWXn+NF74oveCBd8FNE+Iu8am1za8WZ1VkEc2yf7NpzVAa0i7n6jrRw1NvfrZQd181NVyA2QIjulNRt9Itot74lwE/n6nWIqCIQp7BAy48UuMihAISbHVEBRB1211vTvyKMq6oPftCAgKortJTY5X7vXIYfUUXTTLhhL2+6LaddMpHcrBmCzIXvuMX5UTY9zspXpnzRDxDAGq8HSTF95Y15vBLsLpmLtOwyhTeE0VJXxKjUkX/dTr74Z0zOmuaTCUXU8gXHipxy7ctTPyPVIEAqfom5ygD3igc1lvqSDkAJXQmzBTQyk9kuSu8UirPMqXHZP2q7jJEVlsKImBq9zXGJG1GgHGiB5Ab7Jfr6vhtp3f9R4ZlqaEVllfKa8UKFSx+/4k3tWClirURjC6J2qVvWuleb0BY+v4GiFpu/TuGXLvNpY6Kh2YMWyEY2Xl1d4xjOEb1+yHpSqKsnvOBOhw3RYK62KVMmjqcpk4G8EIgoKRiwx7POuGdISFaolrzExIhdRk3XOH/k9Aa3wIzBVZLte2A+jOYPAUFAxcT6B9dw29G/suA2GqjsucaYNg18WneO5TY9m1HvT1qUEoWiqjd249v2i/86L91m1s9TBqPCvwba/eRtdgdj7Rr3XVMC/atsnO7mFnCDFaDgazHgNIWAcoDzUrznyZ12beNfRyRSKDVGprcGSNwTHPEPpu6qoy9G0sffUnUHH3OBMfX/MwJUP0mXrz9MWVrldoW994o32uYAjfuF7erwzXa19Uv1529ccnARTaraxW3taoau99ZQFUx/RkvLqWYW6bEOOY+RrhBT8d46sagWOCS4eUf87CU8KEEEp2+NWT6404YsxS1LqeUAV0vx3zOdO/O4eLYKsUoBfEJpArBCbkabGJ0rXr1sYNAkGhUQJcZIah+dnQXUMI7UMVOOXV9QNGqv1suKRx147ZnoTmH19hcKuAy6Tth/r2dFfoEW3rFWydpXG9tutHvUSKB09smK9CVJe8iqP8JsTVOa2xKULbrfkUMwNgLo423oFsn0iVUePrAADPqrva69l2fAVO5uraOT7rESMUvbHgh6U/WvFsGv6sssRD+l5AcqUb2OpVtU70J6P4R7rvypxMJLzQk1LxeOe9XquxQ8K7VqSdApQqyE+jB6qQd2+AMeyiduX2ibf8X0Vdz8b4Sv8CFvNxdL9nrMcdGBCFIFPNnPqs5XMZAYIhftlD2VbpevWgzWQYRRF3vG8nZyJAF4i6cISAN2gbu8RE75pFL4qzqYxVtt1wAZWVcE8hGG87O+MGcTXdswtfVzdFIkQAMV1GjWOJGYqGC8oMDQ2ssPY6hNU0OMa4efTi2O6hPIoU0Y8wN5MIYzvVtQv9snXqTbXfDE29RGOsEifAaGt9CQ8WDXXsVzYk1Ayddevx7xX8YKFV/Pv4iuckM6xCrdzvzoISTvIin2amVelC0RSn/nfBtQkRjK1+qwNtPMdwaUsotd4GOWvIr2NqGLA0BoTwDVrj2cbMG37rWgJ61lg3NMJASjQRUmq2GprTI1WyXdDHB2vs66V+MntW8IjfnjxT4cAajAVPT6UGfr0cv3WdrnJnvg5w8I55qOZ9ef2zLmB/ZiOw6ZKOQK1FXiWF8RGs2T2nEJ3PblC1fiZd/c3QwMyYysKytFLoEZOXqHWJ79q1z6NZF01bx/h3Hw/ARBKuHi9cpaG+jTOrg1LG5HaFVnnUTV0Xtf1tOKwLxEJoZ3wsNPJWKLo1vlVC5pICLkpxFIgxUVBQd5FVFbe+msd6Dq6XidXTxWXrHupyHzo1hNI2G9askiWIXg5Sw44mQlaMuDaBIXH4GosNa+INh+NBv+RKKFBs/ynsV57AR/UuG8/W93rD5ZWmZtejqDz3NFfKp8a6irmeItnrnpWGP8lYlXbrseCtff2v51S9UaBZ3kGTJiXU4H06a1NPocIa4xqx0qrgrKUAZHWa62Sr4cEdx328tdFu7ababwJF5/JVD5C7Bpzp3hhdEXGt8LpYECP3Rj57FzURZC2bugmX+rnFkJV4GSXeODr0j8jiuSfYwjbaE/IRcsLIzYKxhiH7w3gbpqrirPfAOJQ5udVisI0x1wBiHs80DMDLIsA8kluw18d7xgmw3VXbbCyeGKPUM5oackIvYaGixAoSIelb3IoWy/AEouOkGPtCGbQq8u3cqrvKxkJn0VPXKHh5DYv0taEWQaUxNxxpfah7CIylIalrk+cKeZMlddYgLsKssqsH0NCF/nbD5CYGGKM29LeG5koB310TvrOOUC9nPTL0aZ+NG81WOZPbhlPtxemaT/ULvm7xOwXc8S96//RBb61HseG60ujJE6i3ow/aXe/M/R1jxwBIX0QCLzlZt3IoieCzls9lBAi41DhMakDQa9EXQenplZRk3X2hHYOQUYPJ+7f6r3Txqoxhkiu8BHvdwyJgyoji87IXipgSv9+cBV4P4OrmwvpQ9GhUxoEMG0oqQzf8waD0nKEij3owjaE68kOMnRI74bJoLAuBUuUJEH5vpCp90ek8IQhxjVD71rh114QIV8MWNZilx9UhHMgY1Osr0loh9xu+pezV3zm7exzMVqSmPsq+Sv7ofOdGealPQYO+UNb+bviwIaB61e07GUALAKhIUJtVug3JXGliBHqhY2PL2rpiD4KU746j8ouugJmsJr/j++ujjYTCzB13lSMPkzdeZV99UAVfI1re63g/nbWQhmrKewx6r/HYyFnX48qHnjd/eKYh9uXP9k+hB67NWxsSNuOFrmfy6uEg6E7HTyFYnIWuEZMwm+AiuuafY1TujMF0ga0Ko/0oGqUUEQTSb0ybkkForn7HxBhI85N50UnUH9kgCF4lUq9gvZEidv0i2GUkynmRmXF0g0sRS2OcDWMINVHy1mOc1SOry5i6QHdGH+LTT68htKPRC21OSM1NETi02zUPfe0CKmVehVwDjTfMc+O2TQIgZPiyIZA3jJ9Du9oXSpAibDjwCgR/61iACuWKV/ryIijcGOrxKXddWmk93yrZ9X4LuBpOQs/S3fV6b+7R567LkEEFfRtexWMAjAyhylPH2D6Xx+9z/NWTUF8KD+njzUXDJvU0tdV+N0xDXtz7paRmNjS0iL3y51qNwxqtttlISI0OGnbOC1LVU2CIrkfLy1L0ClxGuVltr24ExISLmrnnFbQipYYv6rbtgpYXXPeMG8/UA8CIVRQMEEFSb0+/XLdL7LdxOBNw/TnF5zhdTEIYb8yYUL+ME1IuMsMgGLCCWGavcHSiq9SLMoytRrHe0Ho7YujS8O7ajUN7R7vGOosej1beEidD6mjESPUQP95BEwbMyWZuoQ9BYJj7xi0IB2CgnDuvqzxLwwpgBQsdxa/RpIAAvbVhfhibKruGkHgIjErRnf5UETV8pe/t986tcTabTikgMA7GsrF4fe8z1rEa7iT75em+SEWo7K7xCBtSrX4Qwmj/8SpFVjooNZzC0jJl1lisd1NUvTH46qFPZ5HWvdufAsLqlPJcjYRn9L+Rkg3F+V4eKKjr30fvAyPWaPrCmhqSVzMCOiNOzXK7TllX+AgvBusKf2OSJQAEWhTdga2SKgO4D/rqzkjufZUmpiekxqL/dl8WbatbSismMb6GGhoqq6tZobJAWw9pUeO6+nVLS+8q4vUyPMdbspjOmHHx7xRYYTz0dezB1efdxMJf1hAIkQVu80N5VgAwcveWrDcjZKUexr7prbyTCmL70yNMqnwYWPOPnmgvfRP/4hvv7L36eEcy4M49d/qq8a77X4Uk9OZa1y86l0JF+Mw9+Mr9VVp4osbyjbDPznceRkGbe/BXja9nl54SLBgEBlEYiMG021W6ck9L5VFenXbZFzEX8Aljyp1/UrhF76UpL6g640qNVj3DK8aLn+i5J1DWa9VrBR484uqcynPnrePBT/6/j4SVM6LdgKeeVzUCFtNqBRGXIrlSZaXj0B0lwF2hPK9sVk2Z/EpXwRs7b/y0wkOoMZvt99otITEDL0BIhPDb6MVlvyLkZRGwk7nIrCGoegeMo1LvYNc2PFO3tC48A70ewBXI1DsQrhzjMEDN9dZPSuLKKbjbG0JxlSHNWU9h1ffOV4WBccZDjAB0Rsk15a/otChRHTVC+t6Fw861tZ4+r+BDfTqaNS2v3ub9fvxyx4c3KaBjrVIpb2xYpQqjnnABFfkquPBMeWH3IdQ7rJLqs/VWXMNzzaxahYoWG3vXT1ksXZvr4WfOsyI7zkCScLHeJMPlfcj0TUPGSmn/lEW2/3/8cKBcw7Rr1Cvf5S9tVw8WSOpP66jhKIDz3JNxwcsOHvR+ky4qv3o4yICL6Be17AS47l7xezFUXkXdpFpdbRNsTFhlacB2vbYcslV/J8W3uk7xO7rXpq8iJ0ZFOmgX3qq0MQikRBA23ENp12i6vhNf2jbE4WRI6LpjulJGZ2ycQ3Lf0AMh9T5hz+qLPRjN2qKUbX6j8KVO8sQO+XUfgrp5N/gJsqtn2Fdm4g/rGVVK9RApd2tOeK+AQl+6SL9ht00HLE0YOsc7m5ci9AUrVbrKKpB6S5Tp8kzrg2rNRcMjDHl5rArmyWChfWWsnkHp3Fi88ResMJqtuwCBobKu6PDFC22cEZCBSHYqD/c3T9amssp16WrOtVvZq1dzZQ31zluVdelRT+59HsCVPm889UzUVe/Ac/X2Kk9HAynHXkJErl7dCFzhqhwRTWA3qKw7WUVtw5Xz7rl3mxlQi1d3voRGgLqJdVkb2qg1NwEVNIpOJhDjBN1RsqfQro1TfFzWKoUiE7HjGrMqwU7yWnneldIsGcKw97QUddRbs1hqTN1o5RrlvX0T75WOaV5kxXQhvOEJz6ybTnFZhN/1mS50mV+vtywaNQdFu/rd1E390g6vrKmZ+scb6GsejVfm1I35PES8JhR19Zc3Fn0XcTc0UUVypaEarn2VNhCFZhCg/j8tcu6nwKIGoF5VU7brhZhXc718W8NW+RT2EZbE31VyZI2yX0PgHsi3nrbxVHZca3/WmK7SRrv+3bZrENYr62+95tka9Cp9v5mPrtsYr/m9on8OCbyU76ew16tmB1HUQkNFO3VvMOAVwka5NrdaemeJfHWK9blW96bu2lOaGxf+CEIRVCHqb+OsR0BIpExz9Yn3QnxQqIwbO0OLIAgLxVGF2phdjd666YsCdvxXHEtR5qmnRmGWSQkz78dcdqH77uU9MdBQuewfNDePDQ9SEua3BroLm/pljq4vPWLAuKA+Y3lCbPXG6lEViRn3rlG8FMK8b/yqDhlSkiIYUe67FNZ19VdRlGeLlGsgSsvWZc2FxyysV6VTpOrZRahrIBmbxvsLgmocypf94Ale2CojSB+PNpRcL4PXvwarHkG9oJWTjrNFf8o7nwS4NMzVOavcmbve07YW8KwXV3ltXQVWKy/1RnvekmsHrg/0WmDX7qufIlpkbhJW8axrdgUTdTLLeAhZ96XnthhMF8EsZK2yOyI0zriu8hoE6L+uqnjyCZjFPoruiH33LFoWHljk1RDCXu+CbRnuCrrU+1kG6yTXkIilyghaAYOe7m9nuaDhjYEybnZSBY9nB63sGItwnFXUDWJVJqWhxcMubOGrCqp5reABIkX/pbl2jUXosbxbgfabTTc7N08KQJ+F1qr8nwx8DVS9hspNvdamYaO9tbbSQWluvLLIXX3dDFYZ2YSM0rN7CqqUmuJLmR0o40nX61iexlfWEmpA2nYXyV2nHzrfNSJ4qMr4ywE+NZK9Xt4xf6XJhvwqL53vhq47/52f1lODq1Tn1Qh4n4kXPdWrfDUjUAu6ymxXs8XMLRb6zXWMaAOWGHqNyBWWvm5RXdLGRK/Ob3zjG29QRk/0ZNW1LY5+RaoZNOVbXNtuYcqQpyAEYvHw+gYRlwEoOYzXkNF6AZinhqrMW5rUOLxUGLMqZwKD+dH++sP9vmtn6NC2p7E25lwAUKXob2jwPjb4yBwpzYqY8Yt60bSbkIqgn4xjkXR5RJ9Lf0Lpnl0z0JcqWc83GaAZKg1TNPusxq4gwO/lkZ7WixecMdWNfGhZD6k0oUDQ+clDMIYqNbREn4IvfICWDcGZM8bBQY/HWwxDAYOQELmvEQT0qmvW+GqzY2lIqca1npIxFaF/KSmbnbP1ABbMlu8qp9rRx/a3z/Xv9RgKfsv3+AqfmWMHC4pWvHo4SAd65HCtEQYqMtHhTtx6Ao2lFqF24XUVkOc7wecBeJUkArZd6P2Y0jERF+a5v+8FHjwciqfrA429+v3+bjgFEm2WTI/FrZDWRWxoaBmmTFJme6kUDba+GtAapytn8E7pM6bdjXuowpjNUT0mtDFebTQtWHiuIYIiTfSoMtGmg+qq9N3fvPXWg6YvGcu2s0ct+LsKs8Kt3wyHrDPvw9YvtKyRWTTe8Vf57BwX+Rkv2VjjXCVKIXf9hNHoPPa3emDtNxqon9dWOir2lAjfNcPLnAkPVj9o89pzDpJ7Vz5q6J9Q83rjVa7rGfxoTuzseNfbWzmu3JXuXYhfpF/jsUkha4Qr8zVi5av2xQKxOX91I9AFVkigKLcMgwHLtCbpnutWawS2GOs+zNpYY72AK1zRU+z3Jq8ixU7uFbtaMeOh09txx3pe6cmP3sYkJg6ZrLK2yUrYheKpR9CxGos6XnIJ1/X2fxmsirFMU6HZuis86vOiCoqXoUdLmT9F1pTQhuV4IIu+GFiLu7sQeR9hhR7J0BexX6littYkLAKArFCX/uooXVfoCkT6Ht7G7Bl847nr3fOhLi+Hx7+dnyLSKxT6rpM9IV17KLoepf6GUCuXDQ9V9tbQNQREzpb2u9YGIMrq8VvDuuWj9s1YG+IBtu7vo3FBXXnZHDFEBUDt247T88rWXUBRfbNzVTl8n+fQa0+ezRqS3o9fzcOGYP0us/Fkeet5tYXhKz16ocJZpVf3tMzJ+j0JZxWT3xsPb73qgSgOse6Cq+cQwlG/PUb62pTm17CHReIuCpZxPd9FRUKBgUuPPluE8eQBdOLK0OjXe9dQLA0rWFugwnotlO8xmXNiupO2XkTnTF/xhXly79Vr7WERmGeLMGVUoa/rPenVeJsZU6UlJFjF1bbRoGsMHcN9M0RF9urHe+dFVXnLuqJI8UONWPuvdN7ImXDcZoeVbosO68FsO2uUuz+knoz+NCNJHdC29hhfhgey71ohuTs6iFfru/nrUS/qvOsW4HncKzf6CpR0LB1rZaf9+2qOtamsaIehdW3Reo3sUwLLeu5PBqr/L7rfUJX7XEc3c3eRjdvT030Rr2oEasGuVPDqIfitzF/33L0W8hobXUS8iM3kMEY9CdOkLMEvVHTFjs8TXC8BcfbGeQWOCJZ7jLAmphuQarWrWCzgddPbS4i9huLJahdZbAxS252P3kMRlLZbtHvjupBYkb+84/av9TN60tYqHASioYaj682TvjWtuLHvHqZXJcLobtrc04Jb+a6JAZQKA1iDXoDRkJE+3f89IO/Q6XmLV3qGUJXRHrK2QGKRYD9d6yogUgdjw8Mq4KBUF+2rb9M4i3j9/XRGV42kD4VdndB2q5ih9R4jsRGB8tZT/5XSpbLzEq9vONmc//Ct19poRmV7gam2V1mvF+F595efaqzrZZQW1RHqKHCq/AqlWau0QPzq4SDIZFE21NbD5HyaGiiPfBUKopnUIrEnjwHx5C+fAu9RuSX+fUtHswh97tJ3vvOdN0rPzuBmlFTpN11xPZ9ORJVRUWVp1VK0tqj+pfoXKT55A/29aboEtvV7FtK3qN2YrE07EJs+N2XR3BSRFHGjhUP3XKvXgMYMUmPV/dTDYiA6ZyvAXfsw5hqWhm2WTpSetq5P1kqO93qiKsXVOViFvhko2pIN1Rx3ilofHKxo/J41z+UHdfsunUv3J0VVGjbkV57bJIP7/2jBSBpzacmL2/kyz004WY+iBoge0m51zcoSpbkgY5H6V7KuWTnt3OP5ZuOsDK5Cb996r/oa5ai+Wo9vQ3FPXmF5+soZgZuLV/cEEJ0QPymbtaiYBVJBxCqUMvRTlsMi4BLS5ghIDWH0QdpbN4Ad4ncAnJgyhoRAmjLIwDRjo+GMCncXj3cC1u1+KmWajvnpt/5eRup89b6ikV6v8mi2lrURZwrVEGLinrXD2O74VpAgfR7EhsaKqCtgK7xL21W6XZdYz6MbxepuK+YQ8KmxUo8QYucW3T0DBF09PWuqSlQf6jFXMcoGuja9f8CJnYyP8B2jRyk4OmJ55AmUoLcwlr0Z6OGergdS2Oarb/Lz3c/KvToq480Saiiq64XaJWdrAOqNeaZeyRV8/skgevNZz6pgaxX58mMBK9qu7K68Uu5PHk0Nb+n2ZGzd25NrXz0cVIupM42lXiFMLOe694tqm5VT90V9jRUX1XC3m6pXJveGKBt3inAxG8a6+p2lU9f6CkZiNJ7O/zFuk10aEBjt6uuiB9dbyhQd39M97/MQmtFTgbmCnpDu0Yh7WcRrbqoQ8YBY5IV7qogIPhrv+S7ua3ii6zqLeNpmQwOMcse7NDGmrt1U8RdwaL/ovkCBkawS5347UI6R4GnhH6GojTMbo3pdZ2i9jU84i0finkXJ+svT4KEWnLkHbzJYRc72PdQokwt7PxiNrg3g/WbPAQKd26aAV6+gEX6lH4SqqowLKOq5V5FqC83xw8cP4Z6CvIKeemiu79/4uTy63miVuWsFS2hafVkdWpkviLJuJTz56kZAoxsSqmDWU1AsbmEsu0jvfiEIddeteVrw014ZtYRtPNJmnSv3m/cDyAYqUiBoFgoh/12rgO6q+E1kXdf2tRP1NClPqOF99H8Jzff/1rVewEuMdGXz2s1nUUrnoimfjfvjEfV1UU8fqoB5IAS6woXOFO4TP67ha3ipSk9Bjwpe16w6p1XOlDEF5+VKzZJqGmaVCRo8HThYb6CLhTVq8r/7SsGi6a5JAUdF3Xjbc+bRc52TKvQi5xqAhnAYhIZBjaFehP7X06/H0Xr9XtDiZFv9Mn+KZzeE69NF7fLzx3PAX/mndVf/4RXfrbOhtwWnBSwtXYDu3C+/92/8s4ZcduNnLZ/ZCGgA4RYJF/Xp4KLfbtIpYiYk0FcJU9eriqdWvQR+N7AgjmvXqxVNWGOvG26oZb/r3Csf9Vex7vECRbVVuC8ZgzWGW568gkUw+9wq0z7Xuet8CYO0/43jV1FVuVaRQSRVmpueuPPc0Erjpet2r6DrQ41dFXwXJf0Pze/C2SqfzrUQjHEYk52afZFSMzmqgErjKpny7c6N8aqTcWnMHFjCh0ASVNqNmEXS2ujc8aJrLHZB3vhla1mvYEwZPPzjNN56IjUS3pvLwKExea8xuqKtHtJYUFEj9yRbBY8/mt3T9cpqIPFNZbd7mzqPNTAFhk8AbUPf1asL4laeyzfl17vulINX3yy2Fq9W+omRhXl2EacEVk//ZnAq/FX+GKCuo1Il7CMrqOEsjGtT2FO4pii+hqKumVJE6p72ye9lpBoN//eZ0vMJ8T8p8/UmMFE9uHVP3UOJWORX0Jggbj8qVIxh49mNzQqn4R0ZWg2dQVJdHC2fFJBUgEunIs7SrkLWOfN3la4CFePlxpLvXsrQ+pI2qwAoF4i4C/FdV9q9BMZypYClwKh1XIGYn0KRjGE3hHkXhrCPOUPvhnwLAIxLaMoc+hRhr6x7nueCP3xWKS+Q6m/qfELSC5QqW08ASSEvVc6Vn/V4qhcbCSnfrdytR9z7S78Fk+tZlMfwN533qkYAMdcYEMZ2pANsWKXGoiijxCYIfodCy5BdYC1z1CgVaZxrROGfhfThRj0ZqQrporperxC2VOmW2dZFfUK/ZdjS9qXrT8+4XuGCzox3Q3tXqkx2Q1AFA73r9vZQQPMktFCvDt3Eq5ttVOVVRd/QEx7yezcnla5VVOtR2OT1ZMjrLRin8bVtgt2FdPxU5dXYcI+INudVjOsBrICXF9G/IKVA5cqevVX0e3+jgRDTPX8hU6i8Ydaj2XkJQlpCVEXk9tdA9DyKhiuquPV5NyiWX6o3njLvupu9C75+N1crR+b3k1nD0ocqen1qmLR658mI1AiW95d/V790fCvLHVO9GPUo5ucLyQ7COI3PthONbRa16Hw7WzTr2qKQMgylcv8zLn17mPq0feUYWt6/hTqIilEownopzv+SMagX0tIJ2b7Vwrv3fd5AJ7/1oM8T2tp6ykTq6rUacwuMXST3Tuknb6B0oZBvHu3SLmq7Mff9DgSYoehZMvpTD2AVQOlQQ8DgmTceSEMM5dv1lEof42saJ+WjHXU2zKW/rhWVO4W2yuquN/RRJV10XQPSNQRKsF7Hxs/rmS2y18+rxyYtc/ZSKEKoqN7irtNYi+B9tO/qtX5088+TKdJHEwbX7+vN6UvThstDvVb6ffKQsVf5wCMFr+WTDdkwVp2TAj3fjWYUqCyde1/ns2GyAjuZj69+gJwBi6dWKItM6jYXyWCaIgcMsG+bKgJFsOYay1aqMLsPkbweUtyWAGISYSAKgoEoA1Rhr2KtcWh5QqSriNelbj3rzazyflJ0W7b+zt9TLNzc+e2EVrbPei1oXoalCPsWKQp3FQ6B6u7zLgpCOI17L9JtvffpQqa6oSVZX1e3l+Y8uemuoYMFV6mtFHoFsN7BKmchLYqnngzadJEYL653xTAKvYi7r7dUg1XkXeOBNn2FJiNZ+bmiL1A2I8dTvz06pV+V9vLZZspUZ1TRGzs5rOffOsxLebO834yhZgE+oewv562IlcMCA30uoDH3VeL1/J7k0phfCvNsQgGDg76V/859dZE+Njz2auGgDX90kqvkV3kV5VZhE/h6DQZTlEW4uzGmuzHbx7rGDkNjCHgC4mVF/mXIxn2f0MMu/K2HY6xVnE+unN9M/HodTx5T21uvpHSoa+25zoW2dj4bziBMpzCO3n2FnbkunW4ch/x5aTbneRF2Q3pVuFWARdxXrzWG5thLkSzaLVoVkjCG+1is3HnqPUu3Iqt6s0XmVzZvHa0p0HrNcunFa2tIG2oovdQlpKm+8hXFvEdLt4/mQb/wf1+VWh7CG0JDDeNdPXtKMLo6eqQ0hvTvc4ZYHQ37dDMZ3uvvBQzmkSdSdFzQhI7dENo5f5IJc27eK6sLCNfwtb7K3Mrb8lINd39TGs5SCsDL/wUEr+4JrDtzBRoqQYpQWUmD39DRMnwntcqtbnGFtYOuUTrl47RQxqBpfM337kKfaw0fVCk/KdR3xAw6XWRft7tj8ne/n5hxvYoyRGlRN7L9eIm5FMqVwTyFYZG4B38V9XdXYg23tghmz2si7D2DXvZV3yYmNMRgUwrQExRcBVLm7+Y+/LWIDZ1a13pdu0tUPebPIi869E1Y4uIW2r3CtP17EtaGUPFk+wekNBS2yL6yBUT1RUrXl4b90Kp1N/xa9Nk1GPJjrvXF89q/Yp0NDdGv/Io3GDPGonxljHRF5WBDNJ7BO5vu/PHUu145fl/ZoXSLvI1j+7n9698bsnoCdepuPxqmW95ZPfOqngAGbBbAu4qSQrjoEEH8r/ONq3WAVYKNwzX+iTiIWZfxFL53AWM8zN2F4J1U6HUnsoS/b6jI9SuNYW/pglzT8whdt4Jv26u86/ItmlmPa91EfWm/SnN/H+0sArrnaQyrMIvMrz6nO1YpGSNljm4yTMxXFT1lBcVSQg3LlM+ErLpwVkTf8aJ3kZr59CzU/oS8atR4HNoRhuJ9noEFLmSnNcmi/FTlsTwi3oxmxk8RQ/TQv3EBHfpkjhqGahKBsBMPUb/s4Ski5uGUFyj5XSvh8Vl7QC/tNSR4Y2l4Tx82tPgEDNczwCP1Sj6Zc5HwatF51zLU3ZDXeoorU3u9CrpyoRR0Vg+0nyvrfXaNyKt6AjpdQrThK41lYR73N+xjIA0HLBKjcHoCZa38Eh6KvMPhCFljtld6nZC2f4S4KIcrWZdtwy1lQH1/Q+CcnLnuZMNKVdgY6ImJrjCM9YDEPqv0i3jQed1W/aiRlzlFgRi/Rd1FhsZ2Ak1pEP4iHnWckbHmUO+gSt3cyjHfuKgFZfRYo9hrC0z0qQKzaBxIEQrDnzUO5RdrTOd93gGFPYp8gchmD9UAr7EvCCoIu1Nxb5cyhW39wempjIZxN8TZMdjAdTLDm8Ozfa2nFOu7x6tWq3zwHz5wau/1hxHVZj3xvv2O/F5Be2Gw+60b0ioH9X4aakXHyk6PK1+Q9KWEmiqLjRTUED8p/IK2zitl39/dX6+q/d06lBqQ8svKwHoJr7JjuETYAW4HEcrCHAIjdhdgF4XVE/DcKooKRi3zCaCMoJ4ZZFK5513kgkiMD3IjMHVhi0A8uzRYF7FeQpFHBXNRZmn75PJtdkjpV+W2TP0S6mw9DGdDA9D3lXpmG4rholMe6IlfqpzuU+SsT4xHEwjQq8LW12jWIK6HVH5dTwsdm7rZ36Q7LmIjtFff8dsp0TuU0CadCjsw1HmsAoL0Kz8dQzdiNcRRz1V4RR3ug3qbOokvimJPJngqlV1v0POcF/30lFEhPRsNr8gmI2eLsGuQ1acdXklfML/eHh7qURXkAW1WoXrWGog3CH46IdiGaco3i+Iro4vUzYf53TGvvLq+642rV8u//a1GAs991vK53jG8HTIJG7PyN4KVcYv2EIhyXysqplrhqetXAkAMMoK8BL4vprjityp5bT9txiF4FL7+NTbtU7Ta8Nha5lrtohr0WZS6CKIKYoWpaKbosXWu0XryDLj8dx8F4m8hg/Us8ILwiHDDKfpDxnc/9A/VNUTxUj4+BWO8bbc7eOudGUfpWv7t3PVvY6a4LX42EQH9LIDfPY4pwa92wQpLSUVuSKweaI1z+9nFwr5z9+qn3GtomiHl+Ai/M5r1MMyz+Zchx/tp2MdzG6PHX/iSLBao1Qv2t/a68Nr1myo361XCjT5NYrhv4ON96ZEMQdcDPw3YUFczHZ902fJTZWgVehMAXgr3NAxWw1SPrnxcL6h9Wp3yqvsEiliLci1K1QhgvMbxG7qoBe3CkkE85Tmz1GXA5uOeornfTtFA/DKCpIOWeAj4FLLSBk/CPVUgT4xACJ4Ye9HAlRogpYajKH/7XTTZv+8jHrtKzr1dbFym1g7aUgZ2hb7kZbRvlOPd45WDlL8QyX2885kA6hOUy2g3ZRDyQ2v3E+AKHWXQBcgNvzRE5+9rG+8xfO1bjaRnOs/1fP3f/qHzuvlPbn95ZpW3OQKqet8iTX9XCVcGK6O7SMvgoIt+UaSdP14cw1S90TZLf2ANvWvo6YGGgprOqU7zBmBUZldO7vt4749yoGRpVDDI+DXUvQYb3VcunxZz1VtjV0NQr3Blc68XTLbtz1M+18JwwzltuIqlyos13dSn1oeBKigV0iLCJXwVwRXu5H2aLWGSDz1RKD763wXhbihbpdG2r9SaG3ONysayyyC18H2+yuLp03FV0PvMlTLgk/Bt/6tsIO99YU/Xbp76U/fZ2LjdkJp5reCWee9vSM18UfZe7LICaZ4oo85RQ5Ltr356znwVeXumaanCJi8pbAa0/KMNvNz7oeai6SdA0GsUco+aRo+GaowJkGm4BG9KAmiabsNx0lK7f+KK/+tttM+Vhc5t9zCUb/EWveA0zBujjXX7qtMi7OoCQGwBlW/3f+2txyPc1JDjEwLHWwVDq3g7XjzeKEBBA0O58lTjXJldpb+ecX+vt/9qZwdVYRS5GxCm6X1llIY1ShAENYAufKq/7v4VmRGeEd7BkBAKZY9ByrR+Z+kdCFYBJQxQH2Z1T9EhBtvwWBFhle8akDJnafWE1IsgnhhhvbIrzTDpgmMRVRXqGc37nTCiYY2U+30fbRv3raHvBh40qtdXBXqloRjvmVWf34rSy1f9+z5i+/q5yqd0rTdXWjZHH037+sOGDiiVNfp9Fn26aayKqgKNnzqGU4w251VeNlWZ11UA18V3yRdF5QVP9XotJBv73WMzG7ozauS6fNHx4BPP8daFeswB74NXTnny7nr4IFmtsaoBWt74SjzJyu/K50tyCkB2LcpvG45ZT+RJlz4BxTV42/7nRf5/olNEi1br0izyqkLqQgsBWzd5US4GMpHqxRhlcu0RPiGgq19c2uahCh3j04XjK/tChicFW+atgJRZ+lwVtvJkENFw7+04fZdZ+puyTLy/L6OiIWY+gbzFTim3xuIl1p55ium33RoaBpgRbY63tqH28or5KrKBsMqT2quyZOgpQzxQNFnam+cuEHcT0y7yd89DF2E7J+XjxqFrAFfxrAEoKt0wq/EyJk2BBKBWoWjvPL2+9lMohVygdWlWr+nkZZ8BFHgCDGXDOsb6tFO5StJv2tQXaxxXlwVozwJ9QlLWHarDSuOvfe1rP7aHofKiX0Xr2i/P4N0NySywWr1Vb2h/qyw3avGk9OvBvCTzr5Id1MVOBNMBhCmDFdX6bAerKIrIe+0s/imfnitTpmk8smEe+wT2PBeKgfB10Uz4ag1XlUMZquiqk+33rg2Y0IYtOnFPrr8+P5W9rs7uBi3DP5UqQQYWQ6NP3yNbZSZ8UG+g6X4yN9QFbXpe++1H+aLK1/XSv88v6PB7PcECGAJYL7TGvv2qgTHOnsJ5/58ivXa8srTrA+SmCkZfX3LdnxBnwzVNmCjQotC8ztUCMS8XT0D/fkNz1+8jvRPCrtyTG7ymX83gEbIy900Y6AFnRdH19goqOt+8w0XFAMTSuJ5p+cvfX83az5N3yjOs4X6Sp8rdAubVd08Kv0a/PL3y/mQoem1B9asZAQqiMcP1DnaQGwZ5EkKKsl4AprMr9c4oaQii+eEY3mYcb3SCuKSeEaLm/ncn6vWpQrIofePWT5NWBthJq9GooVjE079fmsiXUL3n1phsv1uKPNHYYj+a1eMzvwywOegLaShtBoAht2i3YQljWOPJkC+d3ePZho0YrY55sz6K4htiVNYLWP5+Ch3iWUquKcd9nteA5hRH3+HwNFdF4V1T6AIxL0uKblNzGWAem41kZIOy7L6D7tytggMU8MaTd2PueAbXxtHEKzI7j1cAvAWPG+ar8uyRJkufAsXy764TfJrU8YaP21b79JIBaJ3VfZ2/6rsa+fJk1wjX6LrWfvfTfj3x9assDGPQbpS4UsTp3hYEwQw6STgbs2+o59CV1/ZVMLVRhpANA3nsgXHiyCahr5JsDvWVKhHjbj62+kpwfduxf1YLvWhgDcje80TrMiHmaf3bvzKpeeSNXSEQFmNLS3Olr83eQWPKgGLkvlewCwju03c7dJOQdhnjpXMzZfAWRax/Fcz2gXJEo6Lc8npTKYvgu9BZT+KJ3hXq8oxjDWqUd96qgNzXcarzeN8zvFphk46rCBnNuhh+z3ulZcNQnVexem1VedbIXZ/Q/2m9yljJGXlu5pH6rAd0XeMlD7o073xUpj5+MBauNyy5wLBjeAkgbmTEPWsw268n72H1RoFF+beGa9ckXmWfgIrL5Iu2lvhcTwPX+cZ9oaNO9IV/zgC0nVrtvjsVIRqq2IwgricmM2ldE1hU36yNppDpZxXHT0LeNSr+107LE1JoHVvWKLbOJySzfWppzHJPXmSIdwxVYm0LkqzXoLi3qZ+dG3OxGTbG23h4zyDqAu9mudhJW+GQlljDZIyLKJ92nGrXHOwio2sNCfoAHn5vksLORetq2BVPdzMb/pdNwwDfM+dR87CbMotuh6rNjU1h2tXfejuMs/WAHq9hjhoewh99C1/Dsfionh5dAfX39IAaMbSsMm2ocPWVez5NSEg6ccO0peui6/fJ03oG9UK6CP2E5t2/Ka6VDfKIpu1D6/hCN4shVBVqrVc7UyIiRr2CRbj328/93M/9mEWrBe1EEZzm83djUbOE1PUUtsHAFEAFs/H8ej2lQRHgopv+/cSMncA+85I7t/cpVRw1IBWCJ0OilGlOIBwytu0Ih6ySv7orzM1kwQdNF22f1hAXKZV/+pYtdda7Y4DqYdYYUrqdZzzVvQAVohpC/VF35xMQaeipSQd9vvyvDUcz1NjuwmH7h7/3xFT39R3PnquS7boYOgiRNgV26dFsGL832QI/eGufcE3nUd+qwLTJEHWB15xWiWqvsvAUUmxyyZP8fBJvtFGJ3uv+Goj3yWd1RO+th/CSPlgd17rWK6xnvPxYMPKqC8PtvM41W2bdmhKmv2MUg6iQnQdQxlS/b4KGkauwKXvHRlz9FrgcI+FkSkLXc+uXga40T74CXeTNcygaVfz95O6XQVqKErYsnZ/qKiO+z1NZ9FJ3+BT2hQOqLLquUmOqTqEGSLNrLD48rBpmdKpb25DHorAipY6zxx70HjHfZs5snHXHQtnt4jHlU89WOXo1VfRK0zi7aMtb6rsKSq9FnwBJBV6/vVsY/cmDEE9DYYx1x6TeypM+9lA3yrHnOfV48XpZndt6UMI5xtPMMrwGRDjFVp3Wq8ozKysFpsbUxe+VqU9HputplTZF8E9lUf3qlFXq7efKbgHchs/8XqPa/VgbXXg1I+BY4UVmRRLbySVYt97XaBCi+/Y2KsLcLAtMxR3l6t9OYS+OcVSE84PEM690QbgEK7OY7Crsnfwqsv6uv+sR7QSv+9ayCnPLU31PdZV5r7TNMljbW4V2185w3nlM3/jGN94pUcgT4xFs/ND9IhXAniHfUEXXhorceqRADXHd/rrIpV8VXnP+hSK0XbStvvVSuh7F2FNYC3pujAdiyEr7eO0cLV3nvVLUdrDWeygPFHzpd5X0/c1Tuv97wmhBAQVbz4NcdDPe1SGMVm+vSlx/ye4WoKLPXmlq7e4Q5g1cSLiIvKG07lfZCMPqInPY9YyWT2fHrmuNGtTbqSKv7FS2ew0dyEt5Qj/XYOzzL+mDpzGUJq9qBLprsMpGbKqoqG6JYkBNC1vhvc/FLU3akwtocUvc864fw0D7MoWgfu5y89Ofwlj+rmA3O6HW3STqt3F0QbWGYSd3y0tooKl/S8uXSuu60vlYL6TfawDaBm+pmSNPa0PQXzM2eu+ToalCfGLgeh0MyNKn3mGfrdJoe0X8S3vCr46255sCpHS10bx0tKBgAZS7BtkWRDnrqjywc8qoipF3Yb5GwHV/21Us/ZOBEvIzFjLp9Fie9O0XuWdkjAkblcZNNW3YjZfjU2V539b3eGj62FRtY/O8fQH1khatL/+/JCM/SlaT+ysnGwZ/MiC+l5/Usc+Y9xqT9cjLj22rxnI9i9bzeTyCz2wEnL/jRSLvc6vaQZ2ugFUhYRYCfvU3s6TuMZR5/3tZDDR11+5ZwsQonPCZ6H2pRTdgFGGVCXgFOxHLWFtHGfTJzdvyUn2L+Pu9DLJ9fJqn9r9Kt6hjXc4y0xrBhgivMLqQHu9v0VtpDe1ZjGz4RT/EibXdcAxE2cXdtnVF5tHG4tdbqkdol/Ldr76nF9tv3BZS5nUAIAxCF/TqDTzRufUWnHSeeo9wU9dHyA1v48Z1dUgRRZfuBSkNyErTpBvW6as8HeLIgwD6LtNv+bEprVeEfzxXOavhLF+SYf1YxVhd8mQQvvSwOdD1eoM1tk1mqBwWEK18Nc7/BIZqGNs2Hfi0mLyytGDufWDxj2UEuItcySq4xu1LeMRdF6wvDyG8DIBrDEOJDF1CKJiOgTrmw/B9kXfvfVo/ML6i7pfS2DoRywCdgCclsfE99Kv13t/a3t7Tfj1dN46XXMo1AHWFu3i5zNkQw6YP7hEGnu1xxF17KC3LQ43P9t7yQcMtzecHLDoXYs0ygho66Nk3G67oQmwR9v0P8esDPtL/jY03bnu8qU6KsN7Mk4ExZ7sLF9+SGWPSfjNJGIB6aGcY+rpVstmUV/Jx/0Pi+6IX3rfS/uhvZaMov8a/PNg3m3UO739hsIKv8py2upDf0NgTbb+SxIHeU1n0eWnhtbphAUf5u/L5JPs1KJudhx4LBFrPq6eIXuGKdlG0yBryKCEQS8fXzX5abMIc7i+SQbi+x9bnnhMOunIMdIbBInAXyxoeelLM/X6KIxpPXbeGmTrhy5wveQNPfXjyEEr7It2inf5GCbVezzwZkir8hiDcX3e2Mf6GxMS5zeuisYZZ8IeQQjNi0LFtMORdgO6YrjTWDt2WDxv+sJhacKMf5l+pkii9qgwpjxqu+5sX2wwctDn6Hgg6z7VAZIW7oKMvq2HohKrQj2Luscv3/4Vd7cG5NptIcffd/dY2rpCpi9PfC2O6YZOSN07netXDQSNK/X678TasgwfuPs/iu97Tdin1ymKNqPt5Lsvrn05WzoYhtVWj/ITgK6t4euWpbXbPSXmo/WYUzfHK9I6loc4nvfYqR0lfERvuyYUd5CqvXl/UTMkbrPS1JVoXnSB7nknfHVwL+du//dvv0I21DGfgdBNRCYug298dxxLfeMsorhV1NKe85aVrTwZjUYn7TP4q2fanQmA8hKgCVM+g7jfm9zdhbtiu3oQ5FbppDHy9qWZ+GY9jpsvwNVxdNCwPQLfdNcpgMWx4YnfwokHp8JRK2f4vsqxx6YvlGQJKzlHb5u2Ua5VpX05TF38N6BXjKOo1H11XMSfk5n4/4PT973//Xf+EZTZllrfOCzCugir3NcZfAwDM6Yvx62O9PTzt2YbkVo/INOJ9FJyWVo1adK4+fvBEy8uV5wWHBaxPOmXlt99d11r0/8Rf5rohotVTBaOv7glw9WxB14GXGlsGvqLjvv3Gtay19X3tIRThcZ9QkJ2m933Xy0RQhXDF9VeaXhVzDdBPQu1Piy51y57+7/Wf5A30udKvbS9DGcPTUQvNcFhEu24lhiawpxAsMj5lm1CSZeweg1DvwHjK7D0NlsFoKAHiqzFxDzpCjA2tbDiRokSb5rRXiEu3zpP+14toIgGF2//bh6594UnGwvzYFGWeu/ayaakb++Ux14j16AjhKwu44vyXXccrKd/c7+dJ39yf8r++WbMDBPp8Y+jX1x7LwmOrAX9aQyPX+MyHh9CXWGmHIsUDaLGhli4C77x+MsfboOXuE0LXyv/Kn36h0yrxp1Jwoc7OayMsRfvl29UHr24ETFRz4dcy1jCsRWxnxXC7WLhZR+43+VDRMdb9bScwr+BKQzMYp791Ea555GXgIuLW9xIiX1S499eV7dg+jwHZep9orlSBbbtFdaXBLqJSHNq7329h7xd+4Rfe/H2I9ZQBoaDEKR+0LzKmNIp8/MYTFAqU+WWPx313R3KPWGg66RX8IhPH7xRfFxj1xzyuB9gxrfCvcuk8dK0JHRqiaXgT8q8hBrLqCZRvaowoU3SE0imL8rJwKQMva45HIKzDi1Lf9eXm2wZOSt/ahFRTNOlhcjUoDe1R5jyGDU3ySHaufFP+5nsjB+hVD1lY88nIf/qgRBve7Jy33pWtKzVu+L1ro/rTOujDysZ6pDVG7be57fV6Na/6onlCf4IpjevJI1ghQrS1xF2Iu1IXR6rY3dezUOSpq4tBIXS1tpi4RwpU2XQdA6F7FIT7K+Qb623cbo1FwyYbA7zSejpxW9dLRmN/ezIO/TZ2ArQMxhsrMxkHD6sIDTMvHXvCpjFV2S8dCCeauGfXh572dtRQExIeAeRL6QEV3Txl/N3sVOO0Xpjfu0aybVdm7n9ZRqVLx9mwh763jgKOAqaCj1V86OneeodkR+qq0Jt5tUGwyBjibzirgPBKz+K60vdSm/PSe73Qhjca+qgnV8Dh3s5B+Rm9S8vuaNenL897jxtSqgwWcReZL09WWe+425c+v3Ld+9p271mAsIbps5bP9VIZ342/thProqyBWMavEC2h6nXc704zhNz7usj7H3LEWF6Essxc60yJ1ED0yFwCvUajBq+TUSRS1FAF2efXnUeXhgGUpVPbKtLrvFTZLIKtcaOsLAi6r/c2ZrvusbE3fNP+Q4G7eGrufMTQzXvHox/QX9GwOv1GUZlbMeseia1tc1XPr6i/46vCKd+sYa8Cunu7Sc7BhsKa0Hg3xjFYfmvYqAuy2nZdv9WvLvJYxdbD/DqnTdVtiIVRkdUkrFoPhPEpGDA3aLh6BEBbBVvgpJ7SuIrxiQ/rNVSv0Ak8nE8fdFVlzrXK/8pUn0e3ypb5Kt8/geZV6stvn/X785bPtSZgkJRC3+VpwGvJOtgOulb7SlEA5OGZCq3JqHK3LtCQDyVi0rtTr8je5FhneGIM/athaHFvGa5jJrhNiy1jrbdQ2rVPi+rbZmm3imvnr3RddEHYS4e+xW0RcvtXLwOt0Y5y2mwR87G0126zhdAZz+EZddUg3rXLZKkQrvHqmfRPRrn1VlB5eAxe49D34anWs+VNycK5/jMIjEFj9te36z/e1jag03moZ4bfC3I6x2QBPb1QZg1jdxvXg7cb38KxbDx7EGQ44eUa1Pt25AMjuMZ0PbRmPgEKBXMW+CsP672Z867lGM+Xk3VWXm199aKWnqVdjYL/jcGcVaaL3NfjaDv4b2W1/PhUz+riV/EEFi3Y2FH0/qRAnzprMO7rIpTJoDzVt5tqxCJ9CwFU8TeXu0yGERiMDYMU9etD32H8ZHGrVDvhhKdjr/LDoIvuNxWxNNuYdg1L56DMbB4877u/FfFAfOtmd/9ADWD7WM+NsmoYwv133f4Qz2qjZ8rUc4EctXu/PZ1UWyXfuW42WhW89ssrFfAahHrD+GyPPyi9KSzhye6zuCJsdfefYnXvGYK+50KhOBv/rwHAg1WQBVbWXTbkdfeeYWhWj09Ruj6q88n7rZyVbjXg+Bjd9l0QsoJWn5RvGYrOVcGAexvyKx9/Ogq2n8bWVza2vda3hqGGsAkK+t+6NxxbfUSOnuTVtc9jAD736yWL/ihkE7gWfBVeJ+/JopUYGO7+5lbLd9au+5tXbTI2pCI9tG5pCbtIswiuz0AyVxpmQJcimtKmgqmfBGrDHQpG9WwFa9G8vrrmPvR2vfUYbwWp9W8foTD3U7r33NNCZJVGx1elQtG0z/5f2mwKYtFvBWS9IPTfY0PQ5CXj2OtVMMBFeQyK129t9PRKISJn80gPdd3OXCEgefZ3/QzBpXCup1X03vU1AAMf1WDxrMiJZwEufFDPr8ZQHfWCoPF66DV+jeMv+GEE+zsQoV+8B9+VhRqwZpJ17hoarA7qfF+pkbyyxvwJ+C3yroe4em7DV73eultndVHregq7+n0N2xfyovla9cb4OoA3lc+BSYuOuteAwvNCcMxX96j1E2zohwLgOotP1yoiasfRWGqVyS7wEYzt73oGJX6VGOavAupk1SAWOT1N5LqDRSaLqDv2Zf4rRZh1f69U6PSd97eG7UoP9qtQ+593UOS3qBFzOwdqDeB9bzhK2/6vp3jtNtupHtfyZZVKUaT1pc7bysRuctPHzgeFacc8mpQPml+Ph7/+9a+/Ow6ihrJ8V4+LZ7tGkgfAGDd7rueCdb7Qotk/1gAK2Bbd18CjK49pQZh6noCQenvg36LoJh88yYE60Khy86VktN13sw3VQ7EzJn2+c77gbPlpf3uS5eqTleHqjBqQhv+eAOWrpoh2sKx4Y3RLfIMvc2zmQwdUhVOlDO3ugmERRdcACIt2HSRHOCt4mKRrDEU6JWizTaCpnqao3+sJtRRZlhn2nlr/0lNZw1jE4/cN0SzSrQEniBUWbn8XNh0ZsB6SsVTxKI5lKBKqQmpuffuPjj100GFoRcQdn7+LSlfx6BNlecX6A15riPCJ/qU7OjZLrfdXmeAXO3GbFuj/GhIA5+d//ud/jEc3PEtR1Uvxe9deeKjQOVnowvnR6047PQ+E53KZQby++wi1eWNYvYV75v53fhfDAeTp7/JOwRx+7OI1uceb68U9eXbmvCGUKtsvZ2G8gK1GogBAG0/ed3WfPq6Oq67Un85RwVPlqDqlbS3qr5x9IeEgnaccGwMtOuozFSS/9/+13v377uu59Pe/FFGx/wpPQ0U9D6Zovx7HoikM14VuwoSRlmFNZie9dVbhPzFQJ7hGgbC+dM8i/GUu6KZzp4/3EetHw0W1ctWr7CGkMlyFxVwyYg2HMa5CS537Hj29CrO8wAB0Ebj9WcEonRe1XdnUYfdUMahT+MkzraMhtw3VdA61Y11AWiaUKZSB56vw7wiH4/kLC+04Ga9NgHDWV8/jL3/Zb4PHi4gLrrpBU3/PKFQRX12bflsUTN660FzeqSe4Br0eI97p/ogFgeje+V6DXRp+PGnaMp/okOok+qF9Vpo9t4bF7+1bs6JWJ3aBusB5DcAalJfG9WrhoLU4lLIFtgqDSUK4Dc2USCazpZ6AdoocXZOdgOm6NZ37WeXfhakn41VmpCShtSW0eKqJwOAtZdB1/TqBvaatdfH2ns5Fsx6Mpwapc1OGrtIqOqugGqsxFkl13hcxFVW1L+jb9s3XKri7n5KTpaSNJ/6sIVnXv2Pym9/RTcZbn6vnp1397uL19qvKoABCnNvvFlgpYUoIv7rv3umA59vvhtcYmNJvEXHXsmT7XLuyfBzXrkjWsDO/4zcOyvO+yWrnQkin0YD1iIt6pYFXh5S3gImGkrpOU+BXA1DD9aSfruA1c7DewCZj+BSoPQEl5YnP/V8Ptm0CHvq5a3iMYY3JU5ThT+wJqHRXzFdJrRuEURuSKQJbBVXl2LBP0X/fEXDu592/mUAbG/VsjcCVHrpV1Ky/RdFP6LHPbTigyqnjXMYo06xh2L9rPJV1d4uqyizbh46xbR1CZOAdN9z6n4xa+WEzwdCT8sEjVQClUwXUWkIzilr3KtvyFeGQi68vDY24/8bYRev1lDrP+ih0qL9PYZoqDr/xxHi7eJV3XeFGBzuMv/3tb7/jwR2HuSyfaqeecul4958y77ELwrzCRPWEpIh669d9V66AsvJ8+US/dh2nSN/1zlvDVZ6pB95UzvVKjbeGYJX1x7MuyPj1bXTl2QVUu75GHhj38lLnrF5RaVQQtvNbmSvP/3HK51oTqPJHnJ7sue6PzlegG3p5cpkXkWJEjCWn+uq64wsuVmo3412Tp3zPExoTUOTVXPO7V0hCWOlpAhpb7m9FIIvMqvBXwW+8sGWRxEvGoSioNGwpPXdM+lvjaxxHn0sXbCquzUCEsC63erqWwnD6Hw2dR1Sljx7mpczdxeAagQKMhj7MubZrjBe1Way90qyXGs0uQKJNS5X80rEGr8qgL1TpWoF4+hq++/0WiY8/74BE9NG30rGJEz2oboGZj74wuo7mMGfW2ZpFdB+HMgpvlLbaWJTK2AEElR3vIeD91WPDWz0Actc/jKcKuqHhhhIrA59MaMc4ABAf9XiuslRF3Toq45XlRhfWg5Qi3X4VKBWMPemHJz3wKpvFKthvHk76n07WUJTYa62a/dM6e4+BUP5Q/wmK80u8EOOUlddJMgCYs29PUj9C17tgKAhcM4+Mr5a+Cm89mCLMCmbDR0q9qfUQFvWvUWh80T1FPqWj7w1fqK/CyiV27ejuBMmmjbbP+kqhQXF95wAaE3Zoq4ipsesyelEfHtImw6Rv6HL9df6Q+goIzHdj8UXN6EAZrjB3XhYAmYt6JZskYbEdDZsZ19egNuTCIDsHaPuk3dKwSoOir+IXovK/ncE1CIyUNSPK3Fi6Rrggw7zVKFS+r/CqGvZt3xlr13kSNthVtvC4ebQe1TTu9QY+fcjsu3q0uUp7w0KtYz2CXZ8qaKoH+KTMN+Fk53PbXB3yqi+VKYG74aexK9/tdJ8rIlhlXwIVhd3fl6lw395a1LeEQSUY+K7blbkZFZRFc6er/Bqy0p9a/BLcc52UMhUj2fF2QosQjXNRwZOnsExkQfulw/2qRLbPT0zq+SpFu0G9Wc7rRhnaGvJ6TN5yVSTWTAiGtPSqUu9Y/V1jXcVqrjr2xqfNofGZY4pCbjr0p08UXmlbHnjif235uwpj57BKFg/qW70uvHMe8B3m993vfvfHYsMvZa0saDO3FtpLr+bnU+7KtfGDH/zgjfddvrlMImO0RmCcTR1Vx8r28iS0XxmVJAA0iA4c+PM/L7Uy1v0l9RBKoy/NemflguHqqcSl65NBKwheMLPyVs/F9dUjnYfyTa+57/MagDd88VlvbOpVF/W6UWUbf3K9O/CGTZ4GLlxgYu2i1P613TNa7tPTJ2stOymIvhuQGh5yjcFr1kUnej2hTi4F2fBIDeSi8qXBE7IsbTsvlMVmqzx5KU/fNcLqJ1Q3D9/85jffZKh0fjxbZqd0SwPM70x9rxoszzSmWj4xXzVI9QAq3OW5joG3J1umxogyuSL+3X5dvQxe6Xx1O5d/aahsCAo/XKnyNqYqsMpEC7Bjrn7rt37rnUfRsESNT5F+92rcPT0LCEiSGmqsB7xsVrt7753D1op61DvvpC+KqQ5oKIlSr4GocTcnxiXJo/sZhIHLh+Xhu1Z+VN+GM780XvuTEeAN7M7/nZ/19tS78lWFTXYUfShILIBuqFR58gq23lfdJ2AAjZPqxIZ1qgQqBEs89yN4haVI0Y5dpx/e9zFClbQwQF16Ata9BkXqdZ+v9CyhpgQWvZYZGkvWjyr/Haexltlav08ZYpmp7a3b2vlaz0E7bbNhpdLg6P0rv/IrH/3yL//yj8Xweyb9Zjs0c0Z9QhiE2Dzquzkuaru2etBX6fP0Mpgr+BEyvL+FCu161ndhqk0h7qJd0RaF0ZDE0eTqXoFfhbJzt57Bld2fcv/3VY88MrTBs6eUO8dCTN1fgc7WHE6x96wiHhC+QJszBtfmGYauQZxRuLeTCRcZ754kQHFVoQlrUeTo1EP0Crb6DgHz0TUcYyTf2rHJT7/qDbfPn76A6tEMbe3ipouqL8hjZUw9lfXyeg3CPqfPxtw53D4uAKk3/IUcILfItYi0RqFlBdjfjRuqo2+icm8VeF8iY5G4FrAZQZRVU0MXFSN2X8FXRq5SxZgbazXRNSruWc+h92OOoureUzd9aVr3kWA0x3ufl91RoezcdB6Uq1usnDFt+KCoqPsmtGO9Rt36VoPQ7JelUc8DwlubR18eq7IFBNpv70DoGVSlPSPnGUZIn5v94VlGpUbVfK3xZoQ2FFIDgYc6p+qEsK9QzPpwIRn18VKsH+h3wy49j4gc83iK5M21zW2AF0/7+iHFVF/IW0N/uxOaAb1nitbRDVonw5TfeRrOmiKj6vR8F4J7aOPKEyDyo4dEgOUtPNpMueq0Vezb5vLpKu2V/36MbftTkFGP8vOWz7VPoKivRC8qLVEIYb2DHazJ2ljsWrGN6SK2uKYQkIXIDeXUOIi77jpHJ6cW90oRWpF2x1F6tN9VHi/dv4apbmANb2mzLjcmKKOXkSDLraf/95pQkLi+dgg6JKm9u1YPoULHOFAK5qN9bvvlL9/mtAqgoY3l1x4F0Oe77vOEoJ4Eqka3yh0P1VtcHt/Q1Y67gKHhvfap3sB928lrXu//733vez+GpvWDouSF7UZK/T/lXnkkK57V1/vt1gZk4VGOjGiPorh+ecGPcZAlu+/xQw0S/rCAXdqSXTTquU1orZ2Cw3omlbGfeusVdKG5sorO7gEU0dY9TX2vnioI3mvlZ5+GfOrhrcy2fXy2YaJXf8ewBatFsZj4KRa2xKhBMAjo37UOqCi6JzBCOTVKq5gR85QYVKtsn2vNId9mKuwEtI4nz2cV4FPxXJUPISzN0LTt1YNoiKNGqnTeN7TtnLR9z9w6wC/+4i++m58anLrlVYZS/9bY+DTU9xQ67ByWwUtTfPGScFRw6m02q6Te2qL7Hh/RuaYIyucUprE/zXvRrTHVI5D7XvTdzXMd/xq5e9Zu3Esb7QuYuo7SNusBdD/EtXdASqimGTc8vfvfmg5FvqEk/UMLyQTlUQamR7qU9/Xbxjg8Xrrx0rvO0/EKa2mvMts5/5m349FGQ9B4sWs11Q/qWtDYNgrKytcbMdgQc0NobadecxNfnvju1d8s1sHWamsQUuEKrhUsGqoVrgfg3rquG+OqsiwBGAfGgqK6ST5m6otmNqxTg+P/RaUmfhWEOp6sdJluvQTX+218Rb2r/EpPbWN0aN+992koqJ7ZS8fb3vctAv/Nv/k3f+z9v01ZLHJSFwPQtRj9KmJsu6vkdq7Nc8MIHf9TKA0N/U/AhTxqIGqI2s8u0u78VIjFq3mkXZgvmoaOu/ipb92MxeNqSLQC/rSZCBI+PvfOgsbHjcNiq+fwJ37hFfTVnPdtHYGnp5/3t70jF47qXFfp81zw8K4VlSf7zCrazgd61TtZI1RvQNipYFFSwB++NUTWTBo23ULP0E/VRevxlyef6uo89r4nndln9MG4FqgumHrV7KAyd4Wwu0DrHjUOXMSp9CAq96ufMHYhWXuY876P8bvFvMxfAcAgXMkamArLZvK0/+4pslpm6ThfUmpVfmvl1bHoF22fXETMzgBeaTqjzJhlxDIShHHPXQriX/yLf/HNgqO00G4W6zEhjUtWcBsaMle7sbD9r+JtHLzo6Yrfn2i0/LphtQ1x8GJ6nDHehrJrYNfwoCvjy1j5rVlIeKG8UfRbo1DF6LdFikIvNd7aubAQj4DCQo8DQxQgOvEGKFb8c9cgca969aE4GyK1plDw03koMEHDhm8aojUfwkzoat70131ork380+vGV3n+ZPREN5IWqGinXhber6HRXsfVPlbR799V2tU9vVY982Qk2s7KxKtkB1WhQQg7EGsBRS11x1w7prpPLf1+70C64FtlYxKgUM+ZWOivrxbcvQRL4E5uUe2i1lrhpdeV9XA2BHKl1xozrqtYhfFu8t4qpq6pnMKW02wBCzKv90IY2lehtssEunt//dd//U1O+K/+6q++uX4KQSbMvpVLHZS7M3igVItw5YV6ElV4T+i36JXRKApkQDo/Gx6oga7xazudi/LdKq2OlaJ1tpEQ5K5z6Utd+vZZW/q+QMg8drxoqE+H4inSIt/tB2XdzB8GFl+RbWs/leFm15RunS900Pd6ovUIq8ztD6hxumf6atDdGFZeMVa/9wTcPXywivYP/uAP3iWb2BBHJlZe0e9pR+8qXnO8PLA6o/y3e332d/xCT9QDWj32hS0MbwbDk+tRY1GC6ywmKrPVmrYOTCO2X9R6H4fI8QZuguoS9wC4K+sqG0eVPWOCmGuVFyW01PvYCXkpnFMmhkTK3FV+FRr3Q0yEpRuOrtg1fffXUJpbytlubDRpHBfd9WnXYdqnjqfufr1Jz3uO4qMYnhBwhVifn+LRXTcoHZpKvEpEX3g0NXKr7NTbrJLSE3JGM/VCu+rwe3cjW7zd8F0Rvf7cvbzh+9waDoAmfKeOpkY33Nr3DdtLgI95O2gHwDHylS1z0/BTZayeM49yve56Nhtd8Lu+op2Fa3XXaK/38DTnnybkTDeU1jV2T+i+xqRrCVX+azA3jLT8QAcZT43Ahqq3nfbt1T0BhG7n/f1k3ZZwfneE7rpFJSplBZ1YaJSVgqEtQvr9iHQG4LIXFsETCPXW+NQYPLl/NVJPyntp1Xp6X+t7svTG0L+rdBmBLvJaoGs4xQFflPhm+Rg/JXLtXN63OcbUP/dzP/fmvJoTovv97hX+EAq8or5m/VwpaoOWi8qNi5Cqp2HAGpwK3BrnehIEa93tKuY+98TrOwdtvwq/wIHipFD1oRko7q/C2Lxzyq2GyFib0ozWlD4P8GTgvELeYMOem0OPn8q75gs/+BuvNZym/X01JJnqoXB4mMyKJnQBl1LHY1V4djozCIwWUIr2lbUrQEV5B598/NZ7aDrwym/luPRpWzXWjVaUj1tPebO0r6LfcPSTPi146vUvxAjoJGSBaLWWaxAMAjNd6UYhROn9qwAgfkyLybm+Vep3311vTPYKL6JZEBWKurMVRv0v+sJML4WC2velXX/fsWOMq5dS9IKOjtG9zd8/YRK/x4SNYxPexuIx/v3f4wIw1S7eSUvU765TuK/x3qK3In0oelF16bx54677v+Eg48OXHcMalnpwlChjWo9hY/kdT5V7+6etnjq5XoprBR7kpnNVQ1iZIANFwpSw3y6E5977vZ4yWQKayCVgtmE1YVu8ZK2hYa3jiwspdZ4KshoKbMxdeLGyInyjSDO9DwDC461XiIcbvikvruwVPHzyySc/1i7eX7mtAXgCBwVP1RcL/mpM6vXswvKT7niSuwU17vus5Y+1Y5jyL7MjCGF+GnDTxRrvfqp/0TrFbS8AJib8QhyQ7m7/J3CMQSfmiWCEtEhk+1srveN8MgJPnkF/b+wSs1O8XO/mU9czofwaHsEs3NtD8lDcPXtCdYvAlEMXN83ljfdoJo1xd14SeMXcFsE2bFLh6n6DHkRmvtY7LP0sXPq7/Wjq8JXG0BvSLDp/4lUK+wrAAKE2HRS/WTfRZuPsxlUF11h/s67QprxoLik+c0hJ9nTXesl37Rb4HadCPvCxcI+NW+anfLhjhsavnPLv+p55K/pvqET9+K0HCF5b6kMbbR2fHr+i85NyRFPP8oxqsLRV7+Irb3ew87KudFPkS/L79KkHoO0nvqoHWflt1lfBqft3vaB1tH33vPqOYY3U/dB5DFxlsoxe96nMvciCIqH8bzIP3R8jC2n0WICiTOj4FJvjb018x7GuV1FjmXeNRFFCkUB/3wlYF22fqYBf/4/ZiwQJkHspvCqfhmDQA3Nff4WDrq6e+XIKxHHcZaaieMirmSa7MNd+bh31DLogal7MY8MJNSZPNN35KQip0mm6qjoaRikPlsdrYJrFRhDrAVPIxtTTVfWvgKbecb2NBR7oZr4tBGuviqK8cv8fD1XR3TqPXb6rBClt/eo8SB/VVx7H3c/7JDfdlNcTaPXfWPuKyXqj98z12zHj5TXvLehLhda4mOfKOvDU+SnPfvWrX31Tb3m48+T+KvLyX8Pa+rPKvR58i98LWJ6AafvW/8u3HddLwPZVjAB0gkkbD9PJdZG7iAl9dTIaOuqi5113LASk2iMjMJWYI4TPY1C/EIh+F21WcXYCniZhiVqF17LM1FKjUWNYpX1/F0HI8IDoKQlto2lzzY+pCToGZ0Dvb8iNUHqG0uuux0Nmt2eAYOtrjWuV2pUqshom16tMIeUqX79B081kulKgUeXe57W9bnJDHkVPjX3jqwUoVyBufXSf+RHbrneysfIFJK7pi+yuhsAagl2lf5/GvJuVpQ5rFNqB5PFNvbsrzeW/cnzgulz6enRnZICMgoS+BEYMv2Gue/bWnQ7p1+h2p7AU0Xq5BQqVXfxX+lX++w0kfTneWT17zy44XF1RHuxvnedeX9BhPB1TjcPeawz62N+2/i/kfQIrdFyoxizX4hIYCLfErnIw6YQLmseQPT76PvfbubrdHNUUM0jjnpE5REnUZSthl6hKBao0eDIONW5V+p7jYvN0TCb3XchG/b2nsW7Ce99SQ70bmDt/v1tIF2IS1iCwhIEw83RuviCzKllC0Zh0jb3+ukd7T/Qy7xR9w0AV1gp4EX/npx4pZYp+nfcKCaNQgd0Mj3oXV4fTa68wjO1HQZIx1zNewSdDDQVUNtTbPjGS62nhBXSE4s/bMxe7h0BigH43FRXfVTnjM7ua7yRTx0lfqZy4HyBjgPBdlV49HF6Be8xvF13NmWvmbte00KxzzwP4yry0Bs3KTztf+/cagq4dVpdUJ1jnc1+vr8e4yh4v4WtgqWXB6autCeiwSXnKpCjxqxiaaVDrtjF2E6ktC7hcurv/rl32T5UNl0t/MGK35G+8TR8a3tk1ilphysU4/b9uaCevNEM3CpdQiDdrn/BgyLbZgvnNBeHcOTPeQ3OY765xry3uCR0JH/W8+SqcpvsZ385jFW9DO0XgBM3HXDRevWhKfeopimt4qErDsQpVjEWQPW2zNNOeZxnvLsZr171FyKuk12Poexasc2m3cfcaxSZIeB8wAHHPUrqOudZX7ye+V1P+5m/+5ptvRzEDaJ2vhgD1HYjghVE++0pXcnm/A1/r3fAsr86T5Su3ZtVUZ95LZakgiD5Aw4IkwKTJKzVu3afwpReyvd4XDXgKwzSq8VKko7pi66wOWQNTXVCFXwNUnu33q+4TaKdXke41E9WBbGerJDGW2OINmrIUAjqG9fawEoEQIXBDCjUuV+oitk+ud9IW+ZfIVXoU4pPSazusNgZv2KX9c/yAths/b3jk7jtXusajk18FzgNwHRKrUTYPdmI7dbMvW2kMuwi9Ruy+hZee5vtKvYQyK+RnUc94uphfAVGvD4VPWBi9LlQuT5Zvi9QbDihNzdmTArHQunNq7iFi84u+95y9LWjAM9Sfbmx0neHg/fJ8ZYl5+5gEg3sZzYX37v5D8Fd4npQvpN54OX4zDrxjl3BDd816kuXGe6K8GUghHt6gIyrwunHVGFdGOz/LR+rAb80Aqvy2PIGOBYL9+8lY1FOpd3ulQOhJh26pUVP/PlOQ2YXjz1o+19lBdbuqcFYoDfbHGpoTG2sdq0hN/DEvF/Su9xRLz3Oh6xIVDTSMYjG52TVFo1zejql9dY3SMtnQUhH7lRqkXdHvOOu9lGFOIUBbNcAQTXfkoq3jmQmXfkCI2tLnq4OQCaXVaHTnd98YRYg33or2+lqBX7SE7gSm81oPsuHFK2jWNFDtMkwU/4YltYsfzXnncw1L57RHLRR9r2Ji4LVH2Tdc5b6ie16JMcujp5DRsvxfOjV0oD+Mes/k/6Vf+qWPfu3Xfu2dl41mlLkx1eBWodfT64mk7R/es/7E6xG2rOK34Hyeqv52vbG6p/K6irxKn3fpt65TqLMe9icTvi3Qaxur15belYXluQU8C9qMd7OKnnQR2eq95qYG5ws5O6gxt7U2iLouze48de8KWkM6mPx+u0WjYyJICdKg/C3G1VXEDF1c6b6AnYQntLoThIka8/XBdAS5oadOmDHW+ykTdmxVmutZdFH86NNzee73Zns0e6hpkVILKbPNcqG4jL8M9oTiNy6pL7uAvoChxr5M3gXE0gU/LqJXZ2P6Hc+isM59ea7e0bVzmWn4lwGukqqbb66KQMvvG24EIK40lbY8677l06ZzNiHCvOzuWqGso/UZgVtP+853vvMONOh3ES6le4X8WRswvo3nMygFEWh2yt46E6UF0Fg43jWYGumNn1dRr+w2ElCwoo818B8/AI4Cvhpuv7Xd8syToTCvXWwvWHjSp5UVumCz+DZU3GhE1ztebU2gZ3gvceoSl4nfNBLUttathmOZD3GPSc6FlSnUSbVgXMNT95vg1+is8n9C6rWsJToGV7rgVNe89OkiaplPuAZqLWNtDH6Nlz7pSwWd0pBWZ7FYHcZ7/zfTo+EE93WvQhVS5xzdd957vXOMJyo8G3rTJzRB0xqh5bvl1yrmhuiqrPSnmT7t94b9/E4WVskXiKxntEZyZcn8FSCY4+VFyuPq6PEQBR1XGgKpx3Xz/Jf+0l96I08XFro6vKylgK3ygG94j1WaeIN3rG/GfSjfegWlv4v72kST/vYUWq5BXL5o+K1z3jl5ScF//AL69tuTh9DvgqUa6TWwaMeY1eg86VZ1PS0CV7do6wvJDlpruohukWIVzxOxqnTLaJ4hUBaX7Eq8F2xDsI3lq7vnrlzh9q+h6P8YuO9vNUFVJBadIVPPbiyurlkXP7uwtxZ90YUMkJ7SStF0EVNoqWjQ2Sz38QYqv90CnP0XNRinBFy7vjSUsGMUYrMw2X5XOOtJLWJXV+PsVcz9G7JZpVtkVYHHD+sFdI7qodSIFZjUsOLpKkPPWMdZRNYMEDyt7Q3h3LcUyIIAY0crsX4LssbWY1bU41rj8eq6ubvTYu0obnhLHRSY/vF6i0wZT2sIXXNCD78BSw0Vbdoruhc8Lup/Mv4UfGWj9xc4FCxeeVK4y6sv8VmvP8nzegY10n6v4l8v+EqNfu/duhtyfOr7q+wY1unteNOp3G8yGi8vit0QUAXSxBO6+4Z4bIQRxyZg6qrCpwzqYhbpQ/YUbc8rIXRQokW/9S4odQLb/7V93z0krEao9bTUwLXPBLZb58V3ZVpcXWcsz+1H33P/7z4eQhfn9E8b3XVqrBtDbUz4qf+dy4aPtq4KTIWq4ZEeVNb2y1cVjE0SaFZSf1thXBDTMQiFVtAXfVdGrv8WRIVi2lfztCCm8tUwbPcCMEx3T4/8kERR/jC3V5p1c22eEbjv3/iN3/gxIwXR62MNARCkT0WyeKYGC/hxQicPyOa1q+dkumHV0r9zbN4XXHq295XfqhDrEXzysK7QNlf/7Wf7sTzc58s3XUdsxEK/y9vGt+HS0qF6bXnsVbOD1j2ry1t3ezu4C39rCKqcoXb/N/bvLUo2C13u89Vxiq97BfSz7iqmXAsO5dpdXELfs67r/6JJE0R4xOnL0FWSu65QxbGGVh+qwJp+t8zinb7Q+cWy72x5AsajujrOIBBI1y0YyxCxR0O9XFF94NYb2yL/K+UBvFLFW68SYt1FwSL6Kt41MGt4O0+l3QrSU6iwSllKbNMftVlj1kXR8nZTpkuLestVSpRxjeA+h+e0K/5/pYcqqkvd15cu8t+1Sx+9uo9f3AvsuM94hQgLbmSe8c57DAXeq+5o2iZ+6s7uzkuV2UvKfb1odFf/k7IuH378EM0o8GlbjTCsfvHNe2opvxY4tH/lS7Sovui9bQu/Vk+tvn4VI1B3eBVVmX+tbjvYDldINpzQia7yvDAGQlJOV06ZYSTuN0Si39xj6wddtCLkV/r2rCIf/Wzoogq6E60ubRVxrxelr62znkaVq7+bLVJGhtaaGnp/yyA6pV5UumGt+/3uu4XmM7Ab26UEpB3eta6PbHkyDP00zIKOS4uiTuNUVw2D+zbWXB7qfPnd3CwtfVf46z2+EZ6guSdD0jUJHmplqQK9ctK9E/VazEH72A1r5ry0c73HKZMpqP1Cht///vff8Ir9CX1Ju7BPUzprFC+UeNfJHLmqB9ETZ7XhGvlFH573egZdc+m1KuuGW3du0axK9+OH0NF6iAtua6jqoVavNWFAv8qvT+2ujq0RwCP67LcCA/cUeL+qEXj6W6NVlh2Q+zFdBWUJUYvt/91cQ+hkE9iqbuOOV+NtaELKY4W2B3dV8BofrYALFXUtYsMKvV5mq3CuUNc7qiLYUIH+EcK9fs9QCPc5ZW6DGCHjRTWT6crGua+N24PAO7hnznu4naHNXqIY1mNRNlxTd7ihiu6ZKP2qaNBXeaIjPqsH4VMDU+Xe8MoiyjUADX90zppFhR41eEuT8pHfelRDBb11WCdaFKhtWV9FowVw+ED9RfOH2q23XbkxmJu2r048fQr9vIn77TxPnuP1iyxZoL5vcqwNdd23o6E9X37cUG15YHXGyubqGfPw8Qs7fju3NeRtk4y2zW1L3X1+/zaXjYQwgPhJPd2D0jWyDWutgXm1cFCJp2EDLCFrlXRoDUeJoECl/Sa8zhHq4XE9Gvnul352zHKMeAqLW4v59KWby5pPXHRb9w1zVCDqDTwhjoYoSscNn1X57IKvtqr8CYONPM1Y6kIu5X00OVrcvUIB2iBsNgtdaO2Uvbm9nHIZHc4e0haaNISBRlVeeKH809AF+pUe5ZMq+SLZ8qH+tE/1pHiDlErnqMari/AbZiovdI7UY16FVCrI7q+xK4qswsKf979382prPZ4aeGgbvxdIVE4Zce0wYuf9nbzcC+trgD3ftE/HtV/WHiNScLFG+9JLe+5/M7Eayih46xwbR8OFftu6qryrgKvYS/+Px4C8pLiXP6t7XjIALwGK1Z/7UfeGjzec+qTs1zC+qhHYsI1OVeF3cmplX0JZnnlihipd9/ufMB7SJYB3vQd4XfjIK+Max27YCKN1N2YXmfRZ3zquVVZNzVqDWOVeZi9Dud466k0RcIvjlP2TGy0b4/7uQt0yqWeqrBwLfArCaxKN3X37ukJ1GW/HVUQnjCA01fABOq8R3IWzbVM7raPeYI3AotmGxNpvRrTt1ZihCYMojOIehnsN/crGhgDNR8NV5Q9tL3r03NKAbPBCGRB13t8HEO6e45dvfvObb5650JDNg5R7gQoeuWsHHL71rW+9W0u4e7tuoL/1tuphG2tPIe0mNOsxxshTWKO8Sq9Kub93jeJL7zlsbfly56FjYgjqgZSfXase2XZqaHodz64xL2/XG2wdr75juJ16cqMgD50hVJBbJ6lCewWa2QF00F0Au2+ewZVm+Ah53N/HzBaUu7DiBRQU/zJ6x1TlXqEtKnhitnoMHYvFZkKIPlVO2tpsFMrsjN+Fa278h8oILIGpd9OF886F8d7HC3rah3vu2utOZK+fvGcaeqryrgteOm1807W2aT6KKOstlIeKmtB3kXrbfZqfho2u1IPZ0EyFv7zw5MksQMBL/meo67ncdcoaSu85WHdvDRkEb2G28fDusMfTQqarVMiBrDEx+AsN7THM6NsX45zn6HRRxrNhOrJl/voWr8pZ1+W6T8JJuu7pzn+fppOq8wnVV46qOD+evSw7h/UGVy91v49rNTi+GwquIWySx5MXUu/I8/ja79vf6qRXTxE1yOYA63gF0O9FceK1K8g7Ec3iwKhQ1iFgcX+onkDdNacZ1oswORi0Srf51D1qQJ8oaoJVRqkh20nv2Lr4uq6o97B2/K2z8T/1e8tSjxLwsfjncLhr9/otY4NyceaL/knXu4/DxHhRXvTRkMrNwf1/1x01XV5Y9OujvSfPqjQvTf2trqeMmQUd5ql1lM4U35Wts55lhbhKpOsi14cey9D2lCr9AiP81uwr/FZPp14QJGs+moEmTLpZZDeP5RP7YYRxxO7xyXkE9/zF+OuRraFv2uoVoVpJBujpSAgbxsx/98946X29mA0t1mvtgnD5AL8sgCpv7pwqu6BaQ7MIvIq3nknL6sgi9+V79/neazXyvafex4a3vpCF4bWiT1byKd7ZmF7RSRFDiWiARTqn4Cli17tIe7+r72KQu/BmEqEYbucVyIgg1jU1HgsxCN5489Pk+/S+0qYI+InRKiilEwXW4zL0D303PutZ6av3aRph11hWyXDz79u58ub0DIU9B1e063dtU4Adf2O+i9QWBFRBV+nUaBRN6eMCjrZdBd9F1goXHq0irJFyT+ffnHU+6y3hwYb3OsbuiWgmEF5qv54yZ3aNY5XjFWf43P++Aab7W2jofnPQ3KL3jgvQuLabOsyjvN+8HUzWUenOCAIW5VvrYcb5EmqukXcf8FTj0TDUx5Ol2P+flGkV/xMwvm+AqjRS9u8nI1O+qoJfXl6g8JIxeNUdw+18CdHOlBGbRVFDsIKvUHoGbNIoajsMoVS7Yr15jAvMfcRYV+73nvlyf99zx6BnMCrMRaldKKwQVLH3/45lEUUFtLTrJJYR1Fsl5Bkv0WnGgPox/pXNrNmNODWMDUt0TFWIEJv57Delc6Ux1wpujWLLGisGucavIYPSo0ZDm+sZNFxS44Y/691t2KbC1FBXFXLH5zlKmtIr75t/YY+OaTPWVgFU6dcgtR6gRhr1rmHg+fV+nGhKod33Ke4L+Qg5VgH1vCneEcOln+h+vHFATT/27WHlGb+jbetDd957FbF5a33o0jW/0uzjh1M51VO5XPRekOubwZK1WN52z3oT2uz6T2WqPNOxrgFbr+DVjcAq/o37tvFO/gpGLVSJ4Xon3sAa9rDIW/TR2C3kwL3top8FSS/DOAPAlcckFcKuIai3Hk4RaJVIJ3cnbZ9ZOpTBStuGrngC9SS6g/Ta6HlE7cuVxuZbt70ER7vuRkb7q++EuB6Huhhnaw9+W8bv2Ja5l9Ebp6/naT7rfe6zVRgd/yqnhl667rBoj1A2vbK84B4KtIrQYrhSZVevrOELnpMD1XogYGWyxq20bwgSze5+m7faf55RZcbv3itxnwsNSRQoj6Fjr4vb45sCw/v7vIK+GJ7Bc9RJDfgujut/gUDnvvK1EQe8tMDo44dQbHmm/Nf5e5JhUYoFKuX/9ncB0OqW8vMaoIIAfLIy8eovlSEUKyw61Anr9c3IWPcbChHD7hk9V8Sxj1EPxXTgNSJFbgTB/57XvrTRnuOuTQRvPPJK+11lVgS7ir+fjnnDasuIi0TQVxhoPQov0NEWmleZatOboe5/C3HWAi5F0LWL9/PGqlBkHjX8s33f8EwZdw2DflURrsJbb7JCs+inNN7MlvVE2qY2Si99KWouINiQY/lkw0LmsRvlpOAaGyO7SQt2dlNkDAdDDsB4HSv+5W3go6Lvu0b5VyE340zp4qs265GgCYXesBvkft8XirK/wFlDVXrN3NPfboAsves9v1QWfD5FIj5ORKOb9Hofvms40pwu8BPu63vQy+PkqM88RQ/Kc08GZ/UAAFK98qpGoIqxRC8hrlRxVjFXUe6r/Xo/N5HChiwcY0CIemga5cf9Fud0jxfRYCIM6vcuFDdsVFRTZcytXqTxRDflSWFV2T0939+6GEk4/H59JFzaME7o1Xj39X6yNSwMCjVd3fK7zTmlZn1gEQzjjdYVqBplAlFl3j5DVJi6i6b6rVBAnlFHjSxaVdFVSXX+1nC7F3AwDsqqxvXJw+m+kyvd+NRsG/fcpxsj/W5hn8e1oIfyqdFpO/e5uW2mkDqdN0SJ94jxKwy+mP550XaOd72Hx41XvTugCtBR0p47HpPldjzsaPR6AfV6CvxKsyfZWS9wPfYrT4utK5/lhydFXSPvUw8Qb1ZerDEumNwwbPVj+1nDVdlplObV1wSeXKYnJNsFVNeLoLvzrzFE92Mik2GiMJj/m+amboMXKmqfmu5Wd5Fgm6y2VQZQOjkVmqdQT59R1uL/JDr3er2DjXlSDM1dZ+AoDCeFFlFDiifY0k3Vix72HfSF9ruwDsGuYSv9KkyryPvd+6pkyvjlrcbxKQqhvoKR7odgHM1hhVi9/bsKYsMKTwqnPG4MDOme31M+uX7u4igFX0Ra5FolccZ5N122D/7vYr73EvdkWbTWHxsGuxZFmZGvU+COL+ed3iY0fbObuWCjR5kcDzbc2PWtKkhofMN9BaLlsydFWd3yR5H1znWBzK4VlAc3XFSPjjew60uV4faxhqH9KFCqjGxkYT2GV/UEGj8zqWWorgFUwOt6EtBVrGtRe/2IeLnpa80pOwjtrsl37ztbmyXk+WYVLdpu+KkGqgReFLJIgBJ6Qinvm5xVjBu6qBG4IqRTpVAmZXApNP26Uld8N8qdEP/iL/7ijwnj3S8TiIt+RX0b5qk7/+TqNnRYkIAGnaOucdQDWoHGDzUG9WCailnDX5oTqPXuKKvyYOesxsoYKQLtoG9DIOowVoq7CLBHLdRTqqHWZ0qrxqKppPqwR0acgqaYC7IkXFQ2eAQnl9YJri5em+wj3+23FNLlTzLcEBvvvEp05aHXu170FLFohhAe/WT2UzTTC315uKvjygPq6VoAOem6SPtDhy6Yrne34KRjx2+d/yeD86rvE6jlqgL0W92a/o2A3NUijXV9KmBN1SxTF3k2198GJ4rMQXOUR89F6SJfvQO/VfG0z/4mFIS2ymnjfcuMV568hXVF+0wVW5Wy62UEIYdFyRYQD7E10+Y21UnBhTqbS34fLwbRl66dtP9F8cZZA1RhogQYawqniqCIlgJbxWccpcM9f3NfT8293UxVGi2C148nxbIeTu8hI/2989F60My4hOaEIRlDcydzBu1WZjqOe8a90Dxjxivnldz8NtkC/fxfebm1okshPdB1KaQX0sEXaC3EVfkrgJSJZB0QzzGa5EhIsgBL8XzDyjsvy5dVlE/0eslLbyj2Sg3B0p5sdK2T1/ySbG/pnPZvz5bXC8QKFl7dE9jYpkGWmBovsjdxDQMVtRat+50SxYBFu/d9jItBKK77G4MVQQmLCINUsOriuX/DJX4voWUx3HXoacfk3gr70nSv6X+ZpMjbIiFk1wXIzsMJnpMa/Y5evR/KPkQnbbAo8T6H5u4IDoqjXl9ptwupQmpV6oxY3XlzQ0iWDhWArjF07enqYrSuNCRWVFREa3y7t8G8NeyjbWizv63i77pMAVLTPbf/NZzmQB08Nem57Tv+qNJjLNBDXUWnlBMe8gEqGF3rCMI39uyg8f194OFSSO0kLzjo3AIQ+myO7/ceOV0PH32aDCFcWQ+hoGBla8HqE7L+dEJvvQ4UXukBdwt0jXe9xK6/1VAVOPfaGjB/FxjVYG0E4MkLetV9Ak+dep8LI+bXzR5VHkUGG25hHCxmNXa/cX2Ma4HLkRK2tNedrtB19V5MtO6c+9cLYdgqvCvQL9FvJ3ct/DKECSUk7VORQvP39bVMAW0RMoZQhtQJ8/1+XsIhPUqkRwcXpa17bA6qBFtq3DpnStFeM3QIbwXgSairuPV3Y/k1umjZRe+n37rG1VALxWkuavTq5TAQnduitCqRylKTGMTYKdnyQBe2u3ajDe13obkL5AtECi6unII+uTglf/Ue+q/yOX7R7v1293VTZw80bCSghrN7XYz7wAcZo/QaLrt7hUO7t6K8U2CJBmjXEOSnDwfEVYcxrCcn5zHZAV15xyP1zvy/yQxK5bzyqv/7zHoQNQboUB56dSNQJbeDLBP3et9i5be6hialihTSQgjC1RddcFUZCNkFjjr2PuLumKzFZd2fNpC8b/xKF6UxOEZcpb7P1nC+Twk8TWSFouNhMOWVU+5ivUIp978jJ8yjt1FR4J6BFvWhMWVCVAWjEIb1jPzdnHjjN57GaGsAi6RWaNCXwvV7T9Ls4XkNLTW1snOiL/dbjVOf9YFMV/m3rio4/V0AVcOmUCBkxj2erdGh3BkAipgcNpe/Rmz5fwGQuT/Fxwh2n4o2bQbTJx5WacBA93959UJB+tCXJDVTrOCnfMdTrpyhSfnDbzXcf/RW51SvLS3wnPVJex3QsGtYy5f6Rof57QkA7jz02oIoZfvaOl99YfhKrU9X4WsFdVA6YlFYFUTdx22rOwIJgvghN/Um5Mox3/0vXRT6R9hjJKlt0H5dfxa/6OvJs6lA14AVaXb8++zWc2URfhl729TfhjDK3PL7MeXR41B9z2xx3s8x8X//7//9TUxXrFk2hzNcVlCrqPxG6XQNpWl8xrYCUqXdHHP3Esyuv1RJ1IDXaOAnIbtd17k6eYDNrNEnfayiWcWs7GIlZNo68JVxVZDbd7zU9hYslTY1CA054LMuPm94wPU1FPXsGmbxuToOIABY2lfP8dTdc4hZn3x3jPUE+rsx4e/Od42r40/oosqRsdZ7r8dcOn6adTJ0wxP62vnUhgjFApUCHvzhfwbjShNOysPaWCXfsgknO0b9/qzlcxmBDUXo0KZ8uqcZCe14By43udcQ4RjpPn2PsNjklUP+UOxtcKq76Lt/L1Ex1xqh5roTyBJ8hdn1rWuRbuOVK/TtT40rJVi6S8ETpiAsVQTuPXrd+2PvpR/Ofr/7LsYvX1uo6Oq49wfch2Az0vVWavAZpDWca9S74FZaWsDfe5vlUVRdo7gGsIJrHaghm32NqHls6KNjMwcWOPEDIyhOvLywSLp88DT/9X7x0HpGbbtI9SmzRLva4xGtEdZ33iDjTZ55QNpGF3Fxz90zx0sW4RlCmXr1zirrNThKwyb6VgCIX/D/FaCvclYgUkVeY3blh7MproC1YccnZSvsjFYASD3g8gfDtxmH5q0edsHA0qilBmp54NU9gS0GUwGsVwB5FjWZkFraVa5VAlxvL5ShLCHOprPdc2LY5x14tod09YXcGGuPf30iNmJ2khctYu661Q1rlOl3wncHcAWhIZn7nNI+JMbDWpS1YaLrb9+2ds9S/M0YocwvLbTCUxRbGlY5NI3vFEENejdvudawSc9jMt5ulKo3Ure+gKOCWVpo89roLnPzpq41YEqRNJp2jQIi7Xze/w2bVTFV+TeEU2Wx4RptVIZaJ/kwF6Wl8ASl3XRivFz5wdN913RDOjVC7nOi7M2No80lJVzG2X0gbYoZTdEKmDHHXYjVTwagXiN+d2Bddcyuw5Bb/SiNvpyzi2pkG5rsJsfyCdp3/WdD3JtQQt537a58hm9rhPy+PFvgrZ0NDX0hx0ZA+hpvRyirpvJtHFw9ixAwWo+JkNUCrYg3UhhX7hqUV6LzNq5u2UN+WyVCkOvCrQI3xp3sMgdGNcYag26MqZKqwariIYzqwJCbD40RoeC7zwvnCdktkh8Nf/mXf/mdAbxnpH5ePdz5Ki37Ca5UWCpsa+wb/iDg6zkR3O7jqMARAmNtTPgpnFiFUu+l70Qu/3auG0LoPYv81mvo/ZSs8VZpPQnzhnOqgCo3G0JriOXuu2/rW12raoiux4mjFQVffkMn4beGmqrUOt7zAmQG3d/4+DzKe9nMd77znR/zyGsc0b1rLeqxA54+KB2aWrwyU0NPV1QZO3lg6fqjt3y060NXulu/gKCeSMHazrf+mDt0rVdXg1CvtjqqPFygufd+nvK5jUD/rxBcIXjN9a37vEKgsxgC2hfyufj9MZf445W+/9euSu1K/awLuExUQu6ZLLtDuMoCcbnDu9iEQXabeOlDgNGmHok+UGCMrLDDuol3v/qKGtX71C9I9ZDbhc8ox7vvhO6QHHrUAJmrpnZW6Xd8RXNlyN6DPr7LR5tLvQuL7iHc5atrk0fS0EqBRz2K8uETb5pvRrUb65q7X/7tEQkUn3Ebw6LhCn8NHKO3C+1d4C1tu06gv6u8nfNvg1dj7wuE1sOsgetcytrbUMh9H0/dtQMg67VWtoq8/e/1qejMqJUO5SPzVf5sW/e30Jj1sh++NZKexwt4v4amxoHhNZ88lYKVJyPwBCw7Z9VP9TA7zv6t1IvZ+17dCHSSXNuO2nyyHapb3DqvdGPMKf4zAN4RDD2YCOGhuwfBbsJqFOoNdFK66OZvQmFxSJ+5b71eRmPseAUmwd/NZOi6CSYrOuk6hHt6xgyEi8ZQH+NWhci48JI6X1fHvTHqBOCQ1q0T3PNf//rX34zj3Pdma3C1i9z0pYxnkayMS2msIBX11CMUzttzcRapCiMYM/caLzR88ZKwVLmtd+qZxuKNRWaTsXQclGwRY8NZ6y1SbEXE7Sul0/U0v1vElwpbhFnlsvxM0eFTa0GMQY/SWEX1pBM6T5U79DtF/iu/8itv6rCRs57PbgIsAOO9VG6Nka5oONq4utjOaK+Sp6e+9vZEYbLa85LKS5tFWGP45PGWZp1Xstw1jNbROWs9fiu/FXz3/vLOF3Z20LpEZZSi7ypEpYrQB/GFgM4I8ADUaYG4h8jZF9BFtXWn9Leul341V7qZDpSgzJJabmEbzLYx1bXYFVYKrAuX62F5bsMT/icsMl8qiD19tS/u0C80FsO/MNBd83Keo/G57rcucAvH0kQp3B4Gpv4i7mZ7lCkJbQ1pvZenzYCQKJ5xvQqKAHScbadGCY16b+mLH4okGxqhbOvZls+0W+Wz9+hTlSV6VB6aHLHeobqEYluPeahRKP3eCHxoWuUCaJFFbdx18950YW2bq8o7Pgfs7n+GYD2CAooiaXn45HK9hqdssc7FGjGLuOhgTr88ZwMVMPISVqE/RQrqieC56j6/r2HduW59P8n4ln+3T9XXr/pmsQ70ybW5QZ/lX4VcS9hnWF+M60wRiurqgvgJGeZp2EcIqeis7mUFiRKvYrgivokRu6W9G4/q9nZsNYKQyKLVGqgiALTBBFWOBLqW/xDMKeku0BYFU1aME+R81yFV4TbrLbyru++uO80RQsSs+lVGLSOXuTu37aexY+DuWbiy41JvQzSl14ZuujFxjUBDOTVKjYEL11WJM3IUinmtx9lEifKG5xoP31IZ2QVw1wAI/bw5oqiNrZ/SQb8Wbau3i7H17spH9eTr0RhPDT56Fpkez95z8uzxDSPTYzW6CaxKc+eq3oBnlXo9AGZ1A5CmNFRbXlm6L6h8UsAFu1XwS/uCzCsLJsmEUqDR55Q1mF/IZrESo9kTJlUoaDdFGIAJbcxYbn9j8q73pdP1AAyU4jPRNRYYmUKukbhiUVQYQn0Ns+hjjZrQBabjulZwGxIS3ihTF+kzLhQiYapxQW+0pJjLzDfWy/kX07dgxZCh0X3ffTf2q0Nq3ymV+5QJi7i7wIqmfuu9lKbvJ6Trfp5XjaexPqF9c4ve5oOguV99zW4pWuVp1LAVzJRfi+L0o8kDFEZTKgko3sVvK5wNL6hvM1UqR90wqU008K2OykgVRhc0AbHOq0+9GzQ2VzXcCwhkdxX5CqPdHpT7v++ovnuaucfrLB+VF/oiKbJA3kvnGvw1qj0C55NJbS6wadJGDWL5cWlWz2sVfOeDbql+Xc9inyn/lPb9u/W9uiewQlKidiJbKlBrFBz4JqtHDND/XWS9tmTJUAQU0f1P8Vn42/ggd5ZCJDQ8FxNd4lMYV/ZcFczq6FzhqyJ+RouSRhspe32tpTEtSi5zEMKr99xqrjTaOSJDXUfHok/XCdkV72I2n2cE0LWxVAqtSL7M9+R6Nhzo94apatx5K+h2hYIjiJRS66xip5zuf+DB3/inxqN93wVUKNP8dYHcfHWuKiOlRb2RVeh7b1H2E6r0fXzWReqGhshhldQqnYKdDZ/2Xp5Ez/6xWCvlVF/RjBdNhnd899t5BBIQOs814idPja9fqVFqeIxyLtBhFHo0do1svdcf5j0Ky8f4ynpjDacxoV9R/XoIKy8tLynuNQj9f+e14PhJFl81HKQBCqtoqBsmCEw71JDC/WYzCStbBN5wD8R299cK38S439/t6xUbkaSb6bfJhVJ6hEQNm/Fc2UPu1FXEo90TkBMY4ysqZQwsLBsD+jR8gtmEa8RJuw5y5QQKuoLG1FuaXfuOjRAGMp9XrCs4ImBRfl3vGuqGg5ZhO44qzmvLi+t3EbAIVPs1ys1TV28N1mYaFbiY/3phbQMPta7SYK9XodTgVnEDAmhUoNIQRGWGcnO/OT++Ko9UKQE1xgB1a7/KEDqv11XPBN8JhTHY6LQhN/S2prYpz8Ym2eBk83hQeIiiRcON2ff9GNbAzKkIhFJZpl/qZfXzlXgRBRnVd5sZ2L0bq3PWk66nunX2+Sr2XYtcI7O/94RXNFxA/qrvGIZIa1lN/hNR1mrdt4OmnFDYZxpTrOUnaDZccOl7Fonc+E78Pd/Frbp2lGvDLYt2tY/QdYUxMLqIbdYTMYmN75soG3O84rL9Lvqt0GEmCPn+7s7rusoV1LsX+jo63d8VcEhHrJmg2fPhZMp6BBW8NQDaLS127cDcU0rtc+mKx5qlwStiOMtf61Wgd8MM9bSelL+6jLEhvy4monmF0jzXCBt3aeaZhqzWyzH+lxArI9DNXZQ4Pmn2iww7ClmfC1IKzgr0hDa7tnH/U8KMEyABoePtrpvY7S8BhIzI9NOvhkrvWbKyRqseVI0TXbV0K5D9JGuH5Yfu8SjAK+hcg1q994Tsu8bResm7vmxIEL2NfY3V00L0F7ZPoHHWRfodcJGVeyEv4RMTvYeKFQ3IaqlbDDU49dIuYQjkjAyERdFcuKSKqYbpCiZo3NVYOklX+uYnRvGUp3H28Lq66fWEMBGvQWhmFVoZfJX+Go4NjdQAQO5VnHeti+KMJYNgbO5ZFLNrPGW+Rc6l5c4Dehtj6+xaQPdFdF2pzP+0AU19lBIl1/6sR9c+4vsaOnTtGkf5aL1loci9l/dVxWCemxpMERpnw1VVePV2gZvKnoMXy1PG1aSHGiAF/zfFsRvVapC65qKurrVV4Z68AhnSNvuyGgbAXDbk5TdjrrHusc/o0yynH2Xtbtdl9Lm6wr3XZr2updfqFXVUbtS3IBmfFpx5ZvXpylN/6/+vtjAsTqxgggr9CqNrDYMUEfW8d3FhaJ1iMmkmt28rEiLCjHf/KftT0hf2EBd3DlGtb11BCqVCRElAnMbUvQGEpi5+Geh+t5YgRunYB656GXEzb4ytAotRamT04Upjwe6tIm6sdF3HIlXCZ9wErUrX//VYnhAvnqiCKdKvYi3jFyk9uddrADp/PLz2+wqg0NePLjpvmK/83vsp9hXkJzqU3xi0eh/CqZR7aUuZNTZuDjfM2LlS0KCbFAsC9O3+hsq1s2s4q/Skcl6deOopJIa3e1pt6XJ13R4V61XN0nNOkPFJu0Z399cAGNfuKWG4GYZP5jC+eoJV0lW+9Wb7QiuyViCBn7TLUFU+KkuruJ8AVAHShtpWH38hawKsaQkDXXXgRTWNvyHqKcbbDFbiW8C7Sa9rBGUf4r8cdjFvA+9LJnrYHG+j6LjZQfpuHJRhQz9igG2vAoSBtIMhykxFnfqyL/zo+w7qZUEEpdMqdy62BbbGizGIZ6t8PMfLgm7at6bQbd36xxPpxppmTlTg8BJ6o0/5pQps3fGmHupzjVyVc5WR3/XzAAKlUQP0hKZqjK+gCd707Lr+G3pAnxVYdG7OvPuW9uUliRJCRO1XFUo9FXN87TiIkcHCU/WmGtdH/wI63nffebAIFY/iHWP0Wkt84MVG9+mYbGzs7n+Rg6sDEOy8VcH6n97a9YKPXzjmwXPAXjMP8V89TffWS3zyfJe/es+GQjuWKvd6zbyY1vt5ymc2AkVULU2ta0dZyyu1eghzDHNK3YR2YBQ5NxaqJ+wV6Apw3fBjcC6vgtnEPIskjKXxeAxXBG4MlB/m2UPP6l3oY5VgXcYKWlG470XJyyzdXEOwl97abdjG782e6duaNt/efaVnhac0qrAbRw3FKuetp+gJH0Cp6MhLpMyLsmqEtF80e39flor88eaeLz+7v7JQBVG+WqXger3mxtopp0Xx9YgoLgavi/P1ftYbQed6poCOjYCSIoRwKhsAWReOa1iMFbBiDCj7btAy1/pp/qwxCdtcPWcMhIALMm6+enDiXRNC1V/IvPy/gKAg6kfZ/1FP2bhKx+7BMVdkoh5e9eAalhqBpzDm6oCdywUa5rdysYDk1YxABVqDFPW6Uyt8ni+q6xuL+l5Tdd3AzkhsPax/3eFjDgxxLqXFz6u/k2Zx0+RX2WBaiqzhn40LNgzRUMjmXGujbmZjnPdtH0PHWGapUakyUteGP3Y9o/UQiLqMFITFQsbTZjRj2XCS/uqTeasC9kxTX5Vl7NZRejV1dBEeF5wS6VyhU5GgPrXNKqKiKuOod1blX4VSHmpb2u+n40T/JgvU1TfmGgTveSgPUoqrPEqzJ7reb9KmyUfpSOEKn3XdqfzVcJtP1wmAvuOp+1sySBeRaygZ/PX2pY02ddhO97tPQoZjMCpPjHy9Urz5lYS5zfmmz1YXVC6q8yqfnYOV7/U6AMaGeGpknwxJ9WwByVP9r7omUKHTgcY9t6NVlHWFSjjnkHdx7IoFoirmnkkkxYx7CtHZ+ASdm0wTDllc3X7vzkhKsQvRFEMXminOKui+qKST34lCx3Nhm+dv8q9sjL9Ke0Mtru35OVX2xmQuViE0n75b5atUmvmlvjUKi9JrQBpaqpFaL04peOD6e6aCZhxFY57bMAB0B/UyxhbovXioZy712UXs+rLCjqZVQk+GAV2N34K930qX9p3S70axpWf/3vkjZ/ifgdu0R7y2Xov+N4MPD1WB7kY5PEH2GPKiYC81OsVuR7sMpquzB9/5vuf7djfyaq1Av/CsMTUMd6VAz//G+nR/FXHlq4Z9eUPB621rIx2Vq9azutWzlYfPYwg+99lBizLayTJ9hRvhW9rBQwjcP8zl9yN6X5loQgglAkA2TRHFIEIemKUKzIQgJkbd45tNVJmsyFDoomOrgt8Jh4QWSRLounilb4XdxNcDqRJpm/dbF2+X+QgjlOZlIZAyBKuupsk2WaDGhcLQj4YIO2ZjefJeSrvSsmtQ6zLX4JuHhlAYeXNd3iLEEPaivPUydiNZjc+GJjzTdYQi0fu/WV9Pc1i+00e8x8g2dt5QST0biqpGQD31Xs2L9q7uA25dCAYe0HqN+SJnY66yst5BPs/juXbOs68HJaNQGLAo/gl0VkmTuauXt/Hlt8Z0PUX07l6T9WoLgFfpNhRIn+nnKuoN2bUU7PXayvGT5/dZy+dKEa3bVxe1CmUtHyI9hQMw9CmZO3v8jjIQ4kGwbgHvqxOhfwtH3XDSfQdX1xmGK84OoQSqoBBvrW8XXSjbhpJ2Qk1OEVwnqAaRInLNp9lJG7P0qSFUXnIza9zKeBUmRtOms45H++1rjU89jc57+wTNQ9P64vp9nF2krmZ1dE66n0DRpxp3dO59iwavTsh0T5EtD9UDKE83zFkBrNeygooGPh3vhtI610WAVdA1vFcAInPWMFdThM1dwUs9KWMt//MwGw1oWKehJc8uMq2CNNbu5tfGGYKT58v2a2oqxfxksGV8lb7G1LHTCX/w1oA1ykBmaoj1u3xRudv5qvdV8AM0FVh2jaF6om0XGFVXPRmWBZ+vvjCsIzqrA7X+T4OpUjEIjATF3NnjFPoeZlVlRPCa+XNF/rOYoMVNTKWuutcMCXRyH+8tvlJl3zNRakA6CWWeGski4CripwmmjCEVSIELXJexRkc/Gv+vAVgvrv2zWGgdhvFpauIiIMbDtXoyT4JTuviNYbm/e/ggOjEKZeq7bjFzF0mrHDdEVORcQVp3ukaqc3u/734JYy9i8+wuUheVPoWHauzLLxZru7OYklllga87V72nMldk22MeJEp0DtHY2htPB503hl6E3lTrBYXta8fkGS9zP2Di7XBoWP5WN0NlnfGUuzOytAds1Bv6/bdHcdSj63y61oiGe7pO17kvnwOzkhsKELVZw4Aey/dPnsLT+sXTvX9iI7CMvMKFSE1B1EkEKwGrzIRrKG2xfmEdbRYVcR21/2Ywb0MXd4+XznP7+mLsrjUsiqtiKXrqJFV5VEF0vO3zU6yx8VWlKKFZSZTrhkC6qasIodfRuqgE4zx5QsZunWSNdxWt51vnhkoq4LuW4Fm0cF+ztPSj3oLQyQpz5xE912Vun8qjXZ9ZD854a0zVX/7rnJuvItEa3dZf3iIrru+ieOvDi/Vga2Aqh+UP30XtReVkZPu0c+pNZVXoReXlg4ZSteW5erulY42HVFLtMh7mXR1dBzBWL9JR9/0mKvClh8SGhtzMW3nXeIyzILNKfUOceGLRe3XP03z13uqK/r/X9rdXCwcV7bjWSevCqrLC1AHXahqEBR3W3+LVFd93D5TMPdxJP9TQOKJUsmMGmQu8hTeEeBte6gaijm0FfemwhqCTitE2rFGLb1yErQtHVRZFave3EEZf9bmHnT0x1jLt/Y/uXGVZM5Sk+hsWKAoiuHX3O9eu9bfS70qP9DB/jbOXJhVMbr776n1UyVRBNcxxxW8N95Vmfuumq/VS0L10AZiqFLb+0rd1dr1q+eFJRruvw3i0sZ4YPu65MxArnjIH9QYbHqv3VLkoICxyB1AWqRYk6se11XO1nHDbDD9t47suGJfW1rga3qoB+XhSztHP9U2GqdyufqjxqL4wF6XL1td6ynNtY9vrmPr7ZzUEn9sIYKgSD6OIcT9ZI4qg3sAKWRWUtD8KnbI3YB9xviv3DfHffdLHKJbrg/cVYBRldxO3rIvVCdWfTv6OiQIqalv3rXXVqPXkxrveXP4KaxGHTTtdfJP+1z7W0Ki3+do1bO1rM66KHpdua+iKwMs/jWF38RkibcxaW/ioAGJDDassV3igf96H4wrWeyj/LxJfZG8u6xlXHvDhGs+Op6G17b/flvZrJMgalL8hyrbvzCELyUIk+rlrUuXr9qsyvyCmPN6owsb0N0xV1H3fZwjunlsnKD/2TKgNzzTD6z7dU/K1t5lHlTueZl9FyevcfrVe9eDf9RAqF1evVPalob6rp/+XJ5+ulTdeAgt/ouygTnIRRl2quqW9bzMCOliEL4O4j3vnbCCuoImxoFdrCT02V5nBaFxf/4SirhT9NJ+5KKACbwL83fjf/l7FiTlKi/YV3YTH0MhL3wlF3WDKx6axopf2qUKIUU64vFuBUrRTs/2lsBs+qMArVR7Npira67O7OOYaFAYVFjUX8RtX+cf4nLrpmYZ0qsx6ro06q6AWwBStGzNDvV7Lk6JexIjPAJh61sIVT2HJjrcgzbzX22imShWz01xl5zQN2gJ9wcd6E02zxMd4sQqq6L1hFr9XProuVS/KUdTWCSj1Gk28wfvooY6uNxz2yVsPgyFwasEukOPhGhb11lvqeJ9Ag3VL+4Raj/k1t/VoWk8BwALYL8QIPE18O1OEuzFJDFhlqZSBoZYyvcHcpNwE9eArK/s2i1gL0O5Nqt82fKHfjY0b4z3nmOtF7PrsWr+fjFiZHk3K5P7X/yrUo4cTPBunbiiFQehaSnPdCWdPXu3Bcvp8yr5HRtTgrgtvrpcRKwjGji6+qywWIS+63DisdOErUBS6Nl14vQ6GubQvOqVs0KSCi7aLwDsnT2s7HXeN//LNE4LzrDYBGEb4Ci+jfFevomixIK3827/RvuEfqBnPdJ1glU/BX8eEPvVMKgfaxis8P891bvu+cUed3/14oUbHuC1kd03h6pYw8odvDcjd3zDx6qoCx52fevhV4OtxoVMBJx22hqAh5PVOy1/1klefrif5JzYCL7mmRbQUaGPWYs1PyNfvdS938ZDVvuunpE45Wyu43+xwNaHNGaYMqyAbc7dSr10L1Od1bByuhF46LAoraqugrDvtni6SL4JkGKDU20Ajo4nRa5t13fUXE9U4NtZcge9RwZSPnZmLhGv81tAXFJj/osLOcUOA9Rb9XhSvToapwlfaVuBbnpAWlIkPujv2CsWrbzuv+rhobPmkSm89yjUC/Q0v8oALTnqsg3HrZ2VujXZluP3CQ9aFHAfdo9vdW/rW+Mpk6pxe0Td/77w1YsArsg4gdOOIj3vOiQP0QTe/LQ9134vCO/4kL03yrIXj9SzJDdo+LWr71peu93Q+7h7pyUX5nf/OF56t17xe5RNofVUjUIbV0CruEulNA0OAFtZ30UcXmXoq4JUyhQPiKCtEkRkEPVKgXUdYgmrbWeWLBH6SYGMI3kWfr/J3Xy19maN1Xr9P6XdndNc/hMOu3DhPGBrfraLvgVs1luavi2b6V3o1fl6PpMYCwzNsHfeOs0Ij7LVhmi7g1cNUGn40n/fBcw01bWy1wq0uBqV9A0B8yss7/1cWAPn7yXg8LUCWJ9C1a19dOG+/O8b1Btpe56V86l51N5xn937Pjtq6/c1r8mEMeuJt2+L9owNebrizEQKARD3eOyBt1ekDeMqY79kaAqDlK29lSjv1CvT57m2d97/EFONo1OOK+zYctN7TtSn0BID54IHqm23nij7vfHzW8rnfJ6BjG5cl+FfERU3eE6LuIOtKlpGrOPXB5ImN3zP1DBDWom+PnF4L2lhwibyC/USLCo6yKAt9qgzdV5RbRVYUXiTglZRKlbX4JvdSPBdTX6nwt7277owYwldBKSLpWLa/VexCB1VES/uCitZZ5dQ5r4fxBA6Mn/Jp3btPZJEv+u2YtLupuaUDAFOE7J6Ov7QvAl5+KEipIWAE6qHWWNSY8Xwrp5XB9r+ecUNqvb8yh16Va/dB0vra8J+TS+uRrCIrANRudUHlv7J+awQ9TZTXUp41tqaWqvvLCSl270GPUGm4iOxterI+N+Szumu9sSuSNgpW9Wn154aAqh/9jo8q56/+UpmXUHLdJETdwbeuKv8KocHUsHD7Dhl7L/Fdc7roPX8ZA0fIr3/96+8Y1oRjbLFFISQT+oSanpDrIp+W/V/fG/IyZu0+eQvoSImfQHuTEQUJOXRRssJMuaOd8FHPh8HsUkH1w+IwY1SlurHzehKQWsNGm+2jjqZNFsXwcLoRaQ2u5y1St35/++4O0irNl5DsGsonQ4Ue9frqpWifwtmQZw1dwYHx1/C2zSLIZriVh/dY785Xlcb+f3X2jV2uQc828jFuxrljLp9D0rtfojyvD+sN4JPSpnPS0GBPIV1Pq8YYaGTIyNmX38qK+rr+pgAY+LVHTjQUVgBX2W9sv0agRqcyXH4uv+GhGtPS5clTePXsoDJyJ34nd0MdHYzJb2yzC6cVAorLcQZeSXlHTNz7CCjyU1wyWc4YMCBVTic41hAohzUSZc6O+YkO/V5jUeSyY0OzZba6f7yZbuQRr94slhpRhsOehyuO4mjYjpE+I+olNyfojhguU+pbx7MxfnNdhVfk11zzrl80xFQl2HaXRu0/BUigi/4a9lvF1fnomkz5jnAS1L7IpHNfQ2ncBNk99Yxq3DqHNTSliXFV+dWL6XjE79ewe7ZgaxWOOqvU8GMzcDoGfzNG+FK8XakyNsYq4v1UBim7hs36oiljuDH/7M/+7DtPpMa543/i5R/mjKArTdNeg4CG9BIk3706S/fVCx2/+nuAIX7cEOl6kjV65aUFpK+WHdQJXQRTAopLt6zS8gwmM7kbr5WlYr/AGYJT8s4TcSJnF3kJgywfi0kWj6ustz/7W8dZQd34MCbt9TUEZcInV61M000vlLw+Oi5j446NH1r4LuNA3wyfozru1MZzqW+LPsNDiXRjVOP2ZewieUZ5UwaflJ6c9Lqw6F83vALo7xqAjr9n7pe3VgjND6VZBV4F5P+e89T+okf5quNgTKtEjetJ8TYUZuxoj4eLyDuvwM7Vx5tiyLWj3fbDHHUei4i7XtJstAKc0sxcC5PoWyMDkPka+c5z+6vg27vW9QbPHIi53w4kAhTGWKBAnv7M24X1KzWopUPnul5Gr9Et6luwV97pWEtzhgx48/vTmlYNQ+extPushuBznR30Eoppw12sqYIsIRCthO5vXdDzpiGLoFJC7z4poF3I7F4AdVNMEG5/K/E6IfpS9FGFVeSFLkXb6/0UVRe5aqvIuqhHYcjWYLUedEUbgtKxQKRc/G9+85tvwmcO61LUJf2ugl0EvEpiFe4VhtHvlDXkTzB2HaLG+CWGrsJ1nzlhCNp+jVN5uwa0hruKQV+LLi2W7nyvEMqYqVEzJ+hbvsQjjTnXc6xSEBpa3m14w7XKCYXapIP1PKq4Gk4r0q5RqixW9vRrDUHnoAZrjW11TA2stcHG750SekCx2URKF6O/9nYfUpMlrg6vuF1dsfwJhBi79VB9KPgruN2P+rsIX34sX9IBjV60PAHMV8sOKrNvPND1LqKVcOveLeor41L2wjZCOKfwERMqqstrQor6ixJMCBRaBjWeIgYT4v6i3yKYKuEaljJzfy8Sq2AYl1J6EKrt7xOTqPMK9F4GbiqdkNp9EwiL0HXLCY50z9IPbTaTp0iwi43trzoW2ZRfqjR3ri1CV4jbzlPISh1V/otktdFx8TKssTD4na96IFcomxq4Cm4Fud8MvnTgVe73d/cvqAtNzNGmRbavHbt+mg9ydfeJt2vjyrUrxx2dCzDKuw1vVJ+of0N0pV/nq4avgAM4q4yZn29961s/FovHD5WLH/zgB+94cc+jIpMFXDUq/fZxxPZ51rt2Vf1g7tZQNp29uvRpDp8+/e3VF4ZrhdfFU/Zs9VrA3tfB93/pnT0qQsjnrjEMhANhu+V7GaeItYy3fcdkfitqYUBqiRmKCpTJMnnLuPqFnsIv9Q5Kqx1TFewiJ/S/oj9lYOEz92m3IQbPUCRtixKskt5+UURi6etV1b2u8jc33eG6nllp2XFrW70yZCil8lznqMZl6/b7072rPNfbex+KrXdTnutY0Q9P1yvrGghl3QV87Zm7rk80pbFeKMPdPq2Sdn89l3qKXXyllBlO3saG2rZPS4MnZdY5N+88cM81XHTXv/Od77xZS6wsb5r1p2/H5l0a9Nga7/axZy7xBmqQZSuJjKBp10vXKCiATXn3JYRf3VOg+YUYgU5AhUvhRj2hnV0jMDBMJrQDmXLFWGeTY5v4PWd34SLvorHGTutml4m6hlGLjKmEaqrAKvQbSvAMpLETX6O4wqWO0m6F4soKTPt2pZu+Nn1Ru7cecKGgKzIsuhhNkOwmrmEqSm5IrELQNLwrhKZIsUp8jd8KdfmsCFr70B2+6YalClwLutcwly8bb21cX9s3lr4Tez3c8mER+ZNQ1xuqogRy0MN4e7REva0uZNcIoPsqh02P3ZAXGjeDp+2ZUzzXMNZ9Sw8t4jXH9fye1tna3/V8KWLz4HRg47/7bqH4fvve9773Y69excN/mFfbrp6gGxi1nmjcMGy9bHUzkqfP7jnhoRrFAsp6+Tzujm/5Bt06dwWeBTNfSHbQMojGeu5OERTClnk8J/Z2xLrPbuwSDuqZNSb8foeOtFVUjTAVZn1txg2FtVkiV57eIYCBFyVVKHbC7u91zVd51jCVrldMdoXSc82yqGKpUawxqBcj9ON4CjT0ko2Gf9YYGmvXQdrn5p0r6LS8U68Mz3ThuAaDcDyFF9ar6Vz5tJ0qZ7/X61v0t3PCeC4AKU+uZ0AW2sf2jQHp/JqzHg1y9xwogrg3+cARys2kMRb8UuXWcOka+Wa4lae0VwXrWuUK79RbKiir4dlYd72WgoT1zMsj5c8b/yU+3BqB5/HWV9++u6P6qnPkGr5HwzVMXReojrt76bUzSAeoCrZKh3pzFphdX3DStss/7dcTUH+1o6Q7GS1FXAhThK6DRSr3fVb63LUeDve0QeYKT+NKT+F72uyDON0MdNf7FiEWuYimOyOhJzubKQzIrBNg3EVca7j6jO/m/xcZY6ruByjjbyih80SoauzuG+Kp4kBfxuDoA1VZiG/KYUMCyw9lwiKcDYtVAaJ7adnQVRfU8BMDI4ZrjrRln8hTuKuKYhHyenWEbhFYaUqxtW9c+abGbkixYKryURSMrjW0G64psm5brpU/60kwDjyGLox2X0np2BBsDRXv/D4AmpBt0ydrXNGn/FFZLA8vuDL/9+lCr8wlpQZHJAEt3PvTP/3T/9f7tTs+sr/80zBb6d1jzY3TC3EKSveeygcgViNJp1bXVA+j2Utho1dJETWB6yYbEIbYTpZQRdp331lnh7xBEJRet4ero6+FFMNbA1BBkdpX97SofRlvXeoKTLMpGJBFIeorKjCBYtR1Qfu8UqWySKD9dW/pXEbt/+rvQjkEB+1DmoykmOmVKsKeBVWl2Jhv+4EWVcb671k8tsr+STkuGrw56Umwvbe0fVIqjACeqydZr6Ve0qaKltfLq+0vgV/02v6WBp6vstRWaedoZdfx+ZM3iZZ9CZF68EYXk9u+sTDOnf/KFKOxyLnIu1lwy9trAJ68N3yvbWE/z3fRtxlPx7cHNo1f+am360dNQimyZ3Sq6H2Toyp3peEj4PL03ZUDKTUe5Lxywnhu1tYuTD/xTg3rq+8YrovaieqAnph1BYab5KAmTGTiIOPNHrGQ0xX/Cn8NDjRLaLmsiA0Jq6vvHejaQV3VKg106djKcI1PNsbXw67UUUW412vd66bWsHm2wgBRoJvnCSdaOpq3B9I1vr1opWiyjFiGv78ZnNJ8FXzn0PNVBPpc41KD2Y07BKfhFIixBnfrvdLDBv1W3vZc14PQ4sk9J7xrjKtIjKXGvTzsdyfj6k9/ZwAdFdIxF0TgV7Li+nqt98wtaFZZo3ORq70VDYe17tKEJ+6DR554igEp/3c94snTrVdVOWyIZXmmwOWTt3Jy2TynnG1MrbcPLJW2i87LswUQpQ1PhBfS9boa8/JjM5S2ACZPay3lx1ddEyjyL2F3UqF6xKnAXzkDcBs6TIAdvfv8TUZRkF2/VdgmAlH6nlyELlMUyROAKo6GO7S7uwh3EevKxj7r6hJm7Zcui+TUucpVnwgfw7JeWl171zrWolPnBvVwsrvHNvq6/0uTenVF7ZiPECytS9/yBloUwRS5oq/xXJHCq86uWRD2NZLtK16oYUe3Ddm0zxTT9rV/VyjLY5Wl8vu69j7dU1H+7YI5pVJvox5vFaP6G2LUN5vSPFcPUH/RrR5A6Ykm6oTWGx7edcPSo7xfejaLqeCo62z1/lqHPjpjqBGFP8oOdmFbMmETKt1TenTu8Hg3wOHl8g9v6a7/wi/8wjslX57Ud1luvIiChaVN+XLn69VPETWJJUZdso1ZebaTewbg3KK+uKKu3QooRCNu1xi/2BkhKcpobF8djomuNV/UuYreZK4iWwNQFGqy6y4X/dclLr2KDNeoYgBtOXSqqIhx3jS9nlTY/nGBd1FRO6vkzH+Ngj0HUFyFuYa6MXHKrd7kohm8VcCBL6rgffzW+VQaAtJWPVc7Tatci/bUaR2rSppihsreCddbj4hSNf6Oswi8wnylngRQ0b40XHF/2zi19CMTDL15I1PqRBsKsJ5SIwDurcJXB7rxtI2tb+ZaBYUuDHo9whqiKtV6dDVszcsv6PH70cgisTj9J8nZ10cetoV4WYl4sei/Sr7gaGWEsr/y/e9//w19bpOmgx/XUG/2V+XIPQsYS5fPWj6XJ7BIyoB2YWRd7yras8K//du//X/lwNrZV/dGeqIjozHx3XNHHRR5IjLG9P8u9hRdN8f/yTOowoUUIYiGBShcbazSI3BFztpaN68Mq/4irho+zEDx1AshzFWIjJB0W0dPrxKRVXK0V6/57fpL3V00ayy4Sgo9FDSo0iy4KDqq4C1QqOJSx84hHmspmjJPDiPEJ/VM0F8YpIuP9cDqCeHlenur0I2pyq71VuEYx4KXHuHAsFYRM2o2T+p/ARXjQRkzbN0kVplw77XztHAKcDyljOt/N5Y+Ac16geWL3ld9RD4KqEp3e1ccxkiffPktf3kv+fF95/zqJgtVvgsGynt0mX6UT9V7hsCG1JNF9/oADz0evvq2C/k1ZDVOX8jZQSZEZ1jPurpPrtD9fR7Ad7/73f/L3aRcpXvedTH1u1a0epZTfdAKRe2lE33TUDeCQHmNgy7yqBKQPgmhdGxPxGaAoJ0qMs8uoiI0FRC0heCvD47OYBi7Y7UCwb2sQLhvkYZ+nJFFk1OEFHi9G0LWVM4aG8qtm/aWbxj3KvsuYrq/9Zd/akSMqQj/CZGtglvj0babJVPE3NLQUpHyovmO+55xzn2N9pXuBi4NqjjXs8aj5kh7aIzOvEBzK6xwhQIsP9f7u+8aDX1p2LcL5BRR6dV9IeSD8fc/fu24VybMZ70P4Eubnut5QYxc5w6PWFD/wQ9+8GNrB0CZhVuGxPN3/eq9UDag2ahIPbt++/T/kzueSY1b57kL9V2/XI+qRmhp+aqeQDtYdFMlt+GMoqSzdiUUZbUbwzbe6mRLTF63tkjF/xiAITLJ97fXVIr1FWWViI1rMiZ1O+9DgDHO05oCJNbdiZgaU5YJ1e+5+zjGV8637BxolNJ2EmjRCAY1NwyhLKdjRMpev3gaff9pj81YAw/RNXynVDmsF6nPRa712MxllbXfW09BSfmznhh+fAo9rdfRkJhiTLsQrw59KjApgu261C6ydn56XR8LmpY/KboqYuOv8fY7T819XbfpuCrTpU1RJ0XcOWgIhHxXrhgCCpe3wQOp18zAV6EW+Bh3Df4qvwKO8s1dc2rn7//+7//Y+UPi79D/eh0nKwdGCzKrwEvL8kkBiM8ZIXt0PNu1ywJGnkyBXHlIW+qpHL6aETCxiNLrOlMl3/vF84VVaqnL5OJvUMJtsLiF3lNIp7Cu9OUhXEaDRxwubS2kTIbGQ9vXpo5VQWO4npPSmH8V7GY/UN4VmJ4lsmGMCpx77cSsMXw3gWmnCm/RepnK3IlDFlWbW/FSz+157aVTDUAVQssqo9KjBmAResMe/RuvYPgn1PVkANBDqeHRzyJ1dKr3adxVUv6vcWnb5qOZHB2TfvR+YyqvV+6aHKHePcepYK1GcD2YKkrGQv78zkNph1f1sWsUzcxCV7xSnqgewc8byqmRQ+dVcgWgi76VGtn7+2t5R3FBQJMRGk4iS3TT6SSZRAs6VkEr/V/kAtrvnFTnmMt6GgvuOs/LK68eDtoUxg52XZRurqrlXDRWwghLXBFXFJKh9J+8kjL2tXvWuu0VDTQLoghJXVD33WM9YlPLMHC/i8Kv1DCUIYt4q7Qax9eOMFBfXYhOJ6g9YwmqMSbogRdSQa1SwHB19+/+a/Pc1c7ThrmKfNFhx0eYGGNKor9XMXZuV/ELO9WrqpAWrRc5bQabsbQdtKkC8r2hIG0a8/Jg56mGpsJePl7hrVFeD6xtNmxXlL7851mLnVW23eBUg7VZeHhXqRKvAgIwauAW2fNI9UFYuIbauBs+Rfd6luhXj7XXd01GuPln3oY/N2EE//csqyp3wOCev77IOOpCbkHN0zzTZSezJ8cbGq1Rb9tPNF8j8IV5AjpWRdABtuEOpq6gTu7iMYY+BqV0bmIIu3hc3xTVxTnM6u++gJ0CYVUp1kVLxgLBuK8ZEcbBqLmvE1LF7n4TWMRamvi9yqWLzpACI7wKp4YVYq3L3zCbncEYr0d0X133W7OYMFdjrGXKKum6842lVqgJYg2H/ld5ud75cR1ftN7GZ/EThVu0WuWgzdLsrvEkjbEKp2N48sDaBn5aQ9A+VEGUHg1B1OMwtj5b47e/XeH1CrmU/sBZPT3zUGRMcZObet/13ND5ZLDZYvpPnmpc6g0+0bohIO1aN+tmsRrMPl/a77z89Nv1ATywsr1yVl0jjOV3CS71WtYjqLG/enpgXcdR49VMrFX8rbPgej2QV10T6ITvxGM+jFQE2FjX5q1fHWdVhXowkIH0fQKU465JsJyUtHYooWassLD3rMUkjN9+9iC2ErkKscJWZqlAqaP3dyKLiK/UDew6h1j+MQ4UU8NBeBiKLow1TMDTKWLWp7vvDIE0VIqU8b56MT7h6VhWSZmj/u+Z0qEMvt6btnyXwWtwG4tVd2mi/bZX91odRfjm753QDAr1XI1FFc4Cg3pGfU4f8HYVTYGMuixkd1NTQ3Pdr1LadxNfPSBj2Q1k6uiY1eW5emH6UW+TDPfaE4pd0FPPoTrmvm00ZQwKRNTTUGcNyLb75WQ4FhBILKgO6e5084Ted08NAc93lbK6r9z91vLWaNQzXa+nnsuTAfhCjABitYEKwrqNRXU1DgYLgdxzVsh7QBMXETOcywXhN27beCy32AQV1Te9s4qo7rP+QDCYivJbRUdIdoL6NzqtQm74p3U1/ve0uImpIJ62YdxVBkqZguAc81EMNXh3ve+V1Wfzb52gyueKNhnftt0w0Yak2s96i+W7hkPQZcM26quwr7ey/3v9ZjOf2r81MOtNLBovANDOelDtf+vvMwVQ5r1IlRw0FFagVk9GOnRlcOdzkXIVXPmrhr2KtIZ+5wFNCxoa22fMisjxaBU0OnesBWv6d3UU5OCbVZwfz2tyRQi6SI0v7MymR+gEY9O2DKKXPPbKIsPSPSFKw7vN0itgW6BX3mvY6NU2ixWVIVDfH7ACUfT/hKa9jk1czSsju4lMWwiKWa4+59z09YAmuAqhDNQwVAVsS9Fis5c6eVXMOwlXdlLrzpa56+qh3yqTuw+D7vkrRRCNv9YA+p0HcDQXemu2lPUXISPttX8YtwapSFLYoAy7YZ81wnVrq8ja/1UqXfTWtyqj0sXYi7Dd2xBEvVp97BzWKygPrNFfhW5uek/HX0+jqK/18Fr1HVi5+TI+da13uoDsKW3XtdJk+1ol33oZTdk+Naieq4fhehUVfnGfNQJp0q7pY721Kr7y5fa14LN9+VKOHO8Gup6i27ThHl1T5E3urr/S2+uBNjRVcNqNaAXWPc8JDUvv1Tm99uqewDIqIlX5roVepNBFoPtcLO7OtL9rDnY6pI+4CNbFKeGQ+/AMqgwQ/f6/CXRvN6dtzKxIoGihZ/9UYaDHouwn+pTRK1hVmBa9G0LpMbKMIKZAG4axYaCGafSX4dTfy7YSerPpzIYUYQZb5+1VaKwZU5pzBs0Yy8yMHEHYHc5VLmjmG617wF0Frt5Sz2g3j28YPGsCVaYFMxuaML9K0Xv7Z967qN12qnDRq3zm7xVm37uQqg++Ka6GPxoexAcFQavsIegNb5UHy+8Nc6hHCHcP8fMOivI1RK1v9ShK685vQd3uDdL3ZkdtqLb9rkFntGog7K3Yl82gm5BWIwPtZ9s0J8JDV3o/3SJ93Bqn5+rpVj9cqRz4X/3uKw+/ihEQG9tJa4eqBMtQPhCsQ8uEIk6Rd8PYCoWYJ6WOcVlRSmYtc7Nm1GG9oPHDIqei/56l86TEn8IYHXvpU6NWBIlZlnZX+vpAfSlCrDCYl9tJjRbSPCEI/T0DcAbYgViYHHqhXISDtFkjaSyEqwpry6J7BrkC1rBXFWzDHE8epwyuN8wcz6dolCEu/eshlE+rcGq8qxw732hqDDvn/Z+iWq9q00aNYfmyiNbYKC2KkDHU1w3RFunrwype9zXkSpFunfUadhGYp9K5q1HRlwWYq0+e1uw8X5pWF5Snuo5SbwF4uNL3NFgH6yY/fRel6KelXsaVk7GTI9lDa9jWGK1n2ZD4AtCCBtef/v5C1gR0XGertDFxwxMGef9bcOTaCrNsfn0XcjAOQtRl43LV+hXJd1J6thDX88q1dUoRmnHfegoYftGosT8ZFXTzjTmr0JppUTdX35riB7FQBF5S4ZykxindRzF45lJnvTcAil/3v2fAF3FXeP127TEeyxNVEuUH9TXrqYq0dH0yruj0xHvmZRfZ8KVxlq/Mc8da76cGY+dpURneqsKv4JZHNnOoOfX6ZK2soKRokgfYcT8Blc6zeprCXWQqBm0dQj8rM/WS1/vSrjW2zm/XGuoVarvziXa9v0de4CnyVC9A5KAgrN6CcPbX3h7dICUWsDn5uMK4mIMq1/LI0+faFfK+YgNmeYKir94s70rVbqioHkKBb/nws5bPZQQ6mcqTVVsX2wTd5xTQEfSOkKA8Groowt+NOZR03z/cBUieRBGaCezaRJlV/K5IAoJZQ9RJKII0bmXjp6XXlaLKGgNC2jdVrQGqUFswqrKvmw8ZQsgWfPv+VPH/Y9Qi57rOZdBFxYyr+uo6Py1MuU+/e1zxE52K3pberb8Ktnzpu3VvKKrhkwpUkWqRaA3Lzm9BUJU9xayN0rfHdrcf21/y4hn3yRprn8qD+iGsRsaKPj1DTpojbyyU+9OCcWl837wCsopXKVvGAT/oQw3Lk2dUunadbuf0SiMAaGXNQZ//z9vjWO5Zaw/uo2+exrqAroaghrr3qfu8guqLGtfygLEAyRvaWyPQtZHPYww+sxHgJm1sbQfesnEwysfEsa6I3tTOJ6sPpde4rPLuBHpuBaPErqfQhTtMVWL7rQraRHdCV/kVKS1Kbj3e6FUlvCjU/cfIdWHVZ1fxbUcnXAyBOaCEGQCMXE9Du8ayuc/awweM9P7ut2axXMEL5Y8ycBXKKvIaBn2DCltvBbNehrrKCwti6gU+eXcvGYLWUx6rAV9EV88TPctPNSTqWgVZHi8f6o+wCF7YcA++oFj1k0doXust73woPIfOqTEDJnbq1uPb9YeOT4iv4zEmc19AoR7GY2PreP+HSSm//vSFSYfa+yayGlRy18ycjqVzjD/ps/vdEfkFIsahDt+MWd80tusDGwovL34h4SCTjil0ZI1AJ6Rou1kxV/qi5y4kXuEK9wjk1o95aiT831jium0rIGW8CmIX/VZpVIHXGKyVXyNQ1xgaPwa2WEs4KK3GfI1ZTL+Tfyj/Fn3RZl+QcvfbIIYZj8nF/imCegP3fdfsmm6qmk/DIp2jRS0Wn9Gkv5uHzs8bBn3IeFlFx2PkAaGra0W6q8jxGlrhw3o7fa4ApAK7ayL4Qd9eCnFUwfS5Ggnt1fCv4bJmBw0vcGn9PPpdxF5PTDvmHK/1voZxmsiAbvUcS5t+d/y72IoHyHOTDhoe1naReUOjylMa8JdyiOVFKLpeVI+laxw9N6whPDwtIqG/7mUgnY6Mdu4lb0X40re7Llu0j5c611+IJ1CFqZT42+C6xLXaZTwDWIOCEIdo7QAuwa8IDTVmtwZAnSUSBixyXZeziujJOhe5rZIofTxfhQkNObqZaw+l9XjnLlzJ/KFQeQ3oLO0TA7rPmPzOIPaNVVxhYy8T8TTWO7l79aG0vzp7JIB5KLNT0kVxT6GQKt3yGH6qsWqoYmOrVar1CNTV+Wk7VVDm8ikk+oTEGsozT+U7Sq08ZS5d82xj1ZRWQUVp3PTjZpO5v+nFPubhyahTbugldKIuvNRdx10c1VaVIPqsssKbBWXGuAve5py80AE7H6X/Gr8fvk0SuXGc3JwREDJi0ISyGIV6NABSjdR6fZ1fc2RtrlGMrvetDHYfT8M+5ZN6Ul+IEehu1bp6G2vvxFcQ1h3rBgyM0wwfjCQmZ+3AR0ppj+hFzMYJ65ItwqhrXSRCmSwR3feSwl8P4OlE0G5mq/egzYYZMCAh0F8M2IXVU/A2qUD2Fr7OO2iO89Hi6GZXNte+c9h+lF5FpjUaFTB9La+gbZkdrat0Oj9FeYRw0Q/k/oQ+9afCuIvFbROPdA6r9IvQmodeRd2wgTleUNEC3ZmXLnLqQ2Pg9SApnSoONKUc1Vslv/1Dl/Jxgdpm25jLzpO9CuosGMO35FTGTI1BT+PEk/hoEzXwFJ3SNTGe4fJydRavBd3/4G16Jpm6UA3Fbq553gU19dALgJZO5Slyaf/DGYIDshaM94QCc7/7BZ68Ae18YUaA0BZNmSSdXVexyG5dyXvmCOsEvr4nlQHAQLwAE3wGwMvpN5e/hFMwgftquPSvmzDqRi4qW5pUQJfwGITQ7mIkBeZb34q4MdUiqxv3nWJ4zHvptsegaCZssAvhwkxCZ+hFiPSx88ygEjChkzLqCic62xPQ1OLN6FimrSGsMtS3rv00Rr6go2EIbZRHfRtvPVq/mwegpR6qsBMjsSCnaLMIvmPztzlfEFHv5Z3AJo7fdtG1CqIAo8rEoq++d59HY86d367z9PDFK8Yn/ZvRBnoWON0H+DPWXZBdg1+0u7HzGsPyZY1S5UnYmML9o7fywJh5z/Dd710mp3NkETVVHb81hVt/Or/6Uc8ULZxTRQei8fJxFX1pWflZD+HVTxF9CRk3pvp0b9GWiSZYt1nse9/73rsJYWHrMmNMm8m8Y7hocK0fgrcPva+lbuYSc13SFSx11yCUaYvchXa0D6GhX70EzFPExRBg3HoBfvPWMOfKqKcLWRQ6pj9PoYt/lC2mbJsMQtdydpGq9G2GV0NylIA0POVpk5f2CE/jrD0zpkak96unHkkNhPksX5rfFVpzXE+miJgCq+f1khy03QUuCxYAFX2ipKHkA1O8zi7glmb1NBg0MrJGs9fIX0OBlQfzc/+fAi3flY8rUwUCd83mRP3mHdQj2tI5L3jqvNcTtc5Yj+CHCRvzrur10Bvk7+hsba3rE2hhTJ1ThgoYLS8wmkBqvdsFpNbkXlL+S6sajFd9veQq94YIiiy7uaH3KpjvCEqJQSjdkaoOyq2bv4r+KuCeY0x2i3gV9qKLusruLxIzvgqsia0SJWQErQtWrZeQG0dj0j24qjQj/Ghyx20Qoi6qE6QyVRfyuL7651ymuuGEo2i4glHBrlJcr7AeR3mgAqutekY1LpvpZYyeLY38XxS4Rr11FWx07vFDUfGG8wo8yvP1JjvGGs7ycBd2i3Sv6B9+k9nixSgNmaJDDSQ613Mxnh794d6nuW7I5amPxtFwyN0jDbO0xU8Q8I3hFGsVJc8fzTdUp3716H/XMMxPF65lAtlj9MmsHeCzjrueHmNgjU0/6s0/0aL81ToZDjTXT+N0jX5cnftkEDZq8WrhoApOreciwUXJZTAD6Lcz8b2yrRN7/x8TCRtRtJTFlS5ONrZZN78GqmEG/auCfmK2Mt0bwmVH6qJ8OfdcxyJJAttdiJiOklYPxbP9oegtmG/cvaGGej/e7HaFG+pcdahRX6qgzHMNu3moQqlSLL3LF+qukl9gUcO3qLNzsHOkX6uM9Us/dwNREWRDFRvi7BpFx1La+7/hkycwhN8KMMSp6/kwxtbG1gB1PwtkiWanpIr0Gy6pJ73I1/1XhEUq+6sLuh6hH4xaFdXKHb3CCMtU85vF591wVlrXY+uajnDX3WMMgKZogj59nLkoGPC9+gjf3juCncNVnadvXS+rUWKk0KxeYU9OLv9e4c0XOOLByl+vfyHvE1gLSWi6EaUIbwV8V+3dUwR0A72soPu2AIxYhLPeAOvYVMErGH0tfZFFDVif1V/XTCTF6R2kXZSqe8zDubh9XWZx+2NMaODGKOzyjW98481iUd3Uo9kJRI3GtSV81EwhtLlyQnV09Jy2r+/Xt1tLUAfmP+G4ApVh1J5D393E2uzi/pNyrHLGH90Ov8qyjPykiNc4d/4WrBQdU/xFbH2uAKcK3/9VOPVi3FNj9SSETx4keSr/rmKlAGSxoJtrBTL3jZ9kg5GdyttLi7+lfedRH/1fetUA3nfX+CjXggZ9uf+PF7v4Ww8aMOn5O3fNwvGib/2T7szravx/T+38OEq2YbyC1ievFQ/bQ2UjXI238S6A2AiEvt89XWQ3F+bIZ+m9MtHw0KuuCXTSOyhCQTkUyfV5k3YFmje59/E6u1OKl6pVA1A3sZs0GJbeV0F+H3pct6v3VTFhyhOo6yOkbwIxisPWbhJPkd/HIlpTJnkEDMchdPH1MxpywRcZ6CuPB/qo228sBJ2yXqV9fbN4LJRA0RFAC3uYGV2KPu8ZcUqCVV55SbkK+alvx1kG7twtgOg9q7CKsKq4Wj++pUwKUopeS1t0ryfcPvi7oa+dlw1flV8LTFYxtf/dfFkj2mcZWuN/Cv1YlzDWetoUUr3P0hO40b+OoTF3IT4KvCEfShu/UqZdszDu7gOqDtLv8k9BmXEaa08k+HTeFKeN6rCGg3oNnQ5snRyffujBeR13jU6VenkHz91aaQ+9rGHp/HW+y2NfiCdQZVn33Pd1GDpux4omDBLhKAOEKGK0MMn9wTxFm1e0jQm11xhhFea6dCXyFYxIsVZJyeuH4KsQ3NdUM+02JITR3HflFmY7sdc35/pQMg1d9GgM9VHKkL7NZ+cNQPL6Y1G5aFd9jpBwvIRF7aJb5zaVbvr5xOwVQHNmvnpdKZpWZ0vR2MbWW0c9iSpg/PUSWKnAiYFXyaKfv5/i49snvFdau6dz0XrqCRQ81FCXHv1bP3rCJ/5eD6lhjCvl/Q191eA15Od+9C6PmEuyfnUAjJT/8SdwVfkxx64LX9ZoUdoFmdUpDcs4fv74+9bS/jDh2buHTJIl/Gtc3fznPrTufgG68InO6qnX3PnTJ2CwY+0hdOXtl0DRq3sCFd7GJxvH76CKqFhxHTTYLjAe8r9MIYrL5BDChnca5y9DrhdQpVSiGVOVGBR/E9jXCzICEApDhHn3HJz2w9gatqmS81zRehmEEcHcEAzlf99OYzUOiryZQJBVhaZeEiE7JHMfggjRNgceGtHfVf578FwRTpWpZ+vOF2lpy991tRsi8lxpv4p2jUpRM7S4oQHhFm1TJG2vSQIM8VOpMWxoiZKopwvVMlYQdeVJn8pLpRv612O2riAE2HmojOjPym8zVdTp9y6cN1RS3lhe7wZIslSD4hnzXi+9XnVP21UAzfXUyMS1dV73H7wFmqIPp3vKB+Wz6sDytz41TH0GgbddfYFHqiefQIwQexf+0XRBRz9bz6t7AnW5KuD39ymOEkpH11q5p+7VuVHf/va331jmmwjhkSvCKQ7OMpEVhPZv+1U0qlQ5YAinamIwG0P0oRu9tN1rRURSNBmFKor73YIXpLnHQgjBmHCeROcA0xGSeiX1NBpmuW97LpSiSvsOHGNRJVClaQ4W3W+cskX/N/5/83y8U6RZg20OO39Fs+tpurcCW8W1xfPdvbubvqrkqzirbIv4+nv7Zf4bG6/yqueq7xu26AJued7zNSaVF/Q3Pjy+humK9SrKiqLuPPobb6BZ56ih0HrFXQdqqKRGYhUxvlgD0WhEDV55pKFS6af2AvzBW8N43vh9brH39BB9A4x23AXD5dNGCGREqbdeTT1TZQ2yeb/nbAI1tno39dA9W9n4QtYE2tAVi5b32Z16CFbLt27WKaXvfve7bzKDjnD3kQpKSSMuq80lwpzNdKjC2zWIEsWbs4Q93EsooGGTW8aEqpuKxihgdp6FkI4+qINLyui8mYwo87vHmohnGb96JBUgCFw77jU2pxdu1kXXMhoaqAFvPHVRY5kTnfr3xqrLQ+a2PEVQeDwV/PLik6FZENDfyhsLEghW13o81763zS6uGkflZe9Xn3vLr403N8TQe6rUmm2CNl1wLSpXf5VhF0s71iq8LkKukmrf8L66u0HyChlo+2in3oaRG75RjLXpz+vNoAmApY7Ws+nYf/atMUA3+24kVdz/5HCjCPikXju5IytnUE5vWR9cL6sgqvNgrAWqBUrls5Wr9Qxf/QC5Ff4rXkNowafWvTtdi8x4AKf8hSeEh6BhjAitUoJV2FtnhVtmRCfewg30jxm6iYOCLvK7uilpCFs7TZ3EBMbAmJh8/eOWa0f9LSa+aKReV6+t4OlD67y6hK4YEX3uvHZbfRUDetdYXuk844su0kF4fY5HZCGOIcT8TaN7CdEs4Hhy2+uRvq8QanPWzI4r5Y96Yq4tSFpPqfc1/FUjtCEN9OuLftCP0i0Cr3zsuOuN6ovUSUp+PQiK94Ba2yxdlfvfAYj62TTuGtong+Lv0rJjoVRLw4KyelqeN38FZnbW17v92ltQ1bDv8cAp7kPxp6MOqJ5haBpqDXd5bsdz9Lt+eJFWafJEgwJlPGEtRDsb9Vge8/erHyCHwHW7vNRkV9M7Wf+/9v5sB7Lkys51RbL2xgZKgFQS1F/o/V9J9+ogSFQLCOcUMw8swZ/4apzpwUgyUhebYYDD3VdjzWzGbMyWrffty1pe55+F/Hf/7t/9lP55RCr9o2eVJ2JOstRJubf6prJmJHq8+/1/DO3hjoCwWfyE55XAyn36I7aTRtdzAjHntVWkEgBuvtengw0P9ShTpvZHeqXJtADddo00UgK9igT8HXcvHl8LmBeV8sQTPbZV1ox021IIhhoGH4X3ITqVQQfCSMew23r7b586p1csKArY/RYAM06BrGOqfMob18Ybh0tg1yvXiHa9HmxyFu/jV7S7DEdy0F44OktrLJOJIuzku5SodbsSx3ReacNd0SOdN1VqXzbaEjtypgTr1VXBzihjZU9gTF/Fpl/9Xu6KkNNZI+T3ecagdHVR1OJdbWiEovW7Lz2Qvjph1eEWMBnp3lBWSksnSVpcxuGbvmPYSSC9UgVXYdGj0AD8+3//7/8wm95qFxXDPYE0KClnFrO+mWeMCC07bU28r1N0ojQm5CkICnqk5ThdadH11elKhs5njBIQva4UTGXVIDkRXT8DT0F0GW5KqEgi4TadpKBdkY08V8gMzeu7vPHaV+pDSpWS6aGuATGM/6RwGoZNQ1mfKZRNP+lV9d9+GY0uiAXspiKU5ZZZxiPTX+qNkZnvh+g++51+mFIqYrPf3eczLI7d3WrdjPHpy0aKjf85OPEt+VRm5MGCojIhNlgCbumqoW6c8i791xirF86BqWfW/zsWDBhx+TxDUeKbN3gf9zqrL47b+Zv6/VJLTYorb+JsvOplN6aYniy1BbWGMjobBX1t+VlGIEGIwAHrFX4odBqAR7wmgWV4nn1KYphrKKl30FvKOtZ15fqeMP+jf/SP/jBn4f4kTZ7K6EBbb+snImEwIrZ7gRh9BBgpSArohFe00QglrKVh9Lh9Ito+K9gay/poGqn+GDrLWz1mFdXUQn0KpOr7LpPsXqOLaCEf1kutfedgTK8lY/a/+zVSyanRlf1TOdeA7hiqd42N4NJYpb3OkBPNFZ0m+63MO/+i09D56l1P2X64EqyPshBoOwfwcuGlUjXYvSYxT7r+qhcbcZk+cV5ujbp0N90hz5IjcUCH75NM6+3XhnLy13/913/IVGQQk78cw0q48Y61kKVIqrFouE1nNbacX1/ks5Fl/G1VUXrQCr4cUSOIC4e/+cSwT9mVTjEVI0NTwvJb75qX9nkpoN/+9rd/2Dr1MgLd02B2aWgRSMLQRPL7/QT1rXJ5ubzyegmw6Zssu2FuQh9ABXClXEoDday5g84nNAHPpoK0zhqzvp0IVaFMH+mNmqdez9T2ErL64kM/3utvDYACJnCY3qtvgcl6etZnRFNRrhTkxr+goODrfWtUbbN7+i1wrsGynWgsSDnvoTG5IrILrKR3zsBer14VuXX90501onrfgoFzck7w+sBWUUG0T26Lon2CdSM3eacnqjdcXxyTtGvcOkXR0rk0QVxe6ST4Xz3JwTKFogH7v0m3RbfuqY62tDBSf/eFZ0ZwRnHhjbKewQ1v1oNfp1Yno0U40maN688xBD9riWhC/BoKVNfTV+EC9wDjpYCaCI7Q7xof496wV1Axl/0IWwibALVNw3va7p1vHuDV7eRPhOu/zznsGvcASC+9fjgJ9soCuGkmhVj6rGIkED5puN/WsUAqEOUJ6pWkWNK2PvgQmcKsp1s/UtTdqsNcpWB69W+vWeVO4YxodAwav56kxlU+alAbs0B6eVSCmuPrW0MhoNQPVxmZm9Yp0GAZDb173WFS2mlIGkNt2Ef1L9munfbQaew95Z5ztYDktjDrLMTLis8TXLTcqLXf0WjbkaYajsa/oL7GwfZWHn816UfHmodvv8KH0uDd93L1zW9q9JVl9bbxvMnmnjWKh9E+uVdf42Uvj1qjuw7GN3/HsJb4gWsdk1kJpQDzPv/23/7bv/cf/+N//Dug1KAKc/LqY3YW01z9+7jz37vuEeSlff7xP/7HfwDdVt7orZvfXyXM23YCt3MBnWucfapYoRIkNi+t526InJHIU1PwnJsIbBastr3qFwCLNBpb9ejNO0mbYXV81rVen6BrntUxvnN5S41H4ZdGjqPIJePjKrKUZlOFrmwSGFQolXSV1u0RFrA2jVX9Ogw7/xB470SxgKBD4KZ+6z0bhe0SZPsgHeWNOlv0+/S51T1OPAvQ3W+9C8rrYffb3PrqhfJ1HatucWGNzwW48i2nRWDctn49qch1DnIcMppdFz492j1D0NsQ16DVdkbeaOeVIo1kJWMqnY0ucqDFA/nxi20bEeg62VlHI9ArjwilfN7yqmcEAu/W+hcJJHRd72ADCwEwRXjtPYv8PP9/8S/+xd/7m7/5mz/k9noMvXArhqsoendO5jrm2q7d7nf1hZ7z5gEtf8wzuSKJFE9D4f22p9fpsr/650Rix9aQaJzqh98/Cc3v68yzvCZaqy+5CKhK2yU/5rh9gMn6rH9XrdTXV6rP6ECjoKzadrwrGlSh3BtH77KosLJG2fFLb/O/Ae16xi0+qO/do6Ez156M2qaRjnMSplOdt3Itf3Uqw/Xp1eG7QxyjEXzAZ3QrrdQNvXkBU/1YOjY+ZXONfv1Q9y5H6VfjADhvuCnMxrlbimyE0a7HOZ5GRu5NlKP7JntfeXxxRVFRn0bZeb7wVIxx3L9IOqjcWMLlPh4KUULzLONLAyUEEVAv432cadcyvtLmaoFUOfkH+u/zwth/8k/+yR+Wt7nJW4RPYPPe9TDqt96KQttEWAKU8q+XohekYHZeI6BgO4mo11dbeR0x3/kSGa5H2sRR3oX9u3hbfwP4lNd8dUUFlcYaVZWqsTsvk+K7F0vj7ZzRjPMl9UEwNTQODOpHYF90UKolkNoQfOdaAmAf4lqPSyNZqb++3KX+rDOgl/r60LLdvL6Ufz3eV9dznlqqLQD6oFd07x8UwfgAAHvZSURBVLWOevyfHBCj8a6TlldkG010juLtRlULxpU1GI0zXjlJ7qIIjbT9MoLRSGjAKqW4SxNL/1fiQ7TLaWil1Suv7laE5dxuZFXZlUOvtHJIp+0VJ/h1kHXGl5a/yMNipVkU1BQy4Cp8f4r2b/7Nv/kp7/UG5mTLWrus2fvdY9YZh0A3g/NA/6V+XgTwQtgeANOb0TvUA3BidcPH+q/VXs/BkLxvgT0h2LC0bwUlmurddE6l2+jEexZw+62nrZe1QLoe0Bqvrq+9vB9XRDhxtX1p3AquNPa6eLdKfIXoTt7r6Ro1rTH4g9BPuiMaCxR6ftJ9lfjyAtdAKDMCqk7QpqyMUi75KGJKJzKCRalu+5HjpnOUDOjJ1s+dtC39Wf2mvDbqsgikRqyNZaO9rvG8tElm0tX6oUOSzi7PxYDd4uJXswdVxzRkTZZ7vv45edxqqs69iOCddytsi/L/rutZgp5ZSNedYFdGwrxdoeRYvqkReA33AgUfYLJzAsGLAF5+LE/+HdMQbNro1fsAPiNT/T3l9wTxAf9bmvq+WwZqCqGlbRFNy1kkoFfuk6oLYJsTN7yOAd3bPQrgAkZCoAcr3YwiEpAA19VWeqgVPWOFzWsvQM3rMc+9+dB+F3ouwHZeeuuRdF2T/3mjedftkeTyVVNZ8uUnoWVTsOhkOqR74pnr2e2v249Uh7xzbkMZqp2lu31XUQNWHYfOOXn8rmmxQ/IXjaKFBjIaKRet8VcnylebWm1sOkUrs9JbWgtOetVGVdJGQ7cOkQ5OeNB5Vyt1zBU76l6ymeFRluq3UZ3G78fZCsTJ2E8GRSMhn9sqJl6+0sIXd0xW1/z/6npOc3qSoTPNFx19h3dtib/2+ZtNDLdO2Jyk3rLexVs29SaCG9h7PqAQqZRQVrmVPQ3C16h1zbv3Tf726HURyVsNpDCo8AlBcw96OKY71nKmqIKmRkUAWmAQ+C4P3fBOoaquSyGXsf3eOlTeXYqYMDeX0nUBQv83z+o4BBs9u+o3SolOmyaJxj6dWR8EUSM3QaR+vvPbF/fXr+1d+tj9O/8jnfRq9fQWHOXbHu/YbrUQcOQMmerKo29xRHK00cOVznSi3SXR9UF511O1nsvL1MBJLyeYjcJ2tc4WZUHaKv/9dqlxxwN5Iwnloj45sX9FzUa3Px7RneOovfhnGk0+vZIBNgPRe7zL/WsIliavvPPtZlq6xxViZirC5SJ0afvNjcDz1lt90+57NlQYlCV7zwMICr0sxhU2bbda7r/r8tLe+ZZ6vjduPQPQ9a72qX3BLqanFLtZlukixxGYCcgZAz11gTJhXo9JBVuFEPBWwdd7MjK5wL9rXPpY3Zv3tI8JmV5G9+pZ+/R2ita5+mDqyTXZpheMVOSdEdcqhtGOEY7GxTRAoGhKR3B4n4B5De4FRPJtZSAPTTlIaRdI5Fdjqs8tknh0fumAXhoviCWXyoug1H5Y+0BeBq9+uueVstNYk2O978oaoI4p5/JEwNrJUfVtHRvPvzrcuuNTFK0uxZtXXBYroK+s/Uj7zjN03kjOuTKdV41F/6PF48nDr90Y0kjK6OZ92s21h9PSI1ddXtgjb755OujlFMv36wVEmP7/p//0n36aEM6zaQOl3hOQIL6UTkojY/KG3sD/6T/9pz9N/rrNcRs8CcACWiXCZilLZXjNK7v6IsaZW64kjKWCApidXJUJgmv3RLfNMwv83es9TmIqbEYMlv7npe3kVB553p+Gpr4VlZn7XCDwe9MvGuXGnEMQHQJm+7iGQPD0fzwRZPReo0/9j18+4yGg2w9lyfZtY/skfazDcfnUbWPQ0OblbdRVWzk47YXlczA+9R5td65so5d+J/cbbSgP6kU8Vvc0nq4MyjBsWmuN7hqBNdYLmHttbbzS0uLoq+HQgLxiJHQZNo2lRuhh0aP5c2DbB03nIfr0boFXHhb6noDqr5Rt6R3ipfTWqeu6+O/iha8tX20EXjjzOvE63jLMhOZ9l4N8aZ+XBnrXuF933tFT/ldXm6z19GODaUL5eTb//J//8z9M/r7rI2QDLtLwKd81TDEs671rb2tXb329ZcFIgXxFA1Y7gsQlsAq6CrGAYlpFkNOIWF/3Wqfh/yvmMUsT2O/GqZC75tlxaVD1LDuW8q2Ry6Mp9+0OiUWYzRtU5M81ZpV3c8iuLNsoK3BNjj95vkYznhfENhxXVtZzzRA5UV7qwNVnj0bNC+kNtgRafcgwmAJzfNtv5aExXuC3PBfgfLhSENvlu1u3/+O9EaZALvBGK43OGmcNqalBjUiR1a+ORSLKgOfElF2543NDLpjROYs/nTNVvRFBuPTKiwyTi3RqDV181wB980jggXCdbl//wsaWjD6B/Q//4T/8BPQaADvVTp513tCuyOGFTS8CeHMA7/rmAF7J00loXK+fsJr71/vJg5H5MdScvzm7XbJY+QS+hu0dV7gU1NqO8easjQCMUEwH7LfC2moOo5YU/Y2vMPmV6t99oKJhCpcx/wTq0rh6N9oxOlij5gTyK+3yuqDhdwD/Sv1rqbD9EwheW4KihkswWC+wvmtM7I/jXGMhQMbHFhm4SikwyHt/NHDDwgA9I1AayHGsobvkUBltXHud4/fa2jFlGA3WEDqpfRmY+v3JgF40rF7nkSzKmvhS2+m/x19p3I01HV2vfp0B+xpfnnNbHTpX6aVGwvSOdYVFL2p4NPSNf/umOZ/1uOYdv4kR6O02rvQRZN7vNxn8toUoUmigefjl88v3Z0RaafQG+1I///Jf/sufvvP83+ADSpdpXQzpv8qsQeicHvwrC9AbdqlQeowbJejded+Cv//XC7M/CcMrpigWnPRUFmTrn15SxQjD1UvSpj58SbBSyPpofvQKczPsCXCKWR82RbggtlFS/dZgXl5efbhSO9FtJx41yitv8mKXS24qY2Uqg5muSMv69n4/vQl0i3hfnS351Jt3me32xX5v1LxF0NUAvOJEuaC6cqXB0cnSSdDAu9a++zY1uIZ5Af+SXx0Reb48/AFdXPnf9pSZ7fOT57ar2RWUOrKOLZkzSxGtX3mO9fuEi4svLaX/FNF8EyOQdSt8iSgJ5+vsmwsoxE/wyns9715PXCXPsLyJ53/9r//1TymgXvrSiofXlq9lVBn0ZGTYeqF9Cp9rV+Fz8i1AqMhwmbrCpZDIqP1fnaakFnhU7vokuBr56MFsznsnu1VMgdoleO4LdKVfzAWb+tH7E6Q/Kbdr2g2LLwOvMaj90lnSRJlYb3E9UkNwz69MxaNrgn4VTiUUoFZWzMHn9CTbm8Jow7LSQm5z4hxMfTdCk5brwFiUceXJCEMDovNiGkb9W0Ps9iXy1LmnV4pa1cE1yOrbxYerbB2/m2dWXPm4zpoGrHu9J8f38eNhns6K86jh2oUdV0Tw7n1GoK09nsPsveFsKfuvpcVPsvNVV/1eAfJYWj5WR90zw1UiTWw9UI/gdTaA7X28L/3zPj38VQ4s78e1zT71u5OBelzXwxkJ9qurCePW8Fbf5WFsOztxqKd5gb7X6KFpLLxn77XvgqQTvtXhU4d6FNIu4FOQLRpylV5vyS12u+cCfUE2Wvbik5TDuYn3bV57Uz96YNUnTTVIOgoaGuVlIxWNdP030qu/G2EIoPbdeuRj1/aeCtNU0SrHKQPgw14aPg358vcC+/WelWN/B8TXOOP3Rh7WE528JnkKS3TozHlrpDftd3n6ju2TYVjZ/OHgt9dES2V/HQwxQxl617z5z8a58wQZPvu66dbaePc9J/zND7xFMj4gFi2LBuTZ15Sf9T6BnQx5g2yVzksF9X7g15nX2XfPC1/edeXI9AKaM3hG4l/9q3/1h7kF31JkCLxg6moVwWlBbcFzPfGMTcecYd80inV4jWBk/Y1VAVf5LqNjznWVb8cSXeqDOcFopGAHYJ6rbpfROmFpXlTj1D0KsMCoUmzJ6Pru1Fd6sny9eseoh25EE1jaT+to3DkHArNGYT1Pz2c0rS+QaI5rHYg1JLa/gJMxuNamt+rH1JC0MCq6AEBjuONyrNKk+pZGOi5r5C+nR/pl9N6x5MC2bCc53HkxvXXly7GsLjo35DU/fHjXg3qv7Kxx2SjbnP37/xxbDYE6oaFX/taRfH1+dbawxnm+rk1vdhzf9GGxclx1rvX679hbFVS6qIddXmffANuytlRRzH/H2vgtMG5iJYHZJxoVlIQkUL7CQ4V9vQO924TEfYIk5oKbTNpVBjFZZVllWM/FawS6yzPa9hun3lIP3NW/T5N4jrUlm3p+hueWVYjNgTuuHasGqbSVY7pSF/Xdbw2D4+keQVJw6l4jhkpjWMOlUdq+ZVB1lD7dU78EzHjjctadU9Ehuh6u+7Q8WtD+JHefxqoOrfHvnHJldGYb2476G98at9FN1+XYqAdGWgvie0xZth/L+1euB9Gks1H3YsimMqvvXdO7hfeZB1NRGgTpUXn/W3JfSvBy+DaN+U3TQU34llIIoF8E0K55PVj0IoR3PuOR1/hK/9+mb28eoDWwbWn7jMBa14gg41aJr/zjJQDrVVqH+d4U2zr1niP+Rgbm/gTzzaurNIa00jYhMddoLtVw9ROgxb9+61XVb5dRvraeoK1CrLeTECvMlvVG1zALlh2XBnvP5bkt7Xf8gr0G0bGs0VLpNbYL5mvYNQQCXuDu3I07sL773dHTPHK0FiSc61EPkt+ObWkurbKpwuTJFI/jXmfIPqhH8mB5vI5cMp3xbD5JmTKKii47sa1cbB+UH3mnA/iJJsrkGlN5/ynqf/U59+hWEMps1xql1z9l/PHw4W3zQTnc3rN6902fGG43xDoe0Z4BeB0LOHrtpI+/ZyAi4gP/9xyAb+jy0ejN8/kYtm3HsIrAr5e+VntzkbW3iujyLT3+wGUNUP2RcY3JsDqGv6KiJUAakOrr/05MqiDSwGvWg93+N1cTrbunovFMQVJWPSvTERupJAcq9Y4jgNNIL0/Xw1t5FACWBhpOj63iyGMdiAWk7c/yrehZj77rnJ/RcLzzvqvCFT/JpzrRb+V5x6K+SF/1Rh3bcehhXgCrs7Npxk/RQfx2uacAGn2NcDvfJGj011nqugVs/69sv6JzI6g6F3U5Jeq5q6B2ru59emDs1em7AF5ZB8Ocv5+Hsw9jd15KA/lzooGfFQkIGAJIT/i+DrSBVc8SREhfh/YigGcA3rUKvHm3BF8rn0IqoJeAVbxWJTN8apI7gYwZ5dgWkBIic36VyxgF4KYA9tF9V51Y1iter3AB0PAxGtoXlar6mpeRLtu+3rCGOUB3zEZDGr7qU7nMa766e+bjMmCG2ir28l250Oh6fkNsDVWyssAmvQUN71OG62e0rv/Nib02etamugMbUz+vuILo8tCrTxDdsdnnBfNNVXVsgVLHZo2tqStppUOj/C3tkpXlz0Z6K5fdu47BziEqS0YZP37Aj/pdhLKe/2YEHE88aDxlRIz6Wiq/W6kroxkRad8EcNvrXIZcJ+ebGoE8msAqorzvZ5na5+cNrtRQhuCVjMQ/+2f/7KdVQK1yaLBOdOl1RngfQlpl2JSNQHV5qmtZI6DA9O7rSVYJ+65pV09p0D0LzDL3J4LP4/XRc8NpPRcVeUNUz3mtE90JR4rWiqiEfGlhv312YGlqykPBr82E1nkd+fb60MKC+m0/BBQFXkWULkszaaIRsW5p19jcW6iyEV/9Uvk3X6yXL69UbN/bvQYwMNjoqCLd04/d8iH+Xumhlc91MBZYlac2ftQT11mQLvWttJgGQd4ufy+jIg2lv5O+3bN039RP9/84zsRFg8Z2pVuSqcUWncdSXunhc3h6gUwPA0ar+u1Gf9K11HzPT9n3pcs3nxh2NU7FyeJ2yusTgDYr/pY2vSig5X++PF1vS49axV1vZvPsGyGst2i+VuYHVPW5p+/0TAQ91zPvipgVDEHpEuZPSqYSKVj2Q2DVUw9Q9Do1oM8gd3wNo7Rar2kjqfqgxxpA6KUZxelhJUc7X7Gee7TUQdgoRYVeI1JJthZgpHXfjb/weg2FdLpSHvbN/9Wdw/H+51TsktvAfVeJXTK1Hvx6+TvGHc/lACxIC0Su4nF8XX/RszHFgx1LMvmpLo2D8uhYdleAdcq8x/7/eOT2X12uZtzUzvLgkzMiuBsNlRoq2tAZcFse2679JzOtphQfzHh8bflZG8jJiFIoNdqLYNokzpc0PyPxDEApILe6Xe/RgTaRtcSVoftb5ibcrtG9vPdSXTEg7zeBkgkyI69xQVTBuv6voFTWg1hgri+eF1TytKRhCqvyr6Lpsb/fRW96mhoElc4xbYi9AmqbrgIJbAWLrnFyUMOyXt4nugskGv+VJ1M/15rtQGGBaCPSLcl4dUXnnSt495obL/dvFLVjjSY6UCtzK1/Kbuet67qu/wv8C6SmfT7Jvf26oiTbWzlfj1jjnDOpLFXvlyKAHw6eyXf1S4fqWiDiPdJPw+Q8g9vo+06VV4rWlWPrz7lWLnRqV16+iRFw0zj3nWn7h9eB98DY+1/+v5zXC1vaDbQowLz4CkjbCbyPL7iPqHmbHTe8rkQ4gWlLoL9AlQEKDNejWGW5cnPrHSSc60E4Cbb5TYW+fijUqzAZPA1a/Nr8Y3ULeqWIVIzt4ypyvNAbVrkEKSOD/qtkjsv2DPWlgwZCOfKTJ2X7gsfKoPQ3tFbmdoGAUVj9e2Wdm8ZotKpBlJ/OCQgC0rJz0v6T8i/fPjkq+9vifV9qZ//b9hqqjUIE/cpGIgvczoNFu3i0D4zuOH88FhnUT+WvY6Z0ksG9r+vkt2nvosCcmVLQu7200d0rtrVOQ2NwPvVry1cbgXL6bjLWIPKee4Wak8K9C7htI0z9LPDFbPNnMklgWOJEcFNVK1ybRvGc9WiRvUbF97h93MnrBW1/O3ErcNtP0w3bX2nS5wJG31erN207Cf0aIcF203SVhHFDcD0f38JWiVbRwb5vyuhyFpxoq3xKbejNKisLjmuM9Ab1mq/+XLTJMEu7jK0reuz/9nHlzv8Lmtf4F+gu5+tykuTTJfcLxhqreK1erw6tsyENLmOpcdUQixNeLz3WgencK55bJ0+nZXW0dLf9u4yjetb979MT86+O1v27WeDFE+deAnxxwO8v8fTPetF8xLEBUyytFCpCeGmgHnN2f5MlrIQTtF4pbHL51jKqfpjD7b9MXg8ob3GjhpRTQNOqrxFRuJc+qwD1K1oECqssF70zNIFz3+YC9VwvjyCaB1Aam83JX4ZTWmowu3aXxukQdG/yIL877v2vrHG0Do8t4OyYBftdhLA89pxyp/ytLHfftUps5UJASS/ajljPU6CUl5cH+8lRWfo0VsH40otPztLl2OjVm+LZKMB+rp7sONUX+eE44o90Sq7XcK8x6fdvZlmrzuYaNPtXO9Kz8+b5HVf9icfOA+Vg683bj8shWsMW/S9n4JvMCTRYQUxr6aPcb5BvnuAZgHaMjNiuY92BLDM8txZ7Q71VkstLs93aCEgFkU0Teb31X7nfjQQUpI699nwF3iXknxS29qL5jifv4pVdjtp5jaT0vQDEYwuQe6/07phRwKbsUpZ9AKq6XEa6fFyapACC/PJt+7eAYvst7ctjVwkd6wW8Gha9t9Wf2s4AOE+mV7cpnx2LMvnJCGbgN9rrHuVWGTQVpzzosauXGvHl6aZ2/phuraGyHYtGfV9yL53VsTVOlb1nDcO261L4rl1Zcjwb3b1Pi2vaNcF3LRuJa2gu4yJerQx8k+cENtzIi43YPSz2fr95gF5Ek1DLgPV81/OzjQWv3R9f5dfDXVAzNLRuGahymMN3+ZzMrWybmwpawc4T0Auz/9H8svSFovbbsSg4rwgq9nPLhucCvN5Y5+2b0ZyTX9uuz4S879Y79yl14jW2Y+pIwLMfqwSXp7v1rtw1RucUvP8yeqZyLg9yJwYFfp8FqK7u34k+DdeOZQHVosOmsyFgJ1tGm7azsrFtSTv7tLq87dY/x6CufnJO9n944KKOlWHrf8WUzxqipbk6vRGrtL2M8OqXkbeOm+8cqJ13bYaivmjQpZ39+EUeFkuAn3dfxzpXJx8D3h7ovfpOb0IiLrg3YXwRTAZtakpidmyBUwG26E13bW1siLlrrQWcJbpW+crvreW2nR2/EYFGJZoFFArOCkUAu32wfQHE/smvZGHBqnqce1hQ6rihrvvhm4LbiVHpI+Bvfl4ZE/Dtw+U5WZ/GZfm7gCbdllb7XwNRDjjPL5rsy93XWbK95ZljWxnv24/3Sy83dVtjr9zXX9vZtFl902h9CaB2PNLVY1fUWj8F4vq9Omj/fpiH2dYoaSQqGrPNADg+68oJWI/elXL15eHmc6rtk9HNtSLsouM3NQJ12vx8mxm9h8PaH+MN4E0Ctx206YO8eJXXR9VfMS2jAq03qkUs2lgP5wKBnwY9e92vkHvdekNes0CxQrkezIaXr+jJG2kpRI5LI7Vey65U8FyKrae212xaZMFf77S+mirYieOUY58MzsP2YRi3SdiHlqSBKyak+6WkyoHptR3/HnP10K7wEZy3rQvANg3RsXL/+3Twetn7FLl9WZquTMrbTb+skVL2TLV5f9fuhLp933ScPLycnT0uGC74fqKxsup10nt1yjZ+Q9SjIevcOkrvWOkanSFp1jY5gfz2U327cOjdkyHYBReXoVoZ+2Qc/iwj8CpsFvuBvK83c2KzzeAU3gC38x7PMKy3FSFWALSM/e7x+w2RIpiKssusOr452OthmJitYn/y0LbPu9+PT+Jq3ASqpd8yViCsLAh0v/39tOTT+3d55BrDHdun8dtW9S8wX16bbdTOtQrkjxlmlXoVxjrsxyWHr5iW2ahQ42p7AYbj9+UwrpZbGREoHJ+8vAxf924EsGBehL4AF/gZOdquD/et7snTTUP+sbJRjM6hvFpHqHZ1VjR6a0jk/Y/weefZdDwXXKOdfBBXuq791uJtKaQ1Wlcfo9/q4ieafi2d/6zVQe/TY/7vobC2R20jpJcCSrBVis63VfECs6CqNyoYWy4v4iKI9S0wSFCF9wL/XZImUNjXPb6MXi9yFVZAcpwaUSMk+7T06Ld51/UeBFvPx5MN21Ua6SPAXZ6ydarAPSm7snDVfXne27Z9yxO9jL5j1gPeMVyOxI5J2sib9983PMnDFkoUDe3kfX31mYA1VsuH1QmBv095ZzdEa/ymnHTKql/5W354nSk918bb95VH5f2PGWfPrXx8kmENxRrDX83k/jqFn2i8xXFt3T1z5NyP+X0XD5jOfaVXr64D5DXrtKyx/6YvlXlEfE+3tVd9KaAE9k0ER/wApjREcwNN/LkSovKJITLZ5Z+dN23jZGJP3VmH3tX7dt8eGW1/XtkVTQsUXb8Tg3pXKqilvndu99e/DN0liF7Tt2uJOy7tFjz9v2Un39fIrjdWHY1fI2b/4ltbJ2Qclq5/DBD10vSkLmN80dD0wJWSkq6XAxJdr8lCaeeEsI7OgtiC88rMGnbHKPDHqwyAxmIdGZ0GeXXRYKMIV08tT17Zp5/Xeclox9t1JqTHRqXLGw1R1/ek9jpZf8uGiru8srX8Pbu0aR+jaecGOuZWKi2Ffsd6ILbnr3YcYpyGYOXg0tWl+zeNBN5yz34HsO6A2SsNtc6lkBq04WLG4hKKrtOaKwjdv0sILyZvmkhAqd72DlpPSKEsItgc3UXsaGBKq/r3eoX/nXPL7gWhQGqZfXkCm4+svk9An9ItIHn+kxHUuH7JexK4XSJb/W5MJn3i14bgKV4pl40sHJOypyHRw9TZkF7SRaWPJ4Jucm/aRQOwKQ714pNx37TQBcr1RWPmw0wrH8urxhmdM86OLZk2nx1tizAuI13J2KdL6tUVee54rbvxJjfSzkhoZXhB+69+nwYyKmy86sG+yN221nheS7dfaTsdNwWUjspT9xcx7tzkl0D+FzECvfg9RhcNpHhPuN9H799QUwHK+1Y5VLYFjEsxNAA7IarQRuS2nzAK0AMTMPU2VBj/X32rDyleYPZpSaZ99XdKpSe0Odf6d3lq0bmyaSP7+soahQWZjtnnTwbC6KDj0suxeU2C3lg3j78pA/loPdFFgNboSx/pKzBcKY9tSxqbSur/5tOLLlL+a8mx7awhs3xyOvJqA/DL2Khn9c1zgv2mH9cg6g3bTteFA7tL7sqS813y2WtWblcmfOBTUN7U6fLpV5Nnty/rENkHeZks9I7fyj4pHk3bVUF6iZG2lSzrdC9PL/z4RYzAMwCvcy98Sfhd1ua+Qs6MB4Kv7GsjUzgFZL3ciGLuXoIqgFn2mFk9XVu7lfX69P62rQW5FVLPv7LvABVoZbIgdHl33td4nVS+GO61GkTnV9bgSg+FXhD65FVtux7fe63TaE850DHY/i5NKq2tXnBY/jk+x9YzDStflyItL3OGlI+W82mofQ7A9NAaRY325uzXAxUI4nNOh6CyLyBfo6BsNIbL8JuOlRYaHcFVo11evPqM+OzLgtonjz66CJgZn3VABfRPvFznyXuNDjR8znnYH+nSWF+pvt65vrn7yykoOt5o4E8B/D87EnCVQ52Jkb1v2OWaEjIlzeNeRTWUFxhXKWWaK5Q67/1aab399Ui+5BWXE1yhF5C9XmDNM8so2QdfSr6AtIC1NNk21pOoHypTHvGC8xoC6a6ibXi9YLQG6dOj7tXrNiI5Dzs/tGk8+yJALO8aZ/lX25eu/W4xw3p6ja1ja+Qugxmo2x9BtY9gaIpvyzodjl+v1ed4Nle/8rRA5bmudTKya4xo33cp3h3jypS067mi8MD5l6tfq3MLeOpB500Jbo5+6fHjbFConqtTG3X739U7ee3u8tkbFjUMa6il0xrw2q/u7ctlIH9O+VnPCbjFcB1pksttIZzY9P5WRFwW/5VlgOUCAoU9D+CnQc2LuK0zL+0T8RZMu+fTq94UCg3MFZJqPDQ2AsoWaWTOdcH8E892ddUaK/PRO+bLE9Mj9/91XDDsu+PJTddcL3KpL9JGx0Bw1PPzXgH9KuZ5r9TBbj8gPXVkul858BrToIJafb9Waq1ebH5eHXCFSf9XPuJldJenm46orU31KMtudewyUeVGcPeBqq8BLvsnfa7v67rw6ZU1aHvvr0m3KgOb9lVvfVdK7Skrr+2HG0Zgtvuubzvx5FDaSPscmpdNaadmabDj+kVfKlPnWu55rT4xv9tvl459ArHdZqDzTj7FsM2Vq6QCx6Z81vPx2NWvFViv3XPLwAV4DUP3L3jp/epdXYZyvaOlW6W2N8wvKlkhvyKD2nZ5oSCv92cdHd9lw4LG8kY67PFX7HPnXIFV3+Tvxevkuvv1/qtrl9gaFcVj+7qpoYxbRkB5eB8fmPN47bhO/PL+lueX87XnXOUSrdWpy8hdvFAn5fWOZ3XEOsMLU7HqtkDosWuM6/HHl2i8c3NXFPHDyFA8WwMmbd4xd4ZtS5e+pb/6nD5236U/8atvI4010vLlOv5NlohmHV3+GbHesZY7ZSRSMAmWAJr3LMe9ecnddbRzG34lTFnUaxmpQtPeKDE5gjUehdjVT6ZwrH8JvxZd5n+JOVv3GhGVMZpKux1n/zXA1eV8zAJLfRY8BfPaV0Ctu/uVDUN+93sXVOtz7V2pl0/9dbzbZ2m3oGl/3bQr2XNuy3mp+iI4XMZPOgfo0aM2Ls9NWVd3PGYqZuVlo7BL1jwngK48p6+O3YUeOhmbCmp80dEovjbbPbN+d40RqsZjDZtt2YeNYOPFLiR5ZeVpU1OfdqzV+SgaKzpoIjdj4L5YfnzWyihyDfcryU/3vSLvfw74/0lPDMe8F5I04DrwJjp6B/H7717ZCU4THBJil2E1qL4Fik3V6MnEZGfnL89YYyaR3fxtJ6cVLoVV4tv3y+qr1HphO3b7etVpfRrAy8D4X1r2MV8uzRUmwfi15yqrfRJ2DYuergZBAZZfC4arDBtt6B3LL5V004rrRe/4K8pmIBDNpekaBduunk0PSRe90KuP66W+ohd43Sd4VwQPI4wF5Xi19Fi6LSg6/uVfv3cZZX0NAF/Z1VlX6m9TWcrgnqvfPg0sb19ZPV4HSGyR9vIvPu+SXNNFy1OdoXes7fdLYa2hik85ENKt85sh+eYvmlfwFJLXmTY7agB58lrF13nfStZ1huGbyjEPvnk1FasoIKupx1vfU7wEPjAqR2rKpBBP0P6knJ8EaI+t0giO0nPB/vJ8osce12B13U7CpmhLw+5XQeKL43D8/d7ltRpZx/WK9avY2/8rl78GXLrlUbU5m/VfBsZzHXsl46jR17vuuGNe4/OKq85MBQnOm+7bb+kfCOwyQfngOJYHlwG9PO4LvK3D1E2e8DpzG42vIds00gPAdHQXjqgLqxPVtc7IzomoE/Vvx/XjeN0ddxzxsetWd528XUdTOfKjkWjpqNuvL99Km4ttl9H+2vKzXi8pM/VCnwFoS+D1EiJSA3idbmVARNO4yNyu1xuIaLvtrmkKowYZuLtf6oVkgd0bXAHcUDcGeMxx2sYqoUzTw1/PLnorBN5/GRsVMSCNbl678yyNqfv87p7q0wNS4Xbt+6aoLmVYw+J11/jqe/TYqCnaCFSek04L2vLah31SePPD8qfza4j1EO3vZSAFyU0vdXyXJ64hdTwLPttPUxmVwKvzlzOhfqlzS+fada5lwWrl2pV0badRW5cBkN6XnKx+KdM6Q39LFkD+WcfqlNevwV7e24eLn9LwHcsgqpvr9ER/d3y9xv1NjcAD+rcMtA7k3fzP//k/f/rk5a/3Xsij5cySRbSMRgomaOkpa41NO6ziu9RUYyOAuHTM/LQhX5FMUUz/NYQWhUeFW2FXcBSQNRYKxyr/gl/FVNv27wLX/a0XZFsJ5QKnQm+frVevqN8+lS24CkLXhmoK9npbX/KAPyn5JyOkUbYPrv7w2YJP/LhWw8ljeWJfoqdp15Wdq5i626hdPu5Tu/IpnTVNkn6oR8pD7Znu1VgnIzs31fheqY4wYsdR2Whi9Wb1w77tPM8P49yVbqkdjVl9ylGMRmFE7/FeJ9LVlNFZg756XebEVYwaoXXujCQWS76pEXhA3xLPiPkG/V//63/9O4S+Gt/lmiq+xuICRutI2ATF9/v1K1A3dVS5PKML1BQuAbyVUHr6KteOWRBZkIrJ6xls+LqAt2H60mk/nd+2+jgJX1tu6331OyEXFJoHcvI3MPFRfsdTnzZ03qhplyxGh4unHdPz1LteoFcGPbbGTXCwno0ul5/1b9NcG9kt+HfP++8Lm9Yx+GTI1+AYlddn0zfyeid/azO6Lj03apGG0qlxZfyV+V2RlQHZCPYyorax+qJTosHy+YzG+puZW3MyvvoD7p5zCG92ErhxZCi6dos6bwblHe8d7a/oyO2Y67vLRav7S47in2wE3q6hb5fQcvrv89vf/vanCOFNFPsU63o/AvdaNQen0lRX4NyGW0YFrjOP2QqEwC4YrlLpGW7KaBnmtSqP/63XcS5gSaMrreTHVIx9W2Veg2RKStppABdgtp6u02uTr4H0gtrOzVg0BNJqZcA+eN0lN6VsKoJfsrR8uZRsDcYlr52X/8v3T/duGmzprEzEE/skrS76mFoQZPe+rtUwrdHca6zPqPPTttPJgS/LaUyrOzpmAWngWISx4728Xw238ljdV3rph8GNV/L+k/vFl088NWrTgCz2rUPqXNQb+85vKe+1s/Rf2f3mE8MvV/U2kXsde7+fERBkApj1SFJ2re5uNqVgrCUrdM0ICCASQ8bup2hhvUYteIQuJaQgGAVc/RUcV1EVjgtga2eLdSeo0UXPZp8+VagXoLtOWlyGWmEWsMrTms90We4FbEurjif4mxuNx5+M5CcAFaQ0jvLjcjZqN5pf6ZDaV2alczQpLer5NdxXBHnJr6Bp2sD71qmp/6ZmNoedvG3OWQD2WLrSeDb9tc6VEYVAfHnz6bBzLv1/30aatrkRh/VfAPiubwmw/f71EWlIa2l8yYSysGlox5K+uVTadjRQu6BGeV26d70r9Tz/zV803xa/r+H/8l/+y0//N1VSiBTwmnYwB+nAJbYlQHYrVd9MJhgtQ9czuEI8AWaFKIB1smw9/erxXlcdfPLYFpRWkPdaxxEd98Gj9T62nsvTuYzRtukx71sAWa9uAfNTne43Vb9NBWx9m5br/MqRvNKT9R5ppLGo/pTeVWf2ayPZjOsrTy/cYGx5vv1eum+6K9n65EjY9zWA3vsl/qysCkzq3NJw+/Y+zaM59uSwTIGG1ahdsAxP1ghYPumMEUH48Slq+zUOScXxWI91JReWxrnzjuKVOlM6RyOTAS1F67MUl6Ow0eUnY/hnG4EY2CslndCLUK7mibgbIfS9uUOVLABOYLKOa1CWaRHg8pz1BFaYF1Drh/csUWPcKncM/FSkzycvadtUGPdbA7BGaJVCmq/irbe9oBGvdz7heWt5vxbvE1BWsQx33WL3Gu8u/ZR/23b177MjjXsnRpd+n4zeGllpXz3brnxa4Nz5IIFpPX35YgSlh+7ePJ/4/skrr54crsryzXqlq3z0Gh0Yi3KUTl7zgxuBrOOjnEujIgCBO56LDb87lnSauWj+yonfro9uTkBrALZPl0Pg+I0GjBQaj8ZII6o8fDKYf/YTw3X2zQ+0J0bWLKGrc7uSpk7pwRrSVU+ENwLICFwe7A5YoiooepCCX+1tWJZXYK4tI6RnaV22p1Jsnz+B/eU1VpcCtx7tK6bI9Arsx9Z7KZr/tw0VxuMaeOtWoBe83/GMfPcGOku7rr/Gu2VB075Uz9YvQCVnTsius2LdrnbRyL2S/AsQ8k7ZCjx2jsK+yQ8VP9nWefnEq3TJfujIKWcre0tni3V5zUYIa3zUS+kWHpTqXKO03r7HAsomZd2sbSf4X7nk8zJ2r/088t2NVbCvaFR1Ll65AFvahIHK08rhyuL/kXTQI9abC3hRQLkqw506qkC1WiMhTkh3R8Lq94k5Q0cZosC51tfrvgS6EvKVBdis/XoX66l9yvX5fyOgLetxJlSucOlbg2VabT3HFU7nYbp+ebZ00sBJp4T5lWsNtPV3jWOR16b29BgvWskDAV0+VgQevcpPBkpFMmXgyos1mCuDl6ExAg58TH0kK/2+eOCYpEEyorytPDv+eLc0XP6tR++8m9d/csg8tgZvdXllSKNW/TuncEVXa/iT9VbyGAXEk029/AYHYHkjj10Y435qSyP1pPPKhG1fBvUdf6/yNYUklqyO125O82LgNzECKe0zAm+5aB3oIxhKEBmolxOxFZTXxrO0EmWFbb2oBdCIsfdEWPv2iky2yKjqXKurMqTcWvrGJK3WOG1fF0yrez2e9dB2BYGfT8Kz6Z+9/wLkFNGx7DK/nWS2JAe7cdrmfBeoVtE3ulmvSNpsGmF5WR1Xai8Af9+uPJKOGbrLqMqDjTalXaDkDriCYX02mrXs2/CWZxkE25dmfmvElhd+r2e6UZCOkcZeuvtRpzc6MI2zNNxUjnn7wN8lm1ebr2yKKCxzt9RXwot9Mj2alkVwawezCqYAK6u3r+QQP8xtO2qvr91Sqpcx/OZ7B71Bv1TQ+2QRHXyK5FyB20ToFbaCIaK/unvpTAL7CYQuIPokqEvkmLBedLnD6r/ywoLjerVeuyuFlnGd+8QsPWNpK/AIBBez1+B4b/foSdsXhekyrIKmfTQsTijdgE/DYl56I4vl9YKRxy/DKiApo5uavAzUyo4pFSM06WB7a3DSA691UrFoaCdRN/25oLgyJVhKO3/vmDZKuuq/nJZo2bhXfoqwlOerrKOgkbucMudZ1DF1+IHuS1X3Yquietf3J7uuuntlDVWOSg+CmWbtvHMfPj+lIdDQr+GLXosp6mr17hzAyvbK+9eWrzYCWb7//J//8x8mAjf00OtU6HfQ65E98H8fQeAyAJWOmyd9ZZeAWTYy6X6P9VtF2LDQ9ju/aZOlwfb7E4O2Xf+vpyUIridgX5f20v1TX5ZXGp1Ae8HSMRvSO/laHzfv/aloMDbls8CyoLfpk/3Yd+nr8frsQ0DVr9LZZrnjLz0g9L6T1TVMVwpuP9e56q8fAuPSp3ZKo3peo6y3vTKh7tu+/LZt6+jYOiTyYNvWYbmMSv1uHzPB39U3RgKbifhx3pDWnM5GE/W7OQKNXs7pNcdyrRw0SleW+15nVCOvvLqoRrr+IquD2i5ahTfl8Qj+CNP1m4MrXHqlNdUZAI9rddezurw5vTUJeQ6a3TMl1C6tiwmVbVMjsoTfCEJQ2rRA9ZrX3TmF9RY3PFagF9ykp2mgNeCfjINemP3Qm6osb6Jf15kKWhCTfnqFV940+mn49Eg3WtKg2IY8sv1+O58lPd36ZPut8ds2nWfwXregUN52/JfxU45sSxmrHUHWNIopoO1b7SyomP6r6ACsLK2c2W+dBq+JVl1bduEqbt9QNCD+ZAQWI351TFa//71IKlA39R0N8/SbMF7ncB23lZmLPvJ501cuAFFfTcP+3Gjgq41AnXqEcQWQChizWiaaQPjC6Zhf/t8IYMFxldXSefNsMvTKEUe8T0xoDD58dRmg/l+AkjBHi00NVecy6YqA1vvVQ7R/GY/LA9AYXd7ZtuW3ypFHpKDZrwuM1hBWz4azHf8EypsLlUaXEVnv2Lqv8UunlY1k1eXJyUmeoqtApMcai3ThXee6b8e5RnXl4lNflz7eu0Zy6SE9lYk1Hrar07d6dfVfENMQVbZ+6axxWsOco+bKn1fe79JBXZdREEh/czzJ7oNaa0zElnXg3t5qjfHTdh9GWdVjn9cI+wpd+/4JL/ovLb5pOqgZdzu04BDzXEJ1WbqnBM+iCwZ9t5JAELmstTm99eQUvgR/Q/Tt16aXltGXN1RZD04B3qhm67zC20spL+HLA1g6r0ew9V3et/8TZoEn5Qj4rhzmep5rHF0WWt+l+9X3T/R+1+zEXsKvsVi67livY9LpfVqufC3tWxqa2lgg7jo3QXTliq9IXd477ssx6vrLSKyB2mvtn/yI36ujOnNbPqWgMowC1eVYGA2vgdWQrCMgD+yr4L+reX6cOT5XFL37Si1tqrlIz/peluQ5tfJRmVgjqqwqN7Wf4TLLobO9BvbC2W8eCTyrmNI9Yr0B15jhrN5RW0er1K00+mTJ1qqt8PkghoP+pBg7d7F1eu+maKq/cgGUfVaoans9WVMUtXnlJ69v+yTw7nK0XYmlZ3vV9yUlSmA9dq2kWXpFq0LmT0tK7deXiqAsmOpwJHe1sevdF8CvOj0f/RqDCrq0WlrKd1eHRBMNTNdc9+s5f8moVd+CjU7JlU5aA6UxXzrVj661Puv4RM/lU/9XLte5kE+B4Ubiguj76MVvVOC1v+Z3eX/fCta8gtGIBjDdeAtmOlc98nGdoo0md7M/dVxZutJwl7H/WkPws4xAA/NpNgEo6y7o5NX3v5fSRxBX1jSwK2ctEVyOtxbQssRbT8P6N5fqPZ+UvHIByzJ/67qMW3S+2lnAtT8uYbs8cY3FGlmFpjoEqQ0pbWPPrYfYt17vOgne27nlzxqM+tXxa4380vQCT5VYmb3ST1uUuzWI6yFumG/uX+Cu7UBI58rlllfp3NJqz68MXemxy1HYSMT5jgB0x7d6omGJ384vLk2S2SKT2lKe7Xt0d0tn00QZA+X717NKLfB3ialPCfeJL+7d9Y6/aMCXVz1DpLe/eifuNdaN7NdJqa+bVvWe5d83mxh2kmKtnAPqk8Fo8O/3y5vF/CZ4TA+Yj5fwDliw2IF3b0TW+6xsLu7TRPHFgMa5QLSz+AvgVxh/gajzIwuG/e7aq59Xn9er1KvaooI6Nuu8vDSBdCd+BX/fHLWALagr6BqXy+h77pMHusbEpXvKqJuWdd/W54qhju1vPVrTPcruerI6V6Umkgk3pbuM4spZ/b6Mn0Wja0pXUNnxr3zt/wVo+bVGzDRJ8rQe88r89kvDa8Ra28urwD6a/+b3/AzfBH8n8Vf+H8D3npXmA5zIjvdGETlGn2irg3Q5qxpI8Uf6/GJGQO9krWHlUoqI+uYAehBslf6a7DH/Zd0bKSyRjE4+XePx9ZA7pue1oZhM69ildAtO9d/zO7733drjVxSK9fCX5jtW2/kEBhcta+OKOi5P/BNIJPD7u3pc7XT1c8ctuGwxpXb1d/mi8ZLPeprVaxv930hpZeGVdZQ2EjMd0vndiVIwsQ+bCnC8l4Pg+T23oPOpXsfkZmsXDcoAeHw9+M5djtF1fCMUaWu0pTw53+BYq/P/g8F3R2GfOP5juuQrId85l5am/y9CcFFAc2P2xSXU1wIBMaax77M1Xwv8f9aL5iVwhP+04iYL3SqgwLllgg2++zZn3HI61x7v/j2bFrI/FxhI1JT/It56WPbL9tfwOWllHxeMVjEsO4/gioK9fgVSWiwwZWQFH6/T4xYMBbFVvKXnNUY94AWwpa39ki8dW1BWfr5kuGyv/24JoeMhoNhXlzFX1zourgSyP/sMjEWapDPLX5fYajTknQZtizSWv8s7SyC1Y4lGHnP77eSkTIDeqwDW/btgw5SJfLFPW4d0lgdLg2hVvX9LBCBmtTLo8ti732XajcsFLel+z428+ooeHia+6GExKB6Heavrl26sE7zj/aaRwBLd1I/bAFTa9OkZAB9rr/jATIKlgVhQUPBSOPujUlwKt17fhuMyQULHpLXOGoDLS+n7S33avGbCpVALThdjPx0T4AQG51Ts65YLNKy3j/QK7Er76IHJB+ciorEGXTooV9LgmpxeL1GDvIZml9utQekp0UAqI9BzMALRvhhcL1mnZA3V0vBSevlhpFuflo9XmsD/n2T1kqMr56wsyh+jefEiwK2N8vZrPK85DSM8x3LxuuvMrydr6lQ0Wiz6WxYYOEl88UE6xJN9Kl4j+tJ5T24yMG//tdeGuyQsnhg9a+RX9uyPGPi15WcZgYRCYmgIViidA+jaCBPBu77vBuEOotW1a29lop7mKpP91bPYVI3XLGCvEFmX12pYKtYvqH4CRj2ZjXQc4xqaHYttKsgq53ri6/kkiAq8dTjezf13XwqpQsejBXS9e4FulWQdAeXR8/LrkgfH/a53NYl15aA8T67JP0HL9MeVVtqNz+SFY5Vnev9dm2O1/LsAf737dQyW18qIDpaR4Ct6zsrO9iHwFZxsz+I1Og8Ce9etjNvHDLIv1On3Oj7y/XfzMFm01lHd+6JZx8WrMKy23//e0f72XnvHevC2p46XRzsfZvvK2GU813B9062ka0QDYOdf0aPfCa3OrZW/vH3BJU9j249AEUBQMOS1vfWYJJxjXIGRFgJyxwKlP2aJPyldxzYEX2/xkxCuB7iCYXFuxb5cXo/1OPb+a8AtGe4nA75gZQ20fLTdFW6V9hO/LnrI9zWmen55qAHA3l8pVdCErUs8VdxL/nRS1B+drIyKY1MfTDkI0Es/AWRlzs/y5ZKJBXBlZOVjeRwt0v2cAtu2Dum0clHb+xCesl/evTZNKduWNPkNzyOIO5fM+XFTPh2GV64VXa9fr+/PAFSvYxHsdbq2HiPU9f5XF77pnMB6vjJAkE7xI7yPVO9ngWiNQhFBgFJfroik6GI9MZmmx7mEk3hL9FUCmbXHF3RknL8VxAUO7xcoVMxl9HoTO7YF1Dy19Rql0xbpWb27T4pj243+FogFKY3dgsjyakGv4/V7U4f2Yce7yrYAubKks9MqE7cY3jqXB8tXQU3jIG3Uk8BKfnxpIYTOyQK5da28r3xd/Ljq3C3LlUU9/tWzlVvpFh2MLnZhgTTuBTClU4oI3NJao/BXv9+xM+Pf63R3IvnCCX+vg7TykoFSLo32les1uKsH0u1LGZBvGgms8qd0MqWUT/MA3iOIJQzd65uQHLBgpJefcta3TaFcXsY7truXbqneTRVdBqDj17HLU8o4GOIKDF27Qm1JUC4jYzvXZHT99N5VZq9bfpju2fz9+7Qa4rp303+1IR3WIF6GLCOxnpdypXIvEF8G3nz8evXLm8sAbkqqPknf7l+ZkY6bympSUYelNlX6aLL0tc9L14ve27+rz7VhPdvnle9XNmovfy6dr7Jj8vrl+xrnIo7XljsEt7Y/sP/d73lQqi361m+dAKNE09M6Z41VfuqUlCZ/5U0Sm2oWyy6jeMlTNNoo7BNN/6wXze9blxqcW7Q+Ir4B5hkZhim4TbolKD5U5gogrWvKL4H0dt65TzuJLrBc4FtZL1MgKUfu04ef2qooJNWx1/stiH3p/I7jk4Cs8l/KvvVt6iygaXIrITdM3jTNtfzSFTamZJZun5R7lyTnhGiIekCnlOSn10sK6i7Xu+TMKDTg2AimOptkfGXfm+A9uwpIsOjb9eyCnx7t6sDKgH38Gnm9liheTlU82fkM27+cKh2VXRFoe/K5tpIHd+usD33WCLfjsRPXgeZvfj/P4/n62wIAo7p3rzuTSteL3osj9efVncy1CslIcPXioqlOzqXvv8jEsLlRwdO8lq9g29SOCmhdKe8rKbmWc5cUtnS0/65Z3nYvQn5aqy9IX96oSngBqKkgrfOlgJ9A+hrDlhW6FcArJHQJn21exmr7vABQii4hT/l8DkCAVRn0BldptvwxUEjunjdVG4bYHftk1HMs7GPet+DVRGwPD1n/poVeyQi46OFa1x9dW6vebyMTwWDnFLrfeag1BI5ZnV157D7ld/VCnnhM/qnjYoZytVG28uJ/ebkrAfXIM4qeq6SDRVQ7ht/Nsw7vmvY089h68vHXSMLMxisuj40ulfe7bXd++9vf/p20omNYp1V6b+rwcnK/eTrIBgSqGPIG5SD05gypApIdWMTchyj0II1ErFeCObmzhLj+X5Z2gWkVS8OzE9bLLIFPOthnabx0tl+Vi8mfFPfKny89BFH7uW0pcNF5I5erf2vgrmjIa+Th8mDXdfdQT05IyrhK7xj01JThZKqUgYovUOuNRYOAQtopH/JcOUjem2j2+PX0df3eLSXqh3og+FxO2SdjrEPQ/ytXbZ8c43qqmya85PeTY+UDdJVN8y0o2seeCjZiKRX0f/1+KbNynRxdzpkRoVHe4p2ZDvuYjsW7lzV51/73//7ff+pfS0bb98iyY47X4qGrsX6xh8V8iEEBEqjzpvbe7qmDOym5eWY9xsI+Q9WuW+92AaTzryzAd/2Vm7wsqfU4v+C5BG/TSEtPxyqdtt1POdNt+4oc9FYT8PUK7Ydrqy8vQ2CNdi1xM9Vjm11fvZtrvwzGFW0p9HlOpSKVSVMnepK1aR7fp+DdIfdd08M8Kyu9ZnV5VV0CovNlGkyB+hVz+smnuWG9fZ9WVhfWAVDfNr1l6ssxfpK/Lav3mzLxmu7/GmBanksTl31u1OfYKhowl6u3KVwy9X/xhH79XJpXX6mjZKXjpuZ6n8GmwTdiqI33LuF3z3t24N3n1jryw1SRjsxGv36+uRFY0N3JtZaDbthTMazrt7uPLlFr14c4BKQFX42Lxy/AkUAasxhTPyoqjf0oNxlzFFLbU/ntw5faXRobojreVf7LEJifV4m8VuXVG99+ajA6tqkged6YpIN1aVyk0QLbPsof+PTRwLllwc5NlNJx/bgTlRkZjZreex9Xo61caTz1ijeSSqbk+RrmlYOVd8Hg4oH92/qX3oLuJyfokjedL0FxnbIvGRsN4+XUyOtouWNUhjWARUym5pKTX5MWrE9FAzpGRQH1wV1G3RK7/hQNZGTWGbb/zxC0Ikn9Wx3d/5bNuPxikYDM6Vj5rRTOMHoVQEFxSan3rCe/DFVo95j9VfA7tvlomZ5QbPjpetyKqZMMwWUYP/VraWufrvF47fV/hT9h0CN+JR70cWLvEhw9xwt8lobXGBXO8ud//dd//XeeHRBQNTRNwOWFGUovsOnpbxrhAsynpD0XYF+6psUQ7/ybd9g8sNdvZKxjI2iZavL+nT/SMFSPToLetQbE+QRBKX4YFSl7/l6DppFe47x6lA6t/vatrJXSMm21kUv0s57GIW3fOZ1FgV9+dD6H9YcffvjDBHD0u9I4OTrvd88g9LzI+/3AO5lThotY12g1Fueunk6kC8v77pHfq2efjOo3NwK7IiGmPyPQAB6RErSdUJaxW8+XwH89kwW6T8S4BNyi0Lxi+iChaQw7aS2wrvfcfyexLwbK7MZjOyr4psss1iOd1wDFo0vIN0y17eqWZ7YXP8yvrofZeDOqz/vZh8gMszvn2+xUEEFxPe41Xo1No2A6JQDJ83elyDMAKbuyFii4FPKi9W4oFt3kgXKx8q6zYx+SiU1lXh58OpdeCrLyWX45jr32akc5WjpsRFART5K76KP8V0dLOBv7poQ0xtfy2uopc/ED7xQQ7AXuxajqfmmbvPeMQktTpdX1OtGNdN499ado4KJhY3RhjNdpuL+5EajxOmyImQEozH6DydLuALon4gcc15K79XJVtgX0y3u+wuMFJnPPe60eV8pzCZm02fr1IDYVctHSSEXgr+41ptdx6XMZqKXR5Vnofa0xtt0FghTM5Xh5RAvAT9ijgf1ZhXMsnXM+aQ2v0YXRTm33XxlyeV4g8Pjbpl/udWM7eulGtxst6aVext++1AdpLO0s5uN31dv+tp7q1jExiljefgIU+72R0ILo9t82NkKXPubSq9vVWNuPrnF+SvmK3qV8/u/fL2dfJ6b5g5Wrzr37niOTfPgegqXZhWvVEw6+3z1RXEZFnBR/llefHL5vbgS0WilY67DXY73W+qe81wThpk4uI+AxPaIV5q69vBn/KziCpN6F6ZRAX49hwzy9y31PgYDatdGz68yzr5CvJym4aVwFqjVIO+41MvbrjxnQTwrctWvcNq1Wjt+c6QK4nrmrJbz+En77sgpj/ZdR6Wn3V9pE7DKmO5ewofvSeiMU5TT69HvTAfX9WvX0NcZ5rzOKreQQrTOyff9EZ/VQWVaeHJ/X9tlxL2iuDu14Fqj16BdQk6//h1R29yq7Gnn7kWy9iKCtoo1kdTxMT34CaI1xEYV935VAycOFb19q589KB9VRhfBZQo+/Yyl2Kyx2BUKdz1rHEBl/eSGfhElQ8prLaxaQ1xNporrjenVen7Xesp6rfbb99bz3nsuLe8U00a4EWL7oeV6RkX36BB4rSJu7lebvut02eCOxni+wrcA4wd/w3N/7PEh1m5+3GJGkoL5EZGnjO6/dsHCXFl5GvdVwX6KhYzUXbh76MqZr7Gx7oyCNkV73yvuXDKiO1c5DyO8tGsmVDx0qHZQF9kuHd7yvNJdjP6SdO3p2LiAWOH/4fdR1vYvYvna/x3totJ1lX9qwfuUgJ3etoFtnrX5oZFzSGk/FDHX/wrifW3723kEypIHpndSRCFqIJfB/slJ6BebyYmJAoIDvewm61u/Le9n8vDljBXlTQTLLEO3d6xbD7qcjGH7yblYZFZaY7QNfKsAq0W4stYZGb/aKHL5UNJoqq5Hd5r9fcZ5l+52Hv1FNY+n6zYVfBtR+JKPmi1e57b99Fiw0CMmxgLMOTDzsuninZ6cBrL01ZJchrW5XoElTvdzLMAqMW/fyfoFKXq7DsmmqBW7lcOXv8uI/tW36zaf2rfeTMXWc2+ZfsTfZpQ/K2xrL2n1OhJFjL9J67x5+BqII89L/ZCgsrT/1c+dHKl+rt980HRRzepDF/KVC6lraBYkFWRmm961ia4lT0FWcFRzrWAG0v90rQzvvxKVpgOpsXKU2ruV11Wcb0urKCa9S165AaYlGKyybWtCwXEq//HCc8UCeyjMVTP6q9OavVeAFlu7duYmnSIXKRm3ywk3D1vuSvwumOgF/DBwvr1ZeO9blQctP5b+TthfQ1JcrWu686clPQLqGQfnbCW77bEpMQFQvrrrl5QWqHr8cInkgT9z/p0+8Tw6WVo618f0KOXYOwed89h3DO7765PvT04tSTf/tv/23n54D8AVb4kz8SkaTyxYkJCNbdLC3/GJbSQe+byAuwduJ3Xfs5cnaia/0kA/yyKg2b6otjYvENn20A70GfSnn5vdW0bq+OYA8Dr25mFa/FUjrXwHUe4iel5J4XcdM8ajggqzXr8CaMjJX6fl9QEbldCXHKzt/8QkI9LxSpvetE7F9X5AzjdMcgt76OhfxKs/MHKty4bhKHWnUXZF0gfOm4Ryr0eV6nvF9dSbZ0cjY38bqxLbjLcLY9irqjsc+OSf2XSByEnp5dzkR8qhrvqSDS1tlXqD0vSO7qi8ebP91pn7FU8LO72hY13nZiDJ6tGVOfX4GIQx7OPg//sf/+CkiCC9cpqoDUkkufUfxGnSXFl+G4Bd5WKzBtZypzlye0zvfoGVKBO/3eubmIq3Xaxc4Ls9IJVlv5bo3Jq/HnOELNAWExu65ZdbSTyFegNjcn9cvMAgoKosKt0bv6t96gtLItvzY/iUrKrLRy4KXeda9/5XNjV77EwlWa1RcpOBOkoJhY28LAYE5L3BpsfdKx8Crvl+yHD/jn4ZDGVvQWbpVz648u4xH9a9sVp880LtWlnZVlmmdq+1tf9uVh5ccbfrTVUeN5+JnfV7ebZ2/on3nhK60rtt75JDUh5wnn0two8Q2jfMNZi5R3Xmn+PpksnkG6aKefIrEvrb87Inhn25i7+1LuPp+AysScN11xE7xCuN2ojiGythP1n09DBWt0PGVCOr91Zk3oRLGiFecUFRBZJD3XXnE6LOejQquUjUmDc56c/ZhPd1LeDSm/fcaQ+bqv1JoAvTeHw1VuARegL8MTv/zaO3T+52H5dJBlf7TMj1XbSlPepzvvkL6XeasrG+KMgPqCqZkfmVDg+6SxK4xKlja6LgI/ussCYTVWd8/ydWWBVijlzUaS2fHeLWns2UWIVnWa1eWXWq8oKsubT3KsU7RK93jducrP0sfDed+e1+/fcG87Tu3IZ/rd5i4+wh5vTL2p5Sf/ZyAT9Q6mZLSK7yv9FTdMwZ//+///f8/TzRFK4zSmKzAXgTonACqgi0g6wEssNrm5elkQMydCjy78Z10U3AT/Cs6cHyCgxNKev2Nc72C9fQd69ZrXZub/gQa3tM5vZrSf/Jb2kdbZUVQW4/tJ2El/RiY76SvO0tuytB+5HQIkn2erLbV75PPHJlLsZfm0VDv8ZUN1aXhtZ69emzPso6IfFpPUdlSBmvnMgCOV93Q4K4DtDoqr23PdqXjyoqyYCRpZBkfG7/pTr+3P13740HXTQ1tlCNvM/Q7P3HRJKdXh3Q3obtoUP3Nsarfq+v/RyaGfYG4gORTqF3rUqvCIff2zturzu5bBq3nenlmCeW+y3U9CAV7vRWBT8Z2rNyc/aie93EDMr1/meu4DDXXIAguXnPxZL3oT9c7B3DlsYuaorme6ivxctd/1w+9N/ljnxyrdaVUpV82/WF7KWYORP/dBfRKjwhmAcgq9TveA2Jv+fNb4vxWd+ySYOerLmOjIdioUSCVFyuby7/Ly1QvclBMiX16cGlBeYv00onY6O2q8xrLJ2OjTFwGdHcMztA3LvFjx+TCgU1jdf53E2koI/ucjwZ0Zdg9xIx4NYIajPe/Tew0XOuwdX+0WN3SQH7i3zdfIroPxygQaxRUhhRr9xVpRY0e6OZEY4ZLuNYD0jApkIKKbXxJgJeYjWvz7uttryVXEd69TjB2vPquvqxSLWMVTusRGOxvhne92ui3wmcKrzFuFBKwmZbTQ3SM1bm83ofFUqKdA1EBridwtx+Nde9Vdk0VStNeAt5zLj3KrzzsWPUCayd+BNA6KRsZ1eeNEnU2Lnn8JEd+Fmw/FXPu3uMzDpeD4bGt/2p3x+J10eDyile/mvTftxhW3/YlPlw8f+WKhK+VTF37iqntZLfjnUsG1mj3DEGr3vZlNbWlLq6B3ZTszy0/a3VQHUkoDKnraMzNWpuri2HXGuyEbBV/lXznDPLW60t7veu5rTe5ILnjfEUgltkxUw/F8SncqxQLiArf3vfJEPhb73KVVjAvVXUZDkFsJ11VuE88sX3rt78BXP0ImDtuKtGUUvKxxra63bp5AWO9N43N5qqt45Uclza6e2nMjELnq8cUoMZTz1NjISho6HaMyfDeUzs7L6H82MeVjU3vXYAePy4wXT3ddq1Dvq7OXffaTnJrdOn/ADOeuAbfOuvHZhI6/1e/x6JPvJDW0cSoflcC7j5Elnfdc4TbZSEDkxHLENhOfXjFuQr7p+z/4ukgl0jWSV8kXmfbnTGF0GKnjIFS1lBiO5GjMJo2kvgRPcHo2CsLxpf3ZL69e1eRZe56frtcrCJNNie8ln6vX2tv39dgbPppDYReSMqVN7wR0kWf5eOOwWJ0UL22r+e3gO+bu6o/58O6V/lcErkyIS1Vzu5vO2BTB13bE8bPCLyU0HvxR/X5XMi+QrJnaKSjoLyyLL2cOJeXpvHUlY3q1hlYEJYvK3vRUjlZr9e0odGLcrOfbUNZufRUuTMCWNqbelROpJWTvWsMBNfffXj+ZvFDTNLo6MTU59q6jNeLMJOB8K8nj+Vj93d+VxJJ1ysS+uZGwDTNdbwOv2Wh7/8b0HrJjwDv/LunjZveZw1BoOQGT4LRKo4Mk0h65+sBfsoFbmrpJ0L93uPTM1ZAVTLpYr+ucM6+qExfuuY6tt5ofTKP/0nAVzn0vuuvKQrHuP2Ubn0W2Ko3EC5NaB2CWKCj9x1vNS4aLnlyeZvV9b7z8pW/6njy+ozAP/gH/+APO0bqGb6+16cr8npFJ0PDtEtH9dqVO6Nj5XONc3xfh0APVRqsjHq8OtVdizp2Gagd68qt+qjBUYcvZ6uFJr7H2fmZdZ7io3oQoK5+vWI/pbf3iwUV6bRyn7Eq1bMOxGvDCGEjn6KVMjEaWPGtPq8j+c2MQIC8xxLmGnffdTtlCiVlegPI8r3yiPHufw+iReyihhXW6jLPvl6M11/geRFOwm54qFe9huMVIxjbqa2d1LGuLWuw9PCsd1cvKITXJJ4RwSqiCrPjMAS2rZWH69yCgDyxvS958SpD9Wye2u111xO9UgJ6k3lu1efk92vnGYKnqK/4vEF8t37Ta/XHuRCfm5Hfu/opnTOlsd6/8xvy/pNMV97/+rGpGp2bjWDkv0CoEVxZubzvlTllQa/cfhi5BaibIlPO1llZOawPf8Vra00falRyqFZ213BfKcOusf3S4rVj+rOVdb7ruvEYWduXy8H72vLVRkAhXwv/Pm2WpKfUNXp9C2L+Tql9I4+EjhBGDgqWbS0hvOZT7k+hdh7Ae/cVgpfV/cQAmfaKk5tr5L5U9HC6XkEzYhMwuy6QWzp8Apbo8AnYVZjtm55699e+80urpHrkjlFZTHED7HL+GYo1fPJ/211Pu2cFXJ/9D//hP/zpmvfkp8ZIUFBBG2uA63yW46n9jFnR7abopLv80glY2ezYLlWNDmu4Vg+MJu2DMqLO6RhKe1cOSi/7q+xYlDHTIevMWPfijJFx/YrmF83WYGgk7K99XcN5ybQy0vYhOsmvFBFcDp1Lr5fmlctB+yZGINBIMZwNz6L54g0Ja1GIFTiPFy5JrEqMN9dnWzH3spSrUJ67QMvr1rvoWgX0GqPXKaCe9/gqsgChAK+QeVxAsV7pHgAsGF3fV/l0TqXcVJxpOz3fXTWlJy5N4r8RgQbP8Rg9Xs6CEaP5e4HX1Twp4N/8zd/8dLwXg+sklO4LDKRF8rpPul8RgR/laeUjg15Z8G4MplOUiyIa6WnfrUfAE3zXA9aobISx/b/A375WZ86CdYZHZiGkw9JuU08tbPmSI6e+eC65ro/1LdopjxrBXXL+frvf2PuYJlqD8koOSuml+rpG+ueUrzYC7nMhYfTItlMK0npyl9ei59ckctcHKlpOt+/Ncwpo9DIFiIRAoq31FxRT9H4vQC6w6I1fgt54LiNzMW8B8Ip0rHfTPV1rXlMANJW1Rmqjia3z8vIFvjV2ApN53Pp3pdhU4F3a1/k93j0aTg2fHtj1rIC52nUe3vE3P/COPUMgWNdWeuAbpXRWdkzq045//6/MyBONmG0FmK67V8+UcXlbP5W/vm3bthybtKlcKZqOXx9plM77nICpsWio0bDv7nAgNiwmRU9lR2woGnmAHa99SFEa1F6evfW+382HuWLs1euuCktrH9iVX5al+zeLBCKcYFVjL5d/WVIFQ8IsCO6AZETgJsPX03sfmapXrPBu2/X1+t/3la6wXdtw7PZD4F8Qta5XPqUarEcvpDYFX/l2eaaXZ3cZrD1/8Wppd9FIr/MJuKvK3Jep9lSa+N7qiVfPU56OC/huQthxQcL+BjQq26ZHNo3RsZ5+T+6NSGrnmpRdz+79bw8Zaby8krdXZFnRuNYHJ499yl/Q2onenIQ13msYljYrgyvHl6NjH9we2rH3eX3otY4uoV19WqdLTPH878jFrx7kVK5TG22WfhqNpUf96oHSNQTJ/Lu+a4x2pPM757s55PfFk286J6B1dqCv0w3k8rDt5AKmAB9RXBMtARakAhavqT5/qxCflEcvtL4L/LYvgTVyW+cagz1nEew+1aGAa+yWRnoigospmDU69mPTK/Zhedr9S8sLqErzaAT0RBdsdhLMYr0biu+Tpp+U/5rkzVBF7xYpRL+MzLvmnev9so2vfi+dimyLPJSpDJr835TQ6lz9u/RN/i5gK6sZqC0rHx1rnAt29vfq5+qSdNmVfZ/6EX1rS09YGU8W+1wrm5Sn/+/vo8KNvPZ6nV91Q8fgWha8czD2rTErv84FuLutOqbTIh/+FAPws1cHrWdW41rky9tWCSV2TNtJEMHAwTgJaGrDfsW0CG8YbqqkY5+IZf8/KUXjcIWOx/Wc14u+wL771nvvuNd6/koPrYIYIgeU0Wq9tU9GbAFqr/e/4Fy42/bj/S/kfSAY+Bq2y+OAvQUB+3SloL8GYAHIpbreqwfo058ZApfsadBeNJBsmy7VA10QWK+ttl5J+Y1GBNtL6ZvI3vY1pILJpnV1NNbgrzHZlONGUp90RVm65NX03ZX+khaNxxSwdV/OSeeNYn/D8yK+Jne9dXnU+ItKSw/5rmIjhe2PdOijTr8+uX390it9iF6fnNtfJBJYhWogTtzuxFeDFLxdAtbgNQ4BhevVbW8BqGOXx6xXe3k9FQl3pTg6J6F3FcB1/XVfdNBA1e4n626bjWeXnF5GLcBWmGp/Q2dBJLr2rYHW6Er3SwBNY/UpBF6F7Jy5dJ0O+bsrNZStBTLvX8PQXNalSBmb9/32EZK2OjUundbIZwD9/4rzANK/Y67kWQdqnZjAc6O31dV1Tvq9EezKeu3qRCzgbxQgfZSZy6EQBNfr3dScvJanzRM4HiOM5Zv8+HFW7ixor6Ow+rL6Jv5tiqj6l3/qnbJf9Gh6rrG3lHS3R//Ur28WCciMTQVtvv4TmEQIQUiwN9dvuw5UQXY/IcFxBXuFccFLxU9INs2yiiIQd1ygW/qpCGv8XrnSQRbBuOuj6aYNKubLHaMC/snwCeAqyxq9Ld2zYXZtliPfFF3/VRYdhuTjAk/lLMWo7nhpnVfeekHTlwr1lOeOW0O4hsT2lje7rv6To6NjEO1MT71vweJynEyRmNZNPlY2P62Uqk718JJt25YvK/uurLlkRl3QuK+x6xqXj36KRDRSefa/mYdDpY26fkXNYtrSZh2Zy9AuJjSO2tvUl+P/Urp0afDNjUBEecd64EYPsTXRl8WM8BIrgSi08yEKB3MJ3uUtO/n1JeH0vGNTOeufq09Ms3TvWuJtawVRwV0l+wSwTjA6dsF56dS4AlONjp7mel8aSwX6ooEeo3SRJnn4pVqWDu97l5BqiPXI3OlUHl30/eQdCXItkdQLazwBbis2SmHV1qYvdArimb81dhmZLaWcui4vVKdEvpv+0rhfqdJPYG9f1c3daE0ZqVzy7rk1ssmCTo2OTW0o07Yfz3U2TW8WJSYfHbcd//8tC0rkTzRfHFtHq+O2t7qzcxXJTI6k+COmKDOOz5SkMnbh5jc1AnVQZvmSB8+7ukMB2PDTusyRxUiV7gI3LWNE3xVMMkdCL3Mk3qZabFehWO/Auq8+bipIr2/7tuCqR1/ZqOkyQobA0s7715tdr0PgM0zfcTmOHZsejPLghoILGo5NHqR0Kn8KtV5i93VtqzDKo797mpcQVPpo2ORnSxVrW7pcq20uw3h5h+9en35XtuSzHqae4hr75YWAddWrnJQr7/+1JFO5vb49r44vz12N5JhXF7xn5X9TZos/Gyn8+vcyowFcA3o5eNYhfqUH3hdQy6dNg61M1I4Pxe49tZ0jsDL6yZn8syeGLwtno+WqUm6tlIpgSXGdEOsaX8rt2u2EuvrqS/1bT/USWAFVj+jy7lyqujP1l7D7vcbhJ8IDLtLgUvo1sPtbwe3cehbS+hKOT8b1AgZp3/Up4HpMPiTVNSqMdWiQNLam2DaNtOuvr7pMMVRX8lZ977eb1zmBXREA37haGSRv1+OMZo29Ten0APXS+zZqWmBTh3aeayOjeCOfPH6l9zYCsG9rONZxuGR9HZAFQa+/nqLfPuw41qGonk0L2xcNyI/Du21T2V15d7Wdxk2c6FpXsLUqzgcl1wHqk7MjprnthFGT+Pe15WcbgVdUZImi0AayPgixoPHK5nwFkP47q64AVY8M2hn4VzY1dDF8jcJevwZD4fd6z++34/b3VYdFen7ijUUF/KQsa0TXy+73pp/WU9Fr85i/u2d3zrRfq1Cb/7UPrwT+1uUcS/xtBU9jdCM6vamu04jIn5WpHhQqp6ySX0CiHKxRtl8LihpOdWDHKR/0SOWNffN+nboL0AUz21vZvoDfe3TWNqKuGM3ssxsrW62i0ei98z5EuvzYeb7fzXsmyiKU0t7JXVcMLb+c49gUj/xLbj69v1o+mqZdR3yjO/n1c8rP2kXUweTlpWi+O1Ng6fenlIxFj++VDT17pNrQu2JI7sTgBdar0J/C3GXyMnXHosA7vgUBj1nX0uzyqvYejev2sbFdxkZh2acPr37tOEy/mFpYQV3ap9j7bIerwTZHWzh9GchkIkWx3mhSH1NiJ2UtnW9/dw2YyzTfsddu3uaXPEoBWvASzFzZYtGB2hKvBKP17PUQpWd9lFf9/+RcVQRoIzP7I2A5bot08rpoWtvuubRYsnNI0lI58IGvNZ6V7Yv9UB8aq6vTNCZGOH4C9FKIGRfn6gR7+2U2ZPHI+76ET9/spTJ2QuYnrGsBd52/KzsciIIZwwzVVZhLqRLK9Xwuz6v7Ls+ne69Q6pO3vQzbsgbAvgiuAdVOjEVPH0tPyPu80pJL615FXwB3pcnydgHdsQgYXVM9Kt8CZKX11YKiipYHlmxdgCFdtn/rKb3vtj3JmUgeNzJ4fXm0fO8P2InHV0fPKnya2BQ4LiMaffc+HybzJSnrDGwkfRn2TQuu0yO9PnnqVxuuRtsctPK/TtUalmS5Pgioynq8es9p7INYC7K7Ymq3EYnn0b/v3x1vw6vPl86b6nEjt8DdCNExBfgbBey8iGOp/eq/vP748qXl79/MCNjZZa6eYEx1U6oIpYfgf4XHcFxhqv6EXO8oouzE6QK19XtcANrlfAuCn7z5y9upns5fhvSTRyoAZCBcz+6kaEbDuQo98+XB8mP7VJ0LOpdSVFy107kFo/i56aLkKw+8JZmCqeCgLKgg1avClDZyocH2XSDM+9RLq5+vjvdgWA+H6QUKQKsnK2sbrnusSOWaO9HTX7lVXpUteahM+N/6r0heGqkjKwfes0s61XnvEUQXZHU2WpnlggrpeqWspJlLhL3vN7/HF1eGraFJt+KzfcwYuC15hkAZykjscbGtcYh7jac5gPpsH6+lole25Julg2S8Sh0I1OEFxf7v8s8YKlD1W6835lyWMMZcXrwMv0LBzisgl9dU+31vOOl9V//8qITRxDbWA9w6N+3xyaBtv6K7oaWgn8JsXda5gpXw6TW7YuWVlCcvqHPmXJMZ+SD/o7dgsXM4XaMi9SCj0eI+i5KsRRtl2pKye/xLPFdWpKv9Eyijn28qW7nx072mBL1vPflPDoyyWP9Whq7xaRi2fPKsN+pwCWTe+gLk4+GLBt73e2jPtPEnvU02jYy2Hyv7v5vJdB1f+6W81L+MQTK+0aL3OrbLibQf8t+oRYOrA/zKNe/2zV40v8CpgjqwV3ZVUEK/A15PQTDXs1oFMM+7oLq/64PexwK5XvTW8ak96ZK17/poo4Vehse46na8S/Ol1RqT9eq6rz4tuBthCSZXkXb932/5pkdmH19fXqpl++62DdGi/62mEfgX/Jc2GxF5PpqoNCqnHqxAvkpe0bM1UhGQV47NZa+DI6Bf4N6118NH/pb+n5wVr1cXLjpuO5c+bdn2NxIp6tJQR2eNyLu/dOf7vfM10ttxq3tGiRfd/ooU5NJRB8UIZYHcqCZZERfXCHzixdJueXDNIfX/wthvujpoZ8prVMIZPn8qAmfMWYu+nlDFMOka6AVWrywzti/Xvf7/tBrilc3X6xHvAz7W/4nRGh/7uN5k9/nCbQUzQEswr9UWKuRFw4tG10oF69DzVTHzkKKLYX91J2MqZefNwy5fVhErmz4QVH3CNIPzrn9PBmsYG4urOaL9ToLKPx2MneCVtwtUC8AXraWr8tM10kDZEjy/xO+u/dR211nPHhcPFng1evGica8RlSadcyXZTuDKH9tIFlxR9CNy867r3OLXO14UuKlH27s8/zUg8lwaOt4dv7LhghydTdNe6dY3jwSuBypsKNBZr2CFQmtVZ33c/RKCKwKoL5egdb2KqIGSEYZ3Co5jvRR8mZ0gObHVyinB9jI6jcsniE2rqNzbZ+llRPLOKdQK3ALBKtE1NyAoXFHH0unTclBTQtJx/wcO+9rIlS3lRkC4+G2/3fPKvrnss8nadSAE9h2L9NAQblv1WUBz8YSTmY0/WXJSfz3s5U/8NyrcvlzRz6YrFvSr63JoNuUbbd91Ldld3SyvbqSlXEeTaL+rvMSZ/uu520/l5G954rr71mnst6uP1MPLGC82rGFY3dgiP/y/BkR9tf86At90TkDBXiHpmJOP14TNK4ZsCyIy632bI9XDdI967/e3ACMhF3A0AvUhMF7PQOYrADKoc61qMDWksZRu0cXoQVosmK61d4WQ4/uUxlqArL3Lq1oAqJ/ybA2D/NY7NeWjUbKdS4BXKTwWMO45v+Ox8xe23/933cs9a/w07Bp0i0AgGO4k3ad6lG0NuddK9ytaWB5/AkjlqvM5dVddHluer4x4recf3fOmA1Kj6FJt9UUZkGYBd5Olbv0tYMdzsSR9cFL3x2PLDdvda6u3831cERRNFx8uGb7k9QL2y/GKHj45v7r3TSOBSsItY0wTaYm0fGtZNQ4pmwxcT8vrG/B6HAt2WsTLkpYSEJwr1q1nvmPzUzsJVMrcxLlbJKwXdSn1RftL4ZqIUkDWaAq83aeRvtr4g6BgaO2bhkAaB5zWXS63sV7GRVmSF747QhnRyPidh60B1yv/ZGiU37eUNcXedeE7+X3VUX+uVJu86bfzC8qOud7GtWP0vvpgexdgX2BiPfJFXRBsTadVz+qx/enViLtW3vZWHtStziW3j0dX24s3S3vr/fH3UaEvr9/+Z7yMiKXnRg7J6oWDKyerP5esrI5Kg3WuvzYN9GcZga8JZy6Ldym83xFxlfXyQPcBkIu4l+WWUe79soZlvbG8eicta0OvZRWsMDfg8KUkr/gQk4oogO5KiKWnHo5CsIKud7Re7ALJl/ircO6cxyqz/wW6DVcvj9Lj0kBae19gaR21txOwW/ZYEejj09se4vFwFfyi02VwBLAdW8/YrAz03IBAK6hccxFf+l8flFX7tnxfXn7iv2O9rr+MUemvPP/0zAhHB6mycv2+33LdZ1h2f/3a1OH0WO39bqL5V+pP1zUfsNs2q1tXFLHyeGHilksPk235JxaIm1/bzp9tBDYc0jJKgAWsLwmWgr4K9YoDNke8BDDVYNtdJ9MzBF8imsCpl2q7u2Kl3xsy5h1nAK5X2tlfPS5p4ORPHx+WUXl2clVPapco7rjkpdGL/FxASg683o99/yQT8r9rVhZW2ZW3wL9PY88AL1BvH5QV6bkTcpexkwbKVXVWX3MNLlc1jSrgL02f/PvOb42dsrJG6jKwOTvK0OWNLq223tXHP+ZI7EOAXReYX/XoACyvHj1eVLCyqYO0ztnlMf84c32vZKxyBLvmemp4ndjHF+cEleGNDD71ZXFUeV++fnKev9nqoLX2hXWfJsheWQBa5hq+pbR5Wv6vriVCzHCV0nqLevtNLAng6z2piDsRFHju2DQECpmCaN16lLW7jF4wtn8Xk5dH1SHdFqTWU1swW09k214jvKBgv9YLrQS2e35BVgfBKK8w3qeWL2fCcShT244G3H1oNrXjmOz/GpHaEexfvb6MJjooJ5/SSMmkD77JlzUe8nlTTh5fUFmAWgNiv/wtTT85WPX/XVtufwH1Av+u2XE0hjVku+BAXFjdf+XS3zBDXdDRc4GG34LxbgC3mGOxv0tT+WYUrhOtPv2iD4vVsN7NDupLQtR/hf2TkbiYlsKl8F6vhU3IAo0suoCVl+/E2CvXo9q7iqg2Vgg2V6pyu6TzHRMM1ktdZd3wVmOo15PwLjBvn/b89le+bNRiikFjXtlJ9fXMBPcV+gXr6pEX9bEISwfi8oKUy5VDow77IgBdefvL4AYM0qh++VGPlt/eo7PR2PTeP83XrEFfg6A8rYGsje3TRceVrT22PLC+1/+240g/r+iyugVfjbD766Rnq3PS2gnhH44MQceagO7+T3NBl9O3NFNP1IsLJ+XNYo/nFzurd/n8TSOBOnkNcL2IT17CRSQtsOF2nx4yMjz/FALrNZh3NKS/FMZ5BpU3IXXiyHDWOhc41qhp0V0zL8BpyNYblw96JAFG7cubaLFLcx37eoJrWNYgRKOlVWVBXAUWwDaii6969fVP4Oy39Ou3+99vv0x7XMpcPfbbNNZV5JfyV3umwkwBygvp2z3WI+3VmWRvn4L2mvqhPlnfGos1GlvfJ4C5jM/KgNe6AMDlnk6I9/E5ArHDzeXCCBdfKJ+bvlFXf+S/Bvyat5BPXXdFBOtUyMfL6VgaWjYS2PrkaY7DN48EtDICyIK1Zf8v8Ow9ecWuIlGpVsHW8GQta0em+FE4dlWTFrf6rcdrFSLTQnqla7nrdwp8RRbL5OVBv5f+Hav+9shfgfEaaXsZ7a5dr+RT//y99LO/0WONn/Q0urDf1ekGcNXhxoNXv7p3jZQ0WdlbkF5PeI+vTO926smN/9cgvzbdf+uic330peSr+OtNR/erTuVndfVLZeV7dUmvt3qvHQUy+sr06qs6VXulWl5bRb/yp3Pqa+d/d0QATcq/4nnHI9a42klaLm8vnNS5uAB+f1+GVPrmbKzT9E2NgIxcxq9nniAvGF4GQ29JD6B7rXu92updAyBzVtEuby0h0BNckNRLWND+BJTWtWPfyS7vEyRrp3EruOu12ucrXFzAEnSr90vPAFxeoOO073pW8lqB1wi45nsjBe/Vs9aDXKPfHM6urFm5voDYieBekLSTxdW1ueiV5ZUTeW0fqjcDsHRVBi9Zjo6Xc2Bd9sO6lh7WES0XoHdhhP0IpOKBD5yKIytn7qZqO3rR1W+K5l1bhN2YHJsGaOdwfpxo4DLQm0per38jjcsQWNagXdevzl0Gdg2Buv+L7B3UQFMUd7N8ReW10+s1CX4KV9dfa6AFRgdpWsb83HozqxRGA13f6os1erWR8uxe59Gk8Xjttv8lBkmD9Upj/CrQRiPX/Xt9dJFXejnes0p1ycZF2/29Xl8lhdQB+NKyTo9dTon91xB9SSal/crb47UThFeqps+nRQ2Xk7Re4Rovabx16UEmm86PvM8+nbtgc7UhUF987rfP2HgsGlx6tu//tl0BtDqbM2gMpl6j3+qYhlK9i0YarB+PJ3vftbuLrTqhbK5eX8Avj7z25xiQNc5L2zXWl4x+k/cJrHe8Svg+1y6h6zm8EiGrd8OXTUEIcl3vIAX93V9mmWQqROWvDlMMjt+nHfWwq8f8dR8f4NrIZr3cC0wVwvro8caxXlnjN8LRgMqHy/O4hHivdxwKnUqpsug9BwhrfHIG3P9/i+0r8G3YJU+WrirK5uc1PvIzmWiL6TVoRiNuf2Lbq0Pr0AgKy1+PyaP63LkcMnnU1hMZpooOk07cJQvy5hVlOnBfUBULpMVGDCtrym/HSg/X73RQ4678rYG3nXUYfjzGoN6IA5s6Tj422/DJAVVX1Vk/1/HVwYo6LiZazy+6i6gK/gbd7LmvZQskVLYVCgXuD536vVBe65cNryVY/yWm4FnbMr12NUZ69hFxH23f9f3e17Hy8bXh+2sXdC6A6LpP4adC7pgVjs55jxvJRb/1BgWWLylTfVzAWtBdIDelYpvxyLBWvl5jNi+rPKxx+aQ4G7lq3HVy3u+igY2iokfnG6PtXrxdGlj0pJdHFmltPZfXuamclZUt0bIxJj8LvJcOdo0r35Qb8+z2RWzJc+9Ya/SVuXViVjalUXKyIP3DPPFfnT4IuiBr9sCI6ALu1Ud18sLVP8bjlZf6txmNTwsZ/mwjoPLpdRS+LohUVugTyiv3b+i3ANL5DXka8OVpbJjkMeu9lpjtfZuLdrnfMmmPP4AQGAWECzCqR9DcsXzJm3HiSfoLkPLW9r1Pg7H3KMBbb3zWk/oEyk6mS5PLSTAn373XQ3/+lxebZuzYjis6CHyu97ZInwUkI+Pl7SdDudenb56zCFyCVjRfmffblG5LLaPvxe+N9NXD6uu3kZVyW70uQ9WYr7MhjZefm/rRMEX/jpsluIzZD5NtUHcah9GgOrf9uORjcXT5La0veVzcsv69/7ruz04H2bFe9OBkohOxu7IhRVOBY5AfGWLbKeQyQSC0nxoVmbAEt96Ob1ilN9DqJdd7XymWVaCUbIHwAoDt43oCX/Ic9Mh3DAKOXp60aSVL41hadm1GXyW7jMllKPT4vwQo1uN5PfYFXK+XH317387LXDTuGvcu8mU4X/LSNAzS4oqsvCYD3JOmesr22Xs2Anr/63Pj+ERXo/bGZYqo8+qzDtLlHb+SMXC1X7JT3zdiUm4ctzp+0d42F6QX7Pf/jzM26eH4L73e6PMC+jUwK7efAHt16fq9Mv/H6vym6SAtsumS5+0aUnvtegWCgR6G2x/rbStEC+gLNBtqCn72rfqtz1SRSpQR+7SCab0tPep3Xcqg0ptSs1+1mQC69t1c9fLI3xcwLCBJs/W+pJl1rIF+9+TJN/FX3ebIFVSNjX1ZL+3ylFXQ6CFISAuNzi5g0MOLR+sNCkQd22WotvUJBNZRsJ/Konwo9fjJaFT3pork1dJmdVM+Xt6891865rF1cDJE219XDF0erCB9YY7OzdVvjdMnflrnD2NgNN577RqAT2mgjWZWHlZGLtnd3+vAycd1Jn5O+dlGwDDudca16BE/Q/Am9zavG5infD70swD8/u/TkBF+BaY6F+QXKK+ylt76BFyJrEepEG5OOY9OwbKuxn8Br8f0VHrbVvUFYNcyxcubWFDePnRvtLkeplMmKu9+H8h5deggOGf0JSXQA9NY7lyF9Lqiis5fcrb7CLn1yCeZWVrK14BeYPG+AHlpt16dzs+C8QL3Kvwnj7pxKedeY/+v/tUvl63WD2Wu9tZA+hKXTVfVlx3fJVuCrh+fOVhDEO1NF8qHvz22H1/+vev3LWFraNZYfQL6S752rFeJP9Jp9Xjl4GuNwZ+8lbSCvemTJlDfhk5ODBWateufD9G4MucVH3jYCMCVDfXHPizhlhHVt+HegkvlAge9fMHKkNJVRtFBUNxlZnpu9t+8ZOPcp25fkQbWY780YDtOQdT+Ld+7VjrbphP78r17A0+PrYG6vKomBuOJTsAaASM4HQ+/NdSryAvOWwLFJv/X4bAfO7aL9v6vnk2dXss5L+dHI2yUoZ7pia9zIrBv6kRDUdSn3HXdp3MZAmlclObmbBdNV/fVG+VWgO68johLaF9ZfLjm1tTrnY/c3wvq/l+M+nTdtq8BuZzHq69fW/6kOYFKQLdhXcx6j3G/8w/094GO0iMCaUrsPvDes1ZdxajOJcanUO0Kh1cwNEj1z7Gbf1TZHesFQPZplXY9E+neQzAKtIqpgFSfE4NfAqVVcNveEFTjswq5xmeV3gk9J8qlm7xcQBCkFryrt5IBsHTtev6fvKpouuc0hvJC46KHfdVtkScr++rA8uddt5O5Oj7yXuOyHvTqhLKoQamv6xD1ruCOGwFLjwVT+6MDUbtXamhXwdQHt4Beb10arFP1ivdqoHKGXPFoFKJcLoBfkUBFo/GprFOi87jO3J8C/n/Wm8UiYqsKNg/8yrvm7fX9jr0J5PfeVsG0TdSeociY6DlL4Npdz+AVhV5CLJEX/Ba4nAwVEFMMvdC8v/YZT0kU4MqmG2qv8Ui3Bfb1/jQEvm+goqLp+QkIFkHGujRKeol6bgJBbQk6yYleVcq06QLv+ZQ7tw/vXDzYh4eUgUsm7OduqWFbn4o0a0w+XGVfbHf7r5PgNfU7WjiOfgtiyqh82Ovr3xp0x1I9AvSmb2zH+6XZvvbxOYHxy3m0+hIW9HTwpqUEwMspUM6NADSeGT15smnUymKG49e4W3ftLw8/efq28zVGQyOmAbtSoOuU/iIbyNWpPOFA1MHkSbSp0/v4FqB3/f/6X//rD6Cwk6yCpp7/KriA0n9BRAIp0AsYplS6TwUztIzhLjczQkmBioLWYguSAVo0dIKyeuvnGi+BdCeYa7MHnFaB9L5UjAVn6XUthV1Q1BNcA+DLP2yjeoyqFlxUzO2/CrlKa4S3Cmp/zRPvvM4qqXIWnzUEAoXj3HrWaCsfAlxlx7nOj7K+dNOw2B/r2rbrnw5Hk9WmeTvXPJVYsMvG33VONguijXF5sdGMMuK9jt9r9rh8+dt5sPTCjeX7pmy/BNxfAvate39f/FsdUHZWFxd3vlkkcHl6pXWuXThT7DwBw+NnFAJKV0H4yLaTiwrWhsIJhA97qYyGyBEo4d814o2zCMXxOAm+E7EBugKf537lO6OPBmE9ww2ZY7rzEAKdAm66RsDQqDm2+q2A52Vd+eP1ji5jIM+k5YKboOUDefXbsWUsVXTHIm26zrrWeGgsKpfhcFx6Y7W1W4+v0i6oO/ZPntsa6Wi8AGC5+uq5NQLR5cp3m06s3qLf1Y0rEnm86vo1bka56bjbvmcwrihkjcdO0tqW+uU13ffrD7xWV7zvum7p7zX245Ox1hAtHy+9lR5rCK7o4JsZgRXqmLbW0QGqeHkUAWlLJhUIQVvA+RTSbp+cW5BwKlNE1ANapa0veuYq8CciC3J6Wq7uMXRcJd6VDmssPk0OXpNZ8sZ6pKNeucDuPI30FGQ1rOthLU383tB5gSaQl26O1TYvWkn7/b/j0HPdiNKcsYZRB2GXufrx3lV2HRSXHFsW8NUJ+XUBywVke416q5x77crN8te5iKvvpmcaoyCvA9b8kWNwWa+8X2ftE7D+MXD9cfY7ElyXr9Yv/za6sY2rnos3V1k+VjRGnz7Lp1/ECKyn5QTxApuEWQ9Qiy64mJfsXj2uPb55aom1HtEnr7hS+95zjX8nrRrfKuYasQReJe46y+XJeY/CUJ1e7/0LkI5pBbfrBPXqX692va4tAlaecn27PMHGZgSyfbuUSVmpTdMYKra0WfnQMF38qJ54arrDdJme9DoD1/r4jXTXk2wMm4qIV9dcyifwUmaKhNVB7xVkl96d66G2Lzle6m9G3olj+aC8bZptDeWFNSsfGyHIyx/nQTHruFJkRqYa5fhw0UqdsY0/1u+rSOML+G1TnfhmRqABu6GTYZSgsNZIsL6ItBFASmwb65WtlbWfegGfZtQvhVARN92gouqZKSQL6hlIaXB92/4CvKCi0HXcawQDj8mH5lsS2toKDJbmev/b1+h78X1p56T2T8LH6qs1mMunrl3QEIhXMVb+Gpsgm1OhbCjT0n75nCHba21L+lU2qlNeHJsgtIa6c9J+gWkNyB/7XkP+x0Bt9ePi+Y5P+mYQ9jWeevZO3l/zNvbbzyWHftaQ/o7l61e928Y6K/L+4tnFw3Xifm6xnjUE0fGbPyewzDOfvt75BdLmHvMe9LxeCSRabiYw2YfqX2WPKHraEuoaU/W7h0r1C36fxtb3MqHvCyQvr6zjCswlIJ/Azjptz3kK+7S/VQxpo9LY3sVzabfHfEOTQLf1yxPru5Z71v+LR9LZ640aVVydjybqHf/l6RsFL1hqJFf+LgNdyQheim2da/wW/B1bNNoFHCtLzqcI9NJ3jZf9VZ5L/Wy5vNZdMZcO97/xrTOwBmwNddc63uXTD9Dqf//v//135jouMF8DZhZj5e+SiU+fry2XTKzh2358s0hgJ8JsdJXWDl4AkgERJBMaN+xahvZ700oL5msdF9zXaldSLg3WjtFopntXaaWHRmCfjKw/lwe1zN1rV5D7XkXfaMHjGhs95T2/yr1G6jLI0tm9k5SFeLUpOAE4bz36rSxt2kG52YnlgK5r1huTvi7flc99r4Hsfuc8FqySXds0DSqQX0q8QLyyabvJpOPY+ld+nSPIEOp9r7GpTRdRdK3G+XLC5FFjUuaeV64Rq601nCvb4Yg0udrd799NVLXYU13SLJn8BOY/B+C/9todu/eqe0vvbxIJOFgJeHnYdcTfnfMVkhHf0HNXfqy1U6kEf9NAgrEKoyeut/GK/fG6BLCc9oK1oekF8F0bvXZJrXVJv02JdE66e59gunMkgsLFJ/tviCwwqdBrCPqWXlu3KbZNq2jY+73GTwVVHuXXqyvQ0zAvSFanfTLduI6L4Kb8LM02N683LNAu+C8NL55ppPOKP4HG0s700fbPFWjOcVRHTpGgrRd8yX3FSf4tGhGvk0aliVphZJ80uGv814u3PQ3yKysfvrTee9b5W6PZ8aXxp/Kneu6WNVId+znG52c9J2A+V4Hs/OYpK5t/82UTEX3TSjJSRd2VHAKiirme+Xqq1rFe+L5U5v323aWbGlhgNZrIE1tPUDC0nSu03rICfK3iWQH4Uj2fvInGqpLvb1eHrIEWINZYW08PCjoPsUbgk1EsFfP+u/HgAqi02TmmdWYEo53nsg89JbuypDERWN+5+uu8x0Yt0lXDd0VgXXvxVQPlmKXDgmXLmS86bBS3fW4s8nWj2u3jpqxc6ll/Khqr/q+cd+81l9E9RQmbQvrhmFvY1XOf5Ni2F48co+OXLsvXq3w6Fx/s588pP8sIfALWBDTg2xdPrFfRNhLXS51X4C9CVzZtsasqXqkuj9kvmbte+3qGKt4qagxXuVeg6o8TgwvAgbp01VO9rP5OrHZ8ge4qK4BLg+2b/ZUea8w8X3313/H9JIR/9Vc/PVUefd459xfq93rMfTvWNZz+X/nVo90n3l22uTSyvL69ByJVeHWm9gWzy2Daf2V2r5EPX4rGpH1gLK80AMqHUV50lz5roBvzesmC0RqaNRp7/V5zpVu8PofDN3wJvn6b+nEF2A8ftnteum96eL+vVWWrT9Z96YnX7O8vybfP8nzS92/yxPB+OtfDQD363aPgec0p9ntA7JqcioEp0xWWrqcb4KoYAqt9X2Zuzq9zq/SrSBJYD0mQX6ue57d975wAuoxd4+OYbGO9aycOvwTkerYrOHvPgsv28ZPMVJdGM48z71ijV522vQ/0bbrreohs5dQSKGuIjFwc36fIbEF004IrA58Mics+P11zjeXinzR8xTG9jynNBWPBdlNpyuou3U7etm9dt6kSfxe92Y5GYQ3wevkCb5hzAXRtfYoIfiAFKs3damL1T8PyPs1nXg7R4saXjI5trTO8MtG177xPcf+c8rOMwALpdrawXoUMjB74P2+vVMumYhS+V4oQ9AAFEr1z61yjsUp7AUJlFao69VqvddTL4K3LOi7Lv+ctlwcszRZs1lh0/6Y1HIsCvQ/tfQJRx3UZp85bV5OHPiSoN74hrZ5Nv/dFJdWv57782CWn0cB0hXRY2V6jnrOxSv2KuW0jVfmkx/+Kz08svaWvsqNzdfFE+suXlb0FqUeTtio3779yvrJ20W2BLv7VniBs2iXcEGTdq0vAdotnz5tWqh4fnnzR2/v88GGSWKMYTdfDl3Y5g7uY4PotsF+ev/q02Y4v4dcbj+mqry2/+nFR53v5Xr6X7+V7+YspX7fD0PfyvXwv38v38v/K8t0IfC/fy/fyvfwFl+9G4Hv5Xr6X7+UvuHw3At/L9/K9fC9/weW7Efhevpfv5Xv5Cy7fjcD38r18L9/LX3D5bgS+l+/le/le/oLLdyPwvXwv38v38hdcvhuB7+V7+V6+l7/3l1v+fy2m7PzuBAgUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[1], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Sb6n74NDTLLN"
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'Non-COVID',\n",
    "    1: 'COVID-19'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "25ydoppcTLIW"
   },
   "outputs": [],
   "source": [
    "base_dir = 'chestxray'\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for label in label_map.values():\n",
    "        os.makedirs(os.path.join(base_dir, split, label), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JCzKInwWTLGA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_temp, X_test, y_temp, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(imgs, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mlabels, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m      2\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X_temp, y_temp, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.12\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my_temp, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m33\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(imgs, labels, test_size=0.15, stratify=labels, random_state=12)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.12, stratify=y_temp, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NoGmOe4CTSMK"
   },
   "outputs": [],
   "source": [
    "def save_images(img_list, label_list, split):\n",
    "    for i, (img, label) in enumerate(zip(img_list, label_list)):\n",
    "        folder = os.path.join(base_dir, split, label_map[label])\n",
    "\n",
    "        # Se for numpy array float, converte para uint8 [0-255]\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.dtype != np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "        # Se for imagem PIL, mas em modo float, converte para RGB (ou L, dependendo do caso)\n",
    "        elif img.mode == 'F':\n",
    "            img = img.convert('RGB')  # ou 'L' para grayscale\n",
    "\n",
    "        img.save(os.path.join(folder, f\"{split}_{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aVeuYjuhTSKV"
   },
   "outputs": [],
   "source": [
    "save_images(X_train, y_train, 'train')\n",
    "save_images(X_val, y_val, 'val')\n",
    "save_images(X_test, y_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCGt9V1nTSIQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQh9C9fwTSF7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnQpozSiPMdn"
   },
   "source": [
    "##Fun√ß√µes gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2mUcSMIMOLTG"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "V3Jwg9JJOLTE"
   },
   "outputs": [],
   "source": [
    "# Applying Transforms to the Data\n",
    "# pre-trained models expect data with the same pre processing as data it was originally trained on\n",
    "# thus those transformations are necessary\n",
    "# + a bit of data augmentation\n",
    "# podem resizes de tamanhos diferentes?\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3), #xrays are b&w but densenet expects rgb\n",
    "        transforms.Resize(256),\n",
    "        #transforms.RandomResizedCrop(size=332, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(), #image (format PIL) -> tensor (format pytorch)\n",
    "        #normalizar por 255 - ToTensor j√° faz isso automatico\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    #val and test's transformations are deterministic (no noise, no diversity generated)\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "S17sv4mhjjBs"
   },
   "outputs": [],
   "source": [
    "image_transforms_for_custom_networks = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomRotation(degrees=5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.488], [0.488])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.488], [0.488])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.488], [0.488])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqB1PotzOLTF",
    "outputId": "67b4643c-4156-48e3-d802-92e53719ef0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'COVID-19', 1: 'Non-COVID'}\n",
      "399 55 81\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "\n",
    "os.makedirs('chestxray/train/Non-COVID', exist_ok=True)\n",
    "os.makedirs('chestxray/train/COVID-19', exist_ok=True)\n",
    "\n",
    "os.makedirs('chestxray/val/Non-COVID', exist_ok=True)\n",
    "os.makedirs('chestxray/val/COVID-19', exist_ok=True)\n",
    "\n",
    "os.makedirs('chestxray/test/Non-COVID', exist_ok=True)\n",
    "os.makedirs('chestxray/test/COVID-19', exist_ok=True)\n",
    "\n",
    "# Set train and valid directory paths\n",
    "dataset = 'chestxray'\n",
    "train_directory = os.path.join(dataset, 'train') #chestxray/train\n",
    "val_directory = os.path.join(dataset, 'val') #chestxray/val\n",
    "test_directory = os.path.join(dataset, 'test') #chestxray/test\n",
    "\n",
    "# mini batch size\n",
    "bs = 16\n",
    "\n",
    "#needed: #chestxray/train/covid\n",
    "         #chestxray/train/noncovid\n",
    "         #chestxray/val/covid\n",
    "         #chestxray/val/noncovid\n",
    "         #chestxray/test/covid\n",
    "         #chestxray/test/noncovid\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(train_directory)) #num classes = num folds in each set fold\n",
    "\n",
    "# Load Data from folders and apply transformations we set\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'val': datasets.ImageFolder(root=val_directory, transform=image_transforms['val']),\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "# ImageFolder creates mapping {class name: number}\n",
    "# here the opposite is done: {number : class name} so we know the class outputted by its associated index\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "val_data_size = len(data['val'])\n",
    "test_data_size = len(data['test'])\n",
    "print(train_data_size, val_data_size, test_data_size)\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "# batch generators\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True) #not learning sequences here\n",
    "val_data_loader = DataLoader(data['val'], batch_size=bs, shuffle=False)\n",
    "test_data_loader = DataLoader(data['test'], batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vrS6avamOL9",
    "outputId": "7c41ab7e-765c-41a1-b6cf-c8249d5a43b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'COVID-19', 1: 'Non-COVID'}\n"
     ]
    }
   ],
   "source": [
    "#essas redes foram treinadas em imagens preto e branco, logo, 1 canal. at√© agora, estava usando transformacoes que expandiam nossas imagens p&b pra rgb\n",
    "#(como descongelei a camada convolucional - no fine tuning - , ent√£o o n√∫mero de canais precisa coincidir com o que foi treinado)\n",
    "#ent preciso refazer essa parte do processamento, chamando a funcao que n√£o expande o n√∫mero de canais\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms_for_custom_networks['train']),\n",
    "    'val': datasets.ImageFolder(root=val_directory, transform=image_transforms_for_custom_networks['val']),\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms_for_custom_networks['test'])\n",
    "}\n",
    "\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "train_data_size = len(data['train'])\n",
    "val_data_size = len(data['val'])\n",
    "test_data_size = len(data['test'])\n",
    "\n",
    "train_data_loader_for_custom_networks = DataLoader(data['train'], batch_size=bs, shuffle=True) #not learning sequences here\n",
    "val_data_loader_for_custom_networks = DataLoader(data['val'], batch_size=bs, shuffle=False)\n",
    "test_data_loader_for_custom_networks = DataLoader(data['test'], batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TKfviOpJQNOR"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    #Stops the training if validation loss doesn't improve after a given patience\n",
    "    def __init__(self, patience=5, verbose=True, delta=0.001, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0 # how many epochs passed without getting better. counter < patience to keep going\n",
    "        self.best_score = None # smallest loss\n",
    "        self.early_stop = False # flag if training should be interrupted\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss  # minimize loss = maximize score\n",
    "\n",
    "        if self.best_score is None: # save info of first model\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        elif score < self.best_score + self.delta: #new epoch did not bring better results\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: # if patience's been hit\n",
    "                self.early_stop = True # flag set to true\n",
    "\n",
    "        else: #new epoch did bring better results - store\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OOAFDxp0STjM"
   },
   "outputs": [],
   "source": [
    "def train_and_validate(model, loss_criterion, optimizer, epochs, dataset=\"chestxraytry\",\n",
    "                       train_data_loader=train_data_loader, val_data_loader=val_data_loader, train_data_size=train_data_size,\n",
    "                       val_data_size=val_data_size, device=device):\n",
    "\n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_loss = 100000.0\n",
    "    best_epoch = None\n",
    "\n",
    "    #first: looping through training\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        # Set to training mode -> activates dropout, batch norm, early stopping\n",
    "        model.train()\n",
    "\n",
    "        # Loss and Accuracy and Recall within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        valid_true_positives = 0.0\n",
    "        valid_false_negatives = 0.0\n",
    "\n",
    "        #for each batch\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            # loss.item() returns average loss for the batch,\n",
    "            # so we multiply by batch size to get an estimation of the sum for the batch\n",
    "            #(so we can obtain the average loss over the whole dataset later)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            # TODO sugiro usar metrics do sklearn \n",
    "            _, predictions = torch.max(outputs.data, 1) #returns index of most probable class for each instance - the actual predictions for each batch instance\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions)) #compares predictions with labels resulting in a bool tensor (1 if right, 0 if not)\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor)) #convert correct_counts to float and then compute the mean (fraction of sucesses in the batch)\n",
    "            train_acc += acc.item() * inputs.size(0) #multiply this mean by batch size to evaluate the total accuracy later\n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "\n",
    "        # Validation - no gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode -> dropout off, batch norm fixed\n",
    "            model.eval()\n",
    "\n",
    "            # for each validation batch -> similar logic\n",
    "            for j, (inputs, labels) in enumerate(val_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "                valid_true_positives += ((predictions == 1) & (labels == 1)).sum().item() #total of true positives\n",
    "                valid_false_negatives += ((predictions == 0) & (labels == 1)).sum().item() #total of false negatives\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "        # is this the best model based on tinniest validation loss?\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "        avg_valid_loss = valid_loss/val_data_size\n",
    "        avg_valid_acc = valid_acc/val_data_size\n",
    "        valid_recall = valid_true_positives / (valid_true_positives + valid_false_negatives + 1e-7) #avoids 0 division\n",
    "        #scheduler.step(avg_valid_loss)\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc, valid_recall])\n",
    "        epoch_end = time.time()\n",
    "        print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Recall - {:.4f}, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, valid_recall, epoch_end-epoch_start))\n",
    "\n",
    "        # Save if the model has best accuracy till now\n",
    "        torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\n",
    "\n",
    "    return model, history, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "IuS2L78ijjBt"
   },
   "outputs": [],
   "source": [
    "def train_and_validate_for_custom_networks(model, loss_criterion, optimizer, epochs, dataset=\"chestxraytry\",\n",
    "                       train_data_loader=train_data_loader_for_custom_networks, val_data_loader=val_data_loader_for_custom_networks, train_data_size=train_data_size,\n",
    "                       val_data_size=val_data_size, device=device):\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_loss = 100000.0\n",
    "    best_epoch = None\n",
    "\n",
    "    #first: looping through training\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        # Set to training mode -> activates dropout, batch norm, early stopping\n",
    "        model.train()\n",
    "\n",
    "        # Loss and Accuracy and Recall within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        valid_true_positives = 0.0\n",
    "        valid_false_negatives = 0.0\n",
    "\n",
    "        #for each batch\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            # loss.item() returns average loss for the batch,\n",
    "            # so we multiply by batch size to get an estimation of the sum for the batch\n",
    "            #(so we can obtain the average loss over the whole dataset later)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            _, predictions = torch.max(outputs.data, 1) #returns index of most probable class for each instance - the actual predictions for each batch instance\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions)) #compares predictions with labels resulting in a bool tensor (1 if right, 0 if not)\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor)) #convert correct_counts to float and then compute the mean (fraction of sucesses in the batch)\n",
    "            train_acc += acc.item() * inputs.size(0) #multiply this mean by batch size to evaluate the total accuracy later\n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "\n",
    "        # Validation - no gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode -> dropout off, batch norm fixed\n",
    "            model.eval()\n",
    "\n",
    "            # for each validation batch -> similar logic\n",
    "            for j, (inputs, labels) in enumerate(val_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "                valid_true_positives += ((predictions == 1) & (labels == 1)).sum().item() #total of true positives\n",
    "                valid_false_negatives += ((predictions == 0) & (labels == 1)).sum().item() #total of false negatives\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "        # is this the best model based on tinniest validation loss?\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "        avg_valid_loss = valid_loss/val_data_size\n",
    "        avg_valid_acc = valid_acc/val_data_size\n",
    "        valid_recall = valid_true_positives / (valid_true_positives + valid_false_negatives + 1e-7) #avoids 0 division\n",
    "        #scheduler.step(avg_valid_loss)\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc, valid_recall])\n",
    "        epoch_end = time.time()\n",
    "        print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Recall - {:.4f}, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, valid_recall, epoch_end-epoch_start))\n",
    "\n",
    "        # Save if the model has best accuracy till now\n",
    "        torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\n",
    "\n",
    "    return model, history, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dyG4bCHHOLTI"
   },
   "outputs": [],
   "source": [
    "def train_and_validate_earlystop(model, loss_criterion, optimizer, epochs, dataset=\"chestxraytry\",\n",
    "                       train_data_loader=train_data_loader, val_data_loader=val_data_loader, train_data_size=train_data_size,\n",
    "                       val_data_size=val_data_size, device=device):\n",
    "\n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_loss = 100000.0\n",
    "    best_epoch = None\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True, path=dataset+'_best_model.pt')\n",
    "\n",
    "    #first: looping through training\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        # Set to training mode -> activates dropout, batch norm, early stopping\n",
    "        model.train()\n",
    "\n",
    "        # Loss and Accuracy and Recall within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        valid_true_positives = 0.0\n",
    "        valid_false_negatives = 0.0\n",
    "\n",
    "        #for each batch\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            # loss.item() returns average loss for the batch,\n",
    "            # so we multiply by batch size to get an estimation of the sum for the batch\n",
    "            #(so we can obtain the average loss over the whole dataset later)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Compute the accuracy\n",
    "            _, predictions = torch.max(outputs.data, 1) #returns index of most probable class for each instance - the actual predictions for each batch instance\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions)) #compares predictions with labels resulting in a bool tensor (1 if right, 0 if not)\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor)) #convert correct_counts to float and then compute the mean (fraction of sucesses in the batch)\n",
    "            train_acc += acc.item() * inputs.size(0) #multiply this mean by batch size to evaluate the total accuracy later\n",
    "            print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "\n",
    "        # Validation - no gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode -> dropout off, batch norm fixed\n",
    "            model.eval()\n",
    "\n",
    "            # for each validation batch -> similar logic\n",
    "            for j, (inputs, labels) in enumerate(val_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "                valid_true_positives += ((predictions == 1) & (labels == 1)).sum().item() #total of true positives\n",
    "                valid_false_negatives += ((predictions == 0) & (labels == 1)).sum().item() #total of false negatives\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "        avg_valid_loss = valid_loss/val_data_size\n",
    "        avg_valid_acc = valid_acc/val_data_size\n",
    "        valid_recall = valid_true_positives / (valid_true_positives + valid_false_negatives + 1e-7) #avoids 0 division\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc, valid_recall])\n",
    "        epoch_end = time.time()\n",
    "        print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Recall - {:.4f}, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, valid_recall, epoch_end-epoch_start))\n",
    "\n",
    "        early_stopping(avg_valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "          print(\"Training interrupted\")\n",
    "          break\n",
    "\n",
    "        # Save if the model has best accuracy till now\n",
    "        model.load_state_dict(torch.load(dataset+'_model_'+str(epoch)+'pt'))\n",
    "\n",
    "    return model, history, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FGHpMyvHOLTS"
   },
   "outputs": [],
   "source": [
    "def computeTestSetPerformance(model, loss_criterion, device):\n",
    "    # Function to compute the accuracy on the test set\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_true_positives = 0.0\n",
    "    test_false_negatives = 0.0\n",
    "\n",
    "    # Validation - No gradient tracking needed\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Set to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # for each batch in test\n",
    "        for j, (inputs, labels) in enumerate(test_data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            # Compute the total loss for the batch and add it to valid_loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            test_acc += acc.item() * inputs.size(0)\n",
    "            test_true_positives += ((predictions == 1) & (labels == 1)).sum().item()\n",
    "            test_false_negatives += ((predictions == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "            print(\"Test Batch number: {:03d}, Test: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "    # Find average test loss and test accuracy and recall\n",
    "    avg_test_loss = test_loss/test_data_size\n",
    "    avg_test_acc = test_acc/test_data_size\n",
    "    test_recall = test_true_positives / (test_true_positives + test_false_negatives + 1e-7)\n",
    "\n",
    "    print(\"Test accuracy : \" + str(avg_test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QBHeFS7QOLTT"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_image_name):\n",
    "    #Function to predict the class of a single test image\n",
    "\n",
    "    transform = image_transforms['test'] #loads pre processing needed into test images in 'transform' object\n",
    "    test_image = Image.open(test_image_name)\n",
    "    plt.imshow(test_image)\n",
    "    test_image_tensor = transform(test_image) #applies the processing\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      #view regorganized tensor so its format is (batch size X number of channels X height X depth)\n",
    "        #test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()\n",
    "        #unsqueeze(dim) adds dimension of size 1 at position dim\n",
    "        test_image_tensor = test_image_tensor.unsqueeze(0).cuda()\n",
    "    else:\n",
    "        #test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n",
    "        test_image_tensor = test_image_tensor.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(test_image_tensor) #model outputs (probabilities for each class)\n",
    "        #ps = torch.exp(out) #for LogSoftMax activation\n",
    "\n",
    "        topk, topclass = out.topk(1, dim=1) #most likely class\n",
    "        cls = idx_to_class[topclass.cpu().numpy()[0][0]]\n",
    "        score = topk.cpu().numpy()[0][0]\n",
    "        print(\"Prediction:\", cls, \", with probability:\", score) #shows most likely class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rfvc6rKkjjCU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOD8cRbxSsUr"
   },
   "source": [
    "###CheXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYjAcLKNTxOy"
   },
   "source": [
    "https://arxiv.org/pdf/1711.05225\n",
    "\n",
    "https://github.com/arnoweng/CheXNet/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "uIhF-g1KjjB_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'CheXNet' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/arnoweng/CheXNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-9z2fiT4jjB_"
   },
   "outputs": [],
   "source": [
    "!cd CheXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "g7BVmW4ZjjB_"
   },
   "outputs": [],
   "source": [
    "#carregar Densenet 121, carregar pesos pr√©-treinados de model.pth.tar, freeze camadas convolucionais e alterar e retreinar ultima camada (fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__pycache__', 'model.py', 'README.md', 'read_data.py', '.gitattributes', 'model.pth.tar', '.git', 'localization', 'ChestX-ray14']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/Users/llbm/Desktop/deep_learning/trabalho/CheXNet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lj46oJ1kY3yK"
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "model_path = \"/Users/llbm/Desktop/deep_learning/trabalho/CheXNet/model.py\"\n",
    "model_dir = os.path.dirname(model_path)\n",
    "\n",
    "if model_dir not in sys.path:\n",
    "    sys.path.append(model_dir)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"chexnet_model\", model_path)\n",
    "chexnet_model = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"chexnet_model\"] = chexnet_model\n",
    "spec.loader.exec_module(chexnet_model)\n",
    "\n",
    "model = chexnet_model.DenseNet121(out_size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "gRoTd9QhjjB_"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/Users/llbm/Desktop/deep_learning/trabalho/CheXNet/model.pth.tar\", map_location=device)\n",
    "state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "UXUZFv3bjjB_"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import re\n",
    "\n",
    "def clean_state_dict_keep_densenet121(state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k\n",
    "        # Remove s√≥ o prefixo 'module.' ‚Äî mant√©m o 'densenet121.'\n",
    "        if name.startswith(\"module.\"):\n",
    "            name = name[len(\"module.\"):]\n",
    "\n",
    "        # Corrige norm.X para normX (sem ponto)\n",
    "        name = re.sub(r'norm\\.(\\d+)', r'norm\\1', name)\n",
    "        # Se tiver conv.X, corrige para convX (sem ponto)\n",
    "        name = re.sub(r'conv\\.(\\d+)', r'conv\\1', name)\n",
    "\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "\n",
    "checkpoint = torch.load(\"model.pth.tar\", map_location=device)\n",
    "state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint\n",
    "\n",
    "cleaned_state_dict = clean_state_dict_keep_densenet121(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pez4GJZVjjB_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(cleaned_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cTMK0t2tY3yL"
   },
   "outputs": [],
   "source": [
    "#only retrain the last, fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KV0cwXHwjjB_"
   },
   "outputs": [],
   "source": [
    "#print([name for name, _ in model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "a9JItBKhjjB_"
   },
   "outputs": [],
   "source": [
    "#print(model.densenet121.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "IQ-4ivY_Y3yL"
   },
   "outputs": [],
   "source": [
    "fc_inputs = model.densenet121.classifier[0].in_features\n",
    "model.densenet121.classifier[0] = nn.Linear(fc_inputs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "EB96MX5RjjCA"
   },
   "outputs": [],
   "source": [
    "for param in model.densenet121.classifier[0].parameters():\n",
    "    param.requires_grad = True\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "6tWYYbOnY3yL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "params_to_be_optim = [p for p in model.parameters() if p.requires_grad]\n",
    "#depois tentar fine tuning melhor\n",
    "print(len(params_to_be_optim))\n",
    "optimizer = optim.Adam(params_to_be_optim, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "1CtNH4dqY3yL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200\n",
      "Batch number: 000, Training: Loss: 0.7012, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.6898, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.7090, Accuracy: 0.3125\n",
      "Batch number: 003, Training: Loss: 0.6876, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.7008, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6771, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6868, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6995, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6512, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6179, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.6333, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5735, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6972, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.7897, Accuracy: 0.3750\n",
      "Batch number: 014, Training: Loss: 0.6745, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6590, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5942, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6168, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5988, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5717, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6145, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5070, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.7353, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7191, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.7058, Accuracy: 0.6000\n",
      "Epoch : 000, Training: Loss - 0.6603, Accuracy - 63.1579%, \n",
      "\t\tValidation : Loss - 0.6498, Accuracy - 63.6364%, Recall - 0.0000, Time: 98.7695s\n",
      "Epoch: 2/200\n",
      "Batch number: 000, Training: Loss: 0.6778, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.8799, Accuracy: 0.3750\n",
      "Batch number: 002, Training: Loss: 0.7330, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6230, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6647, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.7111, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6671, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6980, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6679, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5785, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6616, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5716, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6117, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5208, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.7536, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5708, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6557, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6516, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5653, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5879, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.7043, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.7579, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.7074, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5273, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6294, Accuracy: 0.6667\n",
      "Epoch : 001, Training: Loss - 0.6552, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6459, Accuracy - 63.6364%, Recall - 0.0000, Time: 96.7530s\n",
      "Epoch: 3/200\n",
      "Batch number: 000, Training: Loss: 0.6703, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6154, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6095, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7281, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.7459, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.8817, Accuracy: 0.2500\n",
      "Batch number: 006, Training: Loss: 0.7091, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.6812, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5639, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6579, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5480, Accuracy: 0.9375\n",
      "Batch number: 011, Training: Loss: 0.6175, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7317, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.6750, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6537, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5769, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.6514, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6009, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6828, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.5771, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5959, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6692, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5863, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5513, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.6991, Accuracy: 0.6000\n",
      "Epoch : 002, Training: Loss - 0.6511, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6374, Accuracy - 63.6364%, Recall - 0.0000, Time: 106.4220s\n",
      "Epoch: 4/200\n",
      "Batch number: 000, Training: Loss: 0.6503, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5781, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6365, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5317, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.7939, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.6458, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7823, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.6372, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7092, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6825, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6705, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5018, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.7537, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.6682, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.4582, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.5087, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5669, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6392, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7503, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6681, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7447, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.5337, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6611, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7391, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6160, Accuracy: 0.6667\n",
      "Epoch : 003, Training: Loss - 0.6452, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6355, Accuracy - 63.6364%, Recall - 0.0000, Time: 101.5232s\n",
      "Epoch: 5/200\n",
      "Batch number: 000, Training: Loss: 0.6033, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.7080, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6443, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6345, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5724, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6972, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6658, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5613, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6500, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6448, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6001, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.7169, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.6290, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6302, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5912, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6884, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6708, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6096, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6332, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5944, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.6931, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5295, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5952, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6123, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.7258, Accuracy: 0.5333\n",
      "Epoch : 004, Training: Loss - 0.6358, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.6328, Accuracy - 63.6364%, Recall - 0.0500, Time: 91.4178s\n",
      "Epoch: 6/200\n",
      "Batch number: 000, Training: Loss: 0.5753, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5157, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5443, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6728, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.7299, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6335, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5860, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6338, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6238, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6755, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.7262, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.7720, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.5983, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6483, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.4773, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.7848, Accuracy: 0.3750\n",
      "Batch number: 016, Training: Loss: 0.6162, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6981, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6052, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6475, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6480, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6129, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5913, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6443, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6602, Accuracy: 0.5333\n",
      "Epoch : 005, Training: Loss - 0.6368, Accuracy - 64.4110%, \n",
      "\t\tValidation : Loss - 0.6326, Accuracy - 61.8182%, Recall - 0.1500, Time: 96.8807s\n",
      "Epoch: 7/200\n",
      "Batch number: 000, Training: Loss: 0.5677, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6860, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5053, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5699, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5763, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6028, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6828, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.8006, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.6774, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.7175, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6385, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.7268, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.6726, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5286, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5767, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6921, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6958, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6125, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6279, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6467, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5754, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6416, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6939, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.5736, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5792, Accuracy: 0.8667\n",
      "Epoch : 006, Training: Loss - 0.6349, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.6378, Accuracy - 65.4545%, Recall - 0.3500, Time: 92.8769s\n",
      "Epoch: 8/200\n",
      "Batch number: 000, Training: Loss: 0.5793, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5640, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6641, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6775, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5425, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6125, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6145, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6729, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5155, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6887, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6272, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.8611, Accuracy: 0.2500\n",
      "Batch number: 012, Training: Loss: 0.6939, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5549, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5779, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5917, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5395, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5996, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6601, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6404, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6438, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6100, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6523, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6667, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6536, Accuracy: 0.6000\n",
      "Epoch : 007, Training: Loss - 0.6281, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.6337, Accuracy - 65.4545%, Recall - 0.2500, Time: 91.9378s\n",
      "Epoch: 9/200\n",
      "Batch number: 000, Training: Loss: 0.6061, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6463, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6316, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6507, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6505, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5448, Accuracy: 0.9375\n",
      "Batch number: 006, Training: Loss: 0.6557, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5731, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.7048, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.7019, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5237, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.6196, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6515, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5966, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6541, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5503, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.7495, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.7875, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.5770, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6073, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6356, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6708, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.5502, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6845, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5682, Accuracy: 0.8000\n",
      "Epoch : 008, Training: Loss - 0.6318, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.6323, Accuracy - 65.4545%, Recall - 0.2500, Time: 94.4118s\n",
      "Epoch: 10/200\n",
      "Batch number: 000, Training: Loss: 0.6119, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.7379, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5791, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6398, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6461, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6334, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6674, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6229, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6235, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5002, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.6770, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6180, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6578, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6305, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6099, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5970, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6928, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5451, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5369, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.7327, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.7982, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.6144, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6232, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6114, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5791, Accuracy: 0.8000\n",
      "Epoch : 009, Training: Loss - 0.6316, Accuracy - 65.1629%, \n",
      "\t\tValidation : Loss - 0.6354, Accuracy - 61.8182%, Recall - 0.3500, Time: 95.7538s\n",
      "Epoch: 11/200\n",
      "Batch number: 000, Training: Loss: 0.6227, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6066, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.7251, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6753, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5510, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5668, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6428, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5767, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5175, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6599, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6584, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6928, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.6715, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6423, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5182, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.5849, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6939, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6590, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.8340, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.6794, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6315, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6104, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6255, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5689, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5522, Accuracy: 0.7333\n",
      "Epoch : 010, Training: Loss - 0.6309, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.6372, Accuracy - 61.8182%, Recall - 0.4000, Time: 92.2444s\n",
      "Epoch: 12/200\n",
      "Batch number: 000, Training: Loss: 0.6254, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5701, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6365, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6738, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6079, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6263, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6586, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6823, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6380, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6837, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.5595, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6593, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5572, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6058, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6446, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6495, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6782, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6271, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5653, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7210, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.5221, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6570, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6004, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5548, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.7578, Accuracy: 0.4667\n",
      "Epoch : 011, Training: Loss - 0.6302, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6273, Accuracy - 63.6364%, Recall - 0.2000, Time: 92.6647s\n",
      "Epoch: 13/200\n",
      "Batch number: 000, Training: Loss: 0.5029, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.5583, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6693, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6414, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5677, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.4521, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6768, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5490, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6220, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7859, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.7052, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7046, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6718, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5545, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7617, Accuracy: 0.4375\n",
      "Batch number: 015, Training: Loss: 0.5332, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6286, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6427, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6935, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6407, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6842, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.7139, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5390, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6314, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6468, Accuracy: 0.5333\n",
      "Epoch : 012, Training: Loss - 0.6310, Accuracy - 64.1604%, \n",
      "\t\tValidation : Loss - 0.6465, Accuracy - 67.2727%, Recall - 0.6000, Time: 97.1156s\n",
      "Epoch: 14/200\n",
      "Batch number: 000, Training: Loss: 0.5408, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5181, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.6257, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6433, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7348, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6723, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6939, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5480, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6130, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6345, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5595, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.6136, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7360, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.5229, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6252, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5246, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5500, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6720, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6573, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7091, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7351, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.6394, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5410, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6714, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6378, Accuracy: 0.6000\n",
      "Epoch : 013, Training: Loss - 0.6247, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6288, Accuracy - 63.6364%, Recall - 0.2000, Time: 92.6630s\n",
      "Epoch: 15/200\n",
      "Batch number: 000, Training: Loss: 0.6205, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6020, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.7029, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6733, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6031, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6796, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5652, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5263, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6633, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6353, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6788, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5905, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6236, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.7536, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.6161, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6460, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6046, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6099, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6768, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.5888, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5179, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5339, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6461, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5663, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5904, Accuracy: 0.6667\n",
      "Epoch : 014, Training: Loss - 0.6207, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6259, Accuracy - 63.6364%, Recall - 0.2000, Time: 93.9238s\n",
      "Epoch: 16/200\n",
      "Batch number: 000, Training: Loss: 0.6175, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6351, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6475, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.7047, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.5309, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.7598, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.5535, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6598, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.4876, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.7190, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.5762, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6838, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5769, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5916, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5985, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6523, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5704, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5386, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.7249, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.6547, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5979, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6579, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5457, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6684, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6794, Accuracy: 0.5333\n",
      "Epoch : 015, Training: Loss - 0.6252, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6307, Accuracy - 63.6364%, Recall - 0.4000, Time: 96.4696s\n",
      "Epoch: 17/200\n",
      "Batch number: 000, Training: Loss: 0.6286, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5639, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5542, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.7346, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6586, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6099, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6255, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5509, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6385, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.7337, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6593, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5577, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6532, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.7660, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.5794, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5516, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6436, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5417, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6315, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.7056, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6914, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6031, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7331, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.5685, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5340, Accuracy: 0.8000\n",
      "Epoch : 016, Training: Loss - 0.6290, Accuracy - 64.6617%, \n",
      "\t\tValidation : Loss - 0.6248, Accuracy - 63.6364%, Recall - 0.2500, Time: 92.9744s\n",
      "Epoch: 18/200\n",
      "Batch number: 000, Training: Loss: 0.6053, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5600, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6726, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6233, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7062, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6782, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6597, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6321, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6183, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5922, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6695, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6996, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6360, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5741, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6605, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7025, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.5227, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.7440, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6301, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5635, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5525, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5601, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5207, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6187, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5554, Accuracy: 0.8000\n",
      "Epoch : 017, Training: Loss - 0.6225, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6302, Accuracy - 65.4545%, Recall - 0.3000, Time: 92.8177s\n",
      "Epoch: 19/200\n",
      "Batch number: 000, Training: Loss: 0.5476, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.7657, Accuracy: 0.3750\n",
      "Batch number: 002, Training: Loss: 0.6124, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5895, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5548, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6075, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6318, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5517, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5936, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6439, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6285, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5827, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6590, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6240, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5834, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6046, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6817, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6600, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6315, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6127, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6917, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5614, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6210, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5196, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5661, Accuracy: 0.7333\n",
      "Epoch : 018, Training: Loss - 0.6132, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6336, Accuracy - 67.2727%, Recall - 0.3500, Time: 93.8031s\n",
      "Epoch: 20/200\n",
      "Batch number: 000, Training: Loss: 0.6078, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6475, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.7317, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6262, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.4916, Accuracy: 0.9375\n",
      "Batch number: 005, Training: Loss: 0.6444, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6291, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5483, Accuracy: 0.9375\n",
      "Batch number: 008, Training: Loss: 0.5837, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6214, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6567, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6255, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6180, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6468, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6498, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6318, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6558, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6461, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6308, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6108, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5478, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6730, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5453, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.8270, Accuracy: 0.3125\n",
      "Batch number: 024, Training: Loss: 0.4773, Accuracy: 0.8667\n",
      "Epoch : 019, Training: Loss - 0.6233, Accuracy - 67.4185%, \n",
      "\t\tValidation : Loss - 0.6257, Accuracy - 63.6364%, Recall - 0.2500, Time: 100.6137s\n",
      "Epoch: 21/200\n",
      "Batch number: 000, Training: Loss: 0.5532, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6044, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6147, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5554, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5521, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5956, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5459, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5981, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7096, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.6518, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6085, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5979, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6166, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5079, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6442, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6199, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5931, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6401, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5375, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.7134, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6180, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.8547, Accuracy: 0.3125\n",
      "Batch number: 022, Training: Loss: 0.6775, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6797, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.7150, Accuracy: 0.4667\n",
      "Epoch : 020, Training: Loss - 0.6240, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.6291, Accuracy - 63.6364%, Recall - 0.2500, Time: 95.4027s\n",
      "Epoch: 22/200\n",
      "Batch number: 000, Training: Loss: 0.5406, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6929, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6342, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6135, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5434, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5180, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6840, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.5406, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.4938, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6474, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5678, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.7132, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6314, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6399, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5985, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5131, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6948, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.7585, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5941, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6872, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7041, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5973, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7118, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.6065, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6113, Accuracy: 0.6667\n",
      "Epoch : 021, Training: Loss - 0.6215, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6283, Accuracy - 65.4545%, Recall - 0.3000, Time: 92.5358s\n",
      "Epoch: 23/200\n",
      "Batch number: 000, Training: Loss: 0.5557, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5887, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6692, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6333, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6173, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6809, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5571, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6399, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6136, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5651, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6136, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5360, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6436, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6397, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5358, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6034, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6101, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6808, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5872, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6053, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5727, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6857, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6336, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6258, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6203, Accuracy: 0.6667\n",
      "Epoch : 022, Training: Loss - 0.6126, Accuracy - 67.4185%, \n",
      "\t\tValidation : Loss - 0.6423, Accuracy - 67.2727%, Recall - 0.6000, Time: 96.0837s\n",
      "Epoch: 24/200\n",
      "Batch number: 000, Training: Loss: 0.5089, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.7826, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.5032, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6339, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7452, Accuracy: 0.3750\n",
      "Batch number: 005, Training: Loss: 0.6481, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6205, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6262, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6207, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5504, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5917, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6711, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5850, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6741, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5340, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.7025, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5925, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6925, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.5497, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6609, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5532, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5264, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5443, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6056, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5616, Accuracy: 0.8000\n",
      "Epoch : 023, Training: Loss - 0.6115, Accuracy - 67.1679%, \n",
      "\t\tValidation : Loss - 0.6274, Accuracy - 65.4545%, Recall - 0.4500, Time: 94.5967s\n",
      "Epoch: 25/200\n",
      "Batch number: 000, Training: Loss: 0.7495, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.5997, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6708, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.5159, Accuracy: 0.9375\n",
      "Batch number: 004, Training: Loss: 0.6062, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5697, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5991, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6712, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6513, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.4991, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.6179, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6315, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5162, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5616, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5830, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6880, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5857, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6045, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6884, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6300, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.4671, Accuracy: 1.0000\n",
      "Batch number: 021, Training: Loss: 0.5442, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6384, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6651, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6048, Accuracy: 0.6667\n",
      "Epoch : 024, Training: Loss - 0.6064, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6234, Accuracy - 61.8182%, Recall - 0.2500, Time: 94.2677s\n",
      "Epoch: 26/200\n",
      "Batch number: 000, Training: Loss: 0.5900, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6046, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5728, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5890, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5896, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6011, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6626, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6093, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5549, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7123, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6353, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5247, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.7493, Accuracy: 0.3750\n",
      "Batch number: 013, Training: Loss: 0.6882, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.7031, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5688, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5485, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.5029, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.6909, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5275, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.7078, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6710, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6439, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5470, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.7234, Accuracy: 0.5333\n",
      "Epoch : 025, Training: Loss - 0.6205, Accuracy - 65.6642%, \n",
      "\t\tValidation : Loss - 0.6206, Accuracy - 65.4545%, Recall - 0.2500, Time: 93.5265s\n",
      "Epoch: 27/200\n",
      "Batch number: 000, Training: Loss: 0.6085, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5162, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6072, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6480, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7729, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.7143, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6902, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6523, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5904, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.4895, Accuracy: 0.9375\n",
      "Batch number: 010, Training: Loss: 0.6424, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6298, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.4997, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5434, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.7249, Accuracy: 0.3750\n",
      "Batch number: 015, Training: Loss: 0.6222, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5325, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5886, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5288, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6425, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6109, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.7242, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6477, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5634, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6376, Accuracy: 0.6000\n",
      "Epoch : 026, Training: Loss - 0.6171, Accuracy - 67.1679%, \n",
      "\t\tValidation : Loss - 0.6350, Accuracy - 63.6364%, Recall - 0.5000, Time: 96.9858s\n",
      "Epoch: 28/200\n",
      "Batch number: 000, Training: Loss: 0.6296, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5877, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6318, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5185, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6083, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5568, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5951, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5531, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.8579, Accuracy: 0.3125\n",
      "Batch number: 009, Training: Loss: 0.7799, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6352, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5952, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6317, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5834, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7392, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.6105, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6196, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6387, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6001, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6434, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6854, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6010, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5282, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5379, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.4806, Accuracy: 0.8667\n",
      "Epoch : 027, Training: Loss - 0.6183, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6349, Accuracy - 67.2727%, Recall - 0.5000, Time: 92.5602s\n",
      "Epoch: 29/200\n",
      "Batch number: 000, Training: Loss: 0.5881, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6222, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5259, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6915, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.7343, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6666, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5332, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5897, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6443, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5028, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.6090, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6444, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6040, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6474, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6346, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7410, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6509, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5434, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5301, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5933, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5998, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5830, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5785, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6807, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5731, Accuracy: 0.6000\n",
      "Epoch : 028, Training: Loss - 0.6126, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6319, Accuracy - 67.2727%, Recall - 0.5000, Time: 93.0522s\n",
      "Epoch: 30/200\n",
      "Batch number: 000, Training: Loss: 0.5489, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5237, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6832, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6420, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5090, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6250, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5509, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6444, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6362, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6188, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7508, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6497, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6168, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5695, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.4491, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.6319, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6299, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6359, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.7246, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5296, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.7148, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.5001, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.7240, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6233, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6167, Accuracy: 0.7333\n",
      "Epoch : 029, Training: Loss - 0.6139, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6366, Accuracy - 67.2727%, Recall - 0.5500, Time: 89.4130s\n",
      "Epoch: 31/200\n",
      "Batch number: 000, Training: Loss: 0.6665, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5725, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5987, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5554, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5323, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6218, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.4826, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.6987, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6458, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6012, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6473, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5339, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5392, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.7295, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6757, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6162, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5962, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5894, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6988, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6806, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5624, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6228, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6019, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.7091, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5892, Accuracy: 0.6000\n",
      "Epoch : 030, Training: Loss - 0.6148, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6213, Accuracy - 65.4545%, Recall - 0.3000, Time: 94.0708s\n",
      "Epoch: 32/200\n",
      "Batch number: 000, Training: Loss: 0.5482, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6312, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6358, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5953, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6879, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.4844, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6395, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6006, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6026, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5667, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6210, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6076, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6794, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6373, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6436, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5722, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6269, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6616, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5752, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6003, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5817, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6213, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6672, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5303, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5663, Accuracy: 0.6667\n",
      "Epoch : 031, Training: Loss - 0.6075, Accuracy - 69.9248%, \n",
      "\t\tValidation : Loss - 0.6329, Accuracy - 67.2727%, Recall - 0.5500, Time: 94.1721s\n",
      "Epoch: 33/200\n",
      "Batch number: 000, Training: Loss: 0.6640, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6985, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5303, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5999, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5184, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5522, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6452, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6451, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5204, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6612, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5132, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6078, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5008, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5052, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6311, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5391, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5737, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7580, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.7159, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6681, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.7608, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.8525, Accuracy: 0.3125\n",
      "Batch number: 022, Training: Loss: 0.6854, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5490, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5813, Accuracy: 0.6667\n",
      "Epoch : 032, Training: Loss - 0.6192, Accuracy - 66.1654%, \n",
      "\t\tValidation : Loss - 0.6192, Accuracy - 65.4545%, Recall - 0.2500, Time: 94.8777s\n",
      "Epoch: 34/200\n",
      "Batch number: 000, Training: Loss: 0.6381, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6253, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6024, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6083, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7177, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6141, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6737, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6278, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5506, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6775, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.7261, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.6952, Accuracy: 0.3750\n",
      "Batch number: 012, Training: Loss: 0.5375, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6625, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6523, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7117, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.4960, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.6198, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5891, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6341, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.4981, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6380, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5882, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5367, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5702, Accuracy: 0.7333\n",
      "Epoch : 033, Training: Loss - 0.6198, Accuracy - 65.1629%, \n",
      "\t\tValidation : Loss - 0.6256, Accuracy - 67.2727%, Recall - 0.4000, Time: 88.9839s\n",
      "Epoch: 35/200\n",
      "Batch number: 000, Training: Loss: 0.6185, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7026, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6262, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7281, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6085, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.4593, Accuracy: 0.9375\n",
      "Batch number: 006, Training: Loss: 0.6082, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5474, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6574, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.7136, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.6214, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6013, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5288, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6465, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5551, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.7935, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.4880, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5608, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.7652, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6768, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5449, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6722, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.4313, Accuracy: 0.9375\n",
      "Batch number: 023, Training: Loss: 0.5188, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5612, Accuracy: 0.6000\n",
      "Epoch : 034, Training: Loss - 0.6095, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6255, Accuracy - 67.2727%, Recall - 0.4000, Time: 100.9767s\n",
      "Epoch: 36/200\n",
      "Batch number: 000, Training: Loss: 0.5812, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6676, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6177, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5304, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6259, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5777, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6220, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5964, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6527, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7056, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6221, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5992, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7032, Accuracy: 0.3750\n",
      "Batch number: 013, Training: Loss: 0.5457, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5271, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6020, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.7191, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.8020, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5974, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5756, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6156, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6410, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5656, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6466, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6836, Accuracy: 0.6000\n",
      "Epoch : 035, Training: Loss - 0.6248, Accuracy - 66.1654%, \n",
      "\t\tValidation : Loss - 0.6209, Accuracy - 67.2727%, Recall - 0.3500, Time: 82.3067s\n",
      "Epoch: 37/200\n",
      "Batch number: 000, Training: Loss: 0.7007, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.6066, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.4481, Accuracy: 0.9375\n",
      "Batch number: 003, Training: Loss: 0.6297, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6700, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6130, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6726, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6068, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.7077, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5321, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5675, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5690, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6508, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5826, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6158, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6721, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5961, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5514, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5578, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6402, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5450, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5801, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6416, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6130, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5592, Accuracy: 0.8000\n",
      "Epoch : 036, Training: Loss - 0.6053, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6330, Accuracy - 65.4545%, Recall - 0.4500, Time: 82.3657s\n",
      "Epoch: 38/200\n",
      "Batch number: 000, Training: Loss: 0.5492, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5105, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.7776, Accuracy: 0.4375\n",
      "Batch number: 003, Training: Loss: 0.5957, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5917, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5784, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6291, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6507, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7126, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5207, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6963, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.4835, Accuracy: 0.9375\n",
      "Batch number: 012, Training: Loss: 0.5327, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5831, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5260, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5872, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.7063, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6598, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6150, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7620, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6717, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6210, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5909, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5364, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6443, Accuracy: 0.6667\n",
      "Epoch : 037, Training: Loss - 0.6132, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6271, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.3718s\n",
      "Epoch: 39/200\n",
      "Batch number: 000, Training: Loss: 0.5274, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6153, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6829, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5659, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6002, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5716, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6457, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6131, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5220, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.5763, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5574, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6914, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.6544, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5736, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5907, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5760, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5906, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5988, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5515, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.5915, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6081, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6415, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5381, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.7833, Accuracy: 0.3125\n",
      "Batch number: 024, Training: Loss: 0.6980, Accuracy: 0.6000\n",
      "Epoch : 038, Training: Loss - 0.6064, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6233, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.6440s\n",
      "Epoch: 40/200\n",
      "Batch number: 000, Training: Loss: 0.6918, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5505, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6936, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5941, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5578, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6262, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6278, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6423, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5260, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6683, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.5684, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6503, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7052, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5563, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5844, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5678, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5707, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6046, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5345, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5801, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5696, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5855, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6016, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6020, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5547, Accuracy: 0.8000\n",
      "Epoch : 039, Training: Loss - 0.6007, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6282, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.3230s\n",
      "Epoch: 41/200\n",
      "Batch number: 000, Training: Loss: 0.4817, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.7069, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5899, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6040, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5233, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6563, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6371, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5052, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.7441, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.6756, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6093, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5929, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5565, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5031, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6765, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6366, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6244, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5457, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6832, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6673, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5675, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7070, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6153, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5099, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.7197, Accuracy: 0.6000\n",
      "Epoch : 040, Training: Loss - 0.6133, Accuracy - 66.1654%, \n",
      "\t\tValidation : Loss - 0.6314, Accuracy - 69.0909%, Recall - 0.4500, Time: 82.5354s\n",
      "Epoch: 42/200\n",
      "Batch number: 000, Training: Loss: 0.6397, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6861, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6400, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6306, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6623, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6009, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6738, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5991, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.7316, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5834, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5341, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5674, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5956, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5912, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5548, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6926, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5849, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6369, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5718, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6795, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5816, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6060, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5430, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.7213, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.4328, Accuracy: 1.0000\n",
      "Epoch : 041, Training: Loss - 0.6141, Accuracy - 66.4160%, \n",
      "\t\tValidation : Loss - 0.6289, Accuracy - 67.2727%, Recall - 0.4500, Time: 82.1730s\n",
      "Epoch: 43/200\n",
      "Batch number: 000, Training: Loss: 0.6732, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5148, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.4675, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6253, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6458, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5832, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6151, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5267, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5966, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5483, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6413, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6804, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6414, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5941, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5637, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5716, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.7575, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.8290, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.6444, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6246, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.7880, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.5673, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6003, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.4759, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5653, Accuracy: 0.7333\n",
      "Epoch : 042, Training: Loss - 0.6138, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6254, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.1884s\n",
      "Epoch: 44/200\n",
      "Batch number: 000, Training: Loss: 0.5040, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6032, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5303, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5552, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5540, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6580, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6510, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6692, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6329, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5024, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6371, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6901, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5536, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6963, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.6939, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6204, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5794, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7924, Accuracy: 0.3125\n",
      "Batch number: 018, Training: Loss: 0.4944, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6139, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6318, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6615, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.4985, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.6143, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6160, Accuracy: 0.6667\n",
      "Epoch : 043, Training: Loss - 0.6101, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6362, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.1118s\n",
      "Epoch: 45/200\n",
      "Batch number: 000, Training: Loss: 0.6106, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6118, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6957, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6483, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5835, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6444, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6356, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5526, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5167, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5405, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6988, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5775, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7455, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5140, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6204, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6138, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6075, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5782, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5369, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5912, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5772, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5387, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6188, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6894, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6512, Accuracy: 0.6000\n",
      "Epoch : 044, Training: Loss - 0.6078, Accuracy - 67.1679%, \n",
      "\t\tValidation : Loss - 0.6251, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.3970s\n",
      "Epoch: 46/200\n",
      "Batch number: 000, Training: Loss: 0.5425, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5601, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6234, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7551, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.5140, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.7492, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.5803, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.4935, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6031, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6612, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6870, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6211, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6953, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.7294, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5372, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5809, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5265, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6039, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7568, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.5159, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5733, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5602, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.7205, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.6066, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5773, Accuracy: 0.6667\n",
      "Epoch : 045, Training: Loss - 0.6151, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6233, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.1688s\n",
      "Epoch: 47/200\n",
      "Batch number: 000, Training: Loss: 0.6094, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5346, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6101, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5728, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5973, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.7322, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.8016, Accuracy: 0.3125\n",
      "Batch number: 007, Training: Loss: 0.5007, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6561, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6520, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5778, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6162, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7077, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5239, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6946, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5939, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5592, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5734, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6092, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5876, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5898, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5946, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5483, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5638, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.7041, Accuracy: 0.4667\n",
      "Epoch : 046, Training: Loss - 0.6122, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6255, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.2195s\n",
      "Epoch: 48/200\n",
      "Batch number: 000, Training: Loss: 0.5332, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.4775, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5813, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6565, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5429, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.7180, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.4721, Accuracy: 0.9375\n",
      "Batch number: 007, Training: Loss: 0.5885, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6191, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6650, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6017, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5667, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6310, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5860, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5604, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5285, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5071, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5806, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5449, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6790, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6851, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6810, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6721, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6207, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6971, Accuracy: 0.6000\n",
      "Epoch : 047, Training: Loss - 0.5996, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6264, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.1621s\n",
      "Epoch: 49/200\n",
      "Batch number: 000, Training: Loss: 0.5359, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6004, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5118, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5497, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6249, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5795, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5907, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5722, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6008, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5779, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5716, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6112, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6168, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5247, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5851, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6648, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6148, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6926, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6471, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6374, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6390, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5611, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6036, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5261, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6410, Accuracy: 0.6667\n",
      "Epoch : 048, Training: Loss - 0.5951, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6304, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.3989s\n",
      "Epoch: 50/200\n",
      "Batch number: 000, Training: Loss: 0.5524, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5938, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6013, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6438, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.7406, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.6859, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5799, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5308, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.4896, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5798, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6523, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6194, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6142, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5692, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5619, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6000, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6518, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5753, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6324, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5587, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5548, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6926, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.7595, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.7282, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.4783, Accuracy: 0.8000\n",
      "Epoch : 049, Training: Loss - 0.6102, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.6286, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.3465s\n",
      "Epoch: 51/200\n",
      "Batch number: 000, Training: Loss: 0.6923, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.6463, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6489, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6847, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5416, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.4893, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5294, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5323, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5980, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.7211, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6673, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6313, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6622, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5620, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.7181, Accuracy: 0.3750\n",
      "Batch number: 015, Training: Loss: 0.5715, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5300, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6443, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5182, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5019, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.5400, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6186, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6683, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5448, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5754, Accuracy: 0.8000\n",
      "Epoch : 050, Training: Loss - 0.6016, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6277, Accuracy - 67.2727%, Recall - 0.4500, Time: 82.1845s\n",
      "Epoch: 52/200\n",
      "Batch number: 000, Training: Loss: 0.5177, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5680, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7010, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7358, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5147, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5956, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5224, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.7244, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6308, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5948, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6090, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6720, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5909, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5543, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5265, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5836, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.7245, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6415, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5459, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6335, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6889, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5711, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5692, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5857, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5495, Accuracy: 0.8000\n",
      "Epoch : 051, Training: Loss - 0.6062, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6309, Accuracy - 67.2727%, Recall - 0.4500, Time: 82.1831s\n",
      "Epoch: 53/200\n",
      "Batch number: 000, Training: Loss: 0.5627, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5923, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.4914, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5105, Accuracy: 0.9375\n",
      "Batch number: 004, Training: Loss: 0.6365, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.7660, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.6168, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6452, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5625, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5869, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5224, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5925, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5410, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5628, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.7397, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5553, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6269, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.7002, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6189, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.4575, Accuracy: 1.0000\n",
      "Batch number: 020, Training: Loss: 0.6412, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5510, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7427, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6653, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6061, Accuracy: 0.6000\n",
      "Epoch : 052, Training: Loss - 0.6038, Accuracy - 67.4185%, \n",
      "\t\tValidation : Loss - 0.6294, Accuracy - 69.0909%, Recall - 0.4500, Time: 82.2846s\n",
      "Epoch: 54/200\n",
      "Batch number: 000, Training: Loss: 0.5846, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5364, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.7517, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.5015, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6172, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5506, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6115, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6330, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5643, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6089, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5371, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.4999, Accuracy: 0.9375\n",
      "Batch number: 012, Training: Loss: 0.5399, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5181, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5904, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6592, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6235, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.4793, Accuracy: 0.9375\n",
      "Batch number: 018, Training: Loss: 0.5568, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6842, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.7027, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6142, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6010, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7307, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6603, Accuracy: 0.5333\n",
      "Epoch : 053, Training: Loss - 0.5981, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6270, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.3299s\n",
      "Epoch: 55/200\n",
      "Batch number: 000, Training: Loss: 0.6335, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5577, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.4924, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6067, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6230, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5088, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6295, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6897, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5619, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5801, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7096, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6593, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.4861, Accuracy: 0.9375\n",
      "Batch number: 013, Training: Loss: 0.6247, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5513, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5868, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.4889, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6723, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6644, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7413, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.6286, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5718, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6493, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5335, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.7901, Accuracy: 0.4000\n",
      "Epoch : 054, Training: Loss - 0.6092, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6241, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.0961s\n",
      "Epoch: 56/200\n",
      "Batch number: 000, Training: Loss: 0.5754, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5466, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5501, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.4644, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.7130, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6499, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5542, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5876, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6959, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6984, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.4651, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6163, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5262, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5991, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6194, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5415, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.7125, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.5712, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5729, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6584, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6245, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6264, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5163, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5676, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6251, Accuracy: 0.6000\n",
      "Epoch : 055, Training: Loss - 0.5950, Accuracy - 70.4261%, \n",
      "\t\tValidation : Loss - 0.6379, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.1837s\n",
      "Epoch: 57/200\n",
      "Batch number: 000, Training: Loss: 0.6024, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6452, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5177, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6198, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5184, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6248, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7496, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5935, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5456, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5579, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6010, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5432, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5976, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6705, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5418, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5025, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5457, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.7281, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6359, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6547, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5989, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6501, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5493, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6083, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5740, Accuracy: 0.8000\n",
      "Epoch : 056, Training: Loss - 0.5991, Accuracy - 69.9248%, \n",
      "\t\tValidation : Loss - 0.6371, Accuracy - 61.8182%, Recall - 0.5000, Time: 82.2534s\n",
      "Epoch: 58/200\n",
      "Batch number: 000, Training: Loss: 0.6462, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5870, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7134, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5335, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5226, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5068, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6539, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6525, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5926, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5959, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6500, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.4943, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5404, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5792, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6269, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5609, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.4606, Accuracy: 0.9375\n",
      "Batch number: 017, Training: Loss: 0.5406, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6490, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6425, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6841, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6067, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6499, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5555, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6428, Accuracy: 0.6000\n",
      "Epoch : 057, Training: Loss - 0.5954, Accuracy - 69.9248%, \n",
      "\t\tValidation : Loss - 0.6411, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.4741s\n",
      "Epoch: 59/200\n",
      "Batch number: 000, Training: Loss: 0.6116, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6916, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.5588, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5438, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6377, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6170, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6865, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6307, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6065, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5599, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6182, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5757, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6431, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.6338, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.6662, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5547, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6201, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6310, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5543, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6143, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5072, Accuracy: 0.9375\n",
      "Batch number: 021, Training: Loss: 0.5228, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.5894, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5622, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6180, Accuracy: 0.6667\n",
      "Epoch : 058, Training: Loss - 0.6022, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6338, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.1996s\n",
      "Epoch: 60/200\n",
      "Batch number: 000, Training: Loss: 0.6223, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6076, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5971, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.4743, Accuracy: 0.9375\n",
      "Batch number: 004, Training: Loss: 0.5821, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6160, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6013, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6014, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5192, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.7198, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.7301, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6408, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5815, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6354, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6067, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5089, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6278, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6780, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6185, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.7917, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.5800, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6153, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5355, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5554, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.7188, Accuracy: 0.6667\n",
      "Epoch : 059, Training: Loss - 0.6144, Accuracy - 66.4160%, \n",
      "\t\tValidation : Loss - 0.6371, Accuracy - 63.6364%, Recall - 0.4000, Time: 82.1658s\n",
      "Epoch: 61/200\n",
      "Batch number: 000, Training: Loss: 0.5591, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6042, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5400, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5417, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6315, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5927, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6680, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6122, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6707, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.7040, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5957, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.4910, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6205, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.4962, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6343, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5906, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.7400, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.5936, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7380, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.5427, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.5777, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5058, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.6270, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5793, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6082, Accuracy: 0.6667\n",
      "Epoch : 060, Training: Loss - 0.6026, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6256, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.8910s\n",
      "Epoch: 62/200\n",
      "Batch number: 000, Training: Loss: 0.5894, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5296, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5534, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5294, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5887, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5877, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.4955, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6025, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.8096, Accuracy: 0.3750\n",
      "Batch number: 009, Training: Loss: 0.6089, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5694, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6555, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5217, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6480, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5261, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6877, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6302, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6625, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5263, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.7349, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6311, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.7743, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.5417, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6485, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6274, Accuracy: 0.6000\n",
      "Epoch : 061, Training: Loss - 0.6112, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.6489, Accuracy - 63.6364%, Recall - 0.5500, Time: 82.7921s\n",
      "Epoch: 63/200\n",
      "Batch number: 000, Training: Loss: 0.5482, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6686, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.7335, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.5867, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5899, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5916, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6187, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6913, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6597, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5472, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5025, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6115, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5648, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6356, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6152, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6215, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6280, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6851, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5155, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6060, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5493, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.5964, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5205, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5839, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5333, Accuracy: 0.7333\n",
      "Epoch : 062, Training: Loss - 0.6004, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6341, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.3700s\n",
      "Epoch: 64/200\n",
      "Batch number: 000, Training: Loss: 0.6844, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5379, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.6473, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6145, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6158, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5949, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6912, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5206, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6924, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5157, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.4774, Accuracy: 1.0000\n",
      "Batch number: 011, Training: Loss: 0.4832, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.6655, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6478, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5195, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5944, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6553, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6261, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5132, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.7498, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.5262, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5821, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6185, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5647, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6172, Accuracy: 0.6667\n",
      "Epoch : 063, Training: Loss - 0.5982, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6276, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.0610s\n",
      "Epoch: 65/200\n",
      "Batch number: 000, Training: Loss: 0.5860, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6065, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6267, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6328, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6110, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5853, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6250, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5680, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6179, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5748, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7424, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.4875, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5625, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6056, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.4992, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5016, Accuracy: 0.9375\n",
      "Batch number: 016, Training: Loss: 0.6491, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6216, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5624, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6116, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6673, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6796, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.5316, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5079, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5783, Accuracy: 0.7333\n",
      "Epoch : 064, Training: Loss - 0.5937, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6388, Accuracy - 61.8182%, Recall - 0.5500, Time: 82.5094s\n",
      "Epoch: 66/200\n",
      "Batch number: 000, Training: Loss: 0.7053, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5899, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5757, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5825, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5523, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6047, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5113, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.6136, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6274, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6669, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6125, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5768, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7339, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5922, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6069, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.7381, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.4943, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.5794, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6344, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6021, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5392, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5897, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5286, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5646, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6821, Accuracy: 0.6000\n",
      "Epoch : 065, Training: Loss - 0.6040, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6332, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.5794s\n",
      "Epoch: 67/200\n",
      "Batch number: 000, Training: Loss: 0.6268, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6048, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5656, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6269, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6831, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6637, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5848, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5429, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6315, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5566, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5899, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6410, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5349, Accuracy: 0.9375\n",
      "Batch number: 013, Training: Loss: 0.6849, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5245, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6113, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6772, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.4704, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5777, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5534, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6443, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.8567, Accuracy: 0.3125\n",
      "Batch number: 022, Training: Loss: 0.5196, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6288, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6503, Accuracy: 0.6000\n",
      "Epoch : 066, Training: Loss - 0.6100, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6223, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.1789s\n",
      "Epoch: 68/200\n",
      "Batch number: 000, Training: Loss: 0.5552, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5361, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6846, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6372, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7141, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.7134, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.5897, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5938, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5653, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6542, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5915, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5456, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5957, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5854, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5432, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5838, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6106, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5656, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5015, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5447, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6515, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6160, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5952, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.4927, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.8100, Accuracy: 0.4000\n",
      "Epoch : 067, Training: Loss - 0.6025, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6235, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.0945s\n",
      "Epoch: 69/200\n",
      "Batch number: 000, Training: Loss: 0.6458, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5929, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5481, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6520, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5986, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6738, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5173, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.7527, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.5569, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5194, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5021, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6563, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.5468, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5737, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6302, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5891, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6021, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6236, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5913, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6163, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6259, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5662, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6415, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6796, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.5614, Accuracy: 0.7333\n",
      "Epoch : 068, Training: Loss - 0.6026, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6278, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.3118s\n",
      "Epoch: 70/200\n",
      "Batch number: 000, Training: Loss: 0.4599, Accuracy: 0.9375\n",
      "Batch number: 001, Training: Loss: 0.5364, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6543, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6507, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5917, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6605, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6820, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.6075, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5924, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5921, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6100, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5437, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6305, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5704, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5765, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6782, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6115, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6032, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6305, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5934, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5256, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6496, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5484, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6688, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5445, Accuracy: 0.8000\n",
      "Epoch : 069, Training: Loss - 0.6006, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6205, Accuracy - 69.0909%, Recall - 0.2500, Time: 82.4261s\n",
      "Epoch: 71/200\n",
      "Batch number: 000, Training: Loss: 0.7145, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5561, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7147, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7187, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6098, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.4498, Accuracy: 0.9375\n",
      "Batch number: 006, Training: Loss: 0.5148, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5448, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5698, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5900, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7513, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6044, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5361, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6309, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5523, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.4932, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5799, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7175, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5958, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6267, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6643, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6656, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.6133, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5535, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6057, Accuracy: 0.7333\n",
      "Epoch : 070, Training: Loss - 0.6069, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6225, Accuracy - 67.2727%, Recall - 0.3500, Time: 82.2450s\n",
      "Epoch: 72/200\n",
      "Batch number: 000, Training: Loss: 0.5413, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.5416, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6125, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5564, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6870, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5200, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5535, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.4595, Accuracy: 0.9375\n",
      "Batch number: 008, Training: Loss: 0.5467, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5545, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6862, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.4973, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.7448, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.4976, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5176, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6771, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6895, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6316, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7063, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.4962, Accuracy: 0.9375\n",
      "Batch number: 020, Training: Loss: 0.7401, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5754, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.4955, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.6789, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.7058, Accuracy: 0.5333\n",
      "Epoch : 071, Training: Loss - 0.5962, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6336, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.1871s\n",
      "Epoch: 73/200\n",
      "Batch number: 000, Training: Loss: 0.5981, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5581, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6509, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5626, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5277, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5733, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5658, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5660, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5684, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6201, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5934, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5344, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5812, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6736, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6163, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5392, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5876, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6554, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6407, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7937, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.6076, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6009, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7083, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5733, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5770, Accuracy: 0.7333\n",
      "Epoch : 072, Training: Loss - 0.6030, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6385, Accuracy - 65.4545%, Recall - 0.4500, Time: 82.3352s\n",
      "Epoch: 74/200\n",
      "Batch number: 000, Training: Loss: 0.5241, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.5926, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7102, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5356, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6548, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5568, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6618, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6608, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6578, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6189, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5681, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6834, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6139, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5091, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6552, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6536, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5717, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7648, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.6426, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5295, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.6657, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5979, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6353, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6066, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5463, Accuracy: 0.7333\n",
      "Epoch : 073, Training: Loss - 0.6169, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6256, Accuracy - 65.4545%, Recall - 0.3500, Time: 82.3273s\n",
      "Epoch: 75/200\n",
      "Batch number: 000, Training: Loss: 0.6549, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6943, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.4947, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5191, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6174, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.7125, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6099, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5266, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6499, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5796, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5636, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6782, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.7560, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.6481, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5316, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.4718, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5750, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6217, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5184, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6783, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5950, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7111, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5626, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6593, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.4684, Accuracy: 0.9333\n",
      "Epoch : 074, Training: Loss - 0.6043, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6258, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.1342s\n",
      "Epoch: 76/200\n",
      "Batch number: 000, Training: Loss: 0.4998, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5247, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5192, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5761, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5583, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5933, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6063, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.8590, Accuracy: 0.3125\n",
      "Batch number: 008, Training: Loss: 0.5436, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7385, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5934, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5750, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5352, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6128, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.4804, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.6286, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6131, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.4980, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.6953, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6588, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6138, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5647, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6180, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7358, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.7558, Accuracy: 0.4667\n",
      "Epoch : 075, Training: Loss - 0.6075, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6257, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.2653s\n",
      "Epoch: 77/200\n",
      "Batch number: 000, Training: Loss: 0.6574, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6283, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5475, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5964, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7248, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5474, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5483, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.6311, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5777, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5729, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6348, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.4964, Accuracy: 0.9375\n",
      "Batch number: 012, Training: Loss: 0.6596, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6088, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6931, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6607, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6707, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6340, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6397, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.4633, Accuracy: 0.9375\n",
      "Batch number: 020, Training: Loss: 0.6188, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6753, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6890, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5237, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.4648, Accuracy: 0.9333\n",
      "Epoch : 076, Training: Loss - 0.6069, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6351, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.1761s\n",
      "Epoch: 78/200\n",
      "Batch number: 000, Training: Loss: 0.6212, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.4662, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5123, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5415, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.7022, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6483, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6120, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5094, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5345, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.7240, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6750, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.6247, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5623, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.7606, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5939, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6251, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5469, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5181, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6178, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5529, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6560, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5901, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6433, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6774, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5644, Accuracy: 0.7333\n",
      "Epoch : 077, Training: Loss - 0.6033, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6270, Accuracy - 72.7273%, Recall - 0.4000, Time: 82.2580s\n",
      "Epoch: 79/200\n",
      "Batch number: 000, Training: Loss: 0.5588, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5071, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5748, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6879, Accuracy: 0.4375\n",
      "Batch number: 004, Training: Loss: 0.5165, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5869, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5752, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5000, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6039, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6027, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5859, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6402, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6321, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6280, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5796, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6601, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5967, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6015, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6975, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5294, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5678, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7335, Accuracy: 0.4375\n",
      "Batch number: 022, Training: Loss: 0.6659, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5306, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6264, Accuracy: 0.6000\n",
      "Epoch : 078, Training: Loss - 0.5995, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6307, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.1037s\n",
      "Epoch: 80/200\n",
      "Batch number: 000, Training: Loss: 0.5813, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6167, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5298, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6040, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6642, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5290, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6341, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5992, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6246, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6863, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6381, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5382, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.6028, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5154, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5723, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5849, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5924, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5183, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6588, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.7972, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.5072, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6722, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.4991, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5261, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5750, Accuracy: 0.8000\n",
      "Epoch : 079, Training: Loss - 0.5947, Accuracy - 69.9248%, \n",
      "\t\tValidation : Loss - 0.6317, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.1810s\n",
      "Epoch: 81/200\n",
      "Batch number: 000, Training: Loss: 0.7213, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.6959, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.5850, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5878, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6298, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6023, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6523, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6209, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5230, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6190, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5544, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5800, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5502, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.4969, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.7515, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5025, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5359, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5251, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.4993, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.7988, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.5886, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6603, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5380, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5478, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.7476, Accuracy: 0.4667\n",
      "Epoch : 080, Training: Loss - 0.6042, Accuracy - 66.1654%, \n",
      "\t\tValidation : Loss - 0.6238, Accuracy - 69.0909%, Recall - 0.3500, Time: 82.2850s\n",
      "Epoch: 82/200\n",
      "Batch number: 000, Training: Loss: 0.7357, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5864, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6389, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5920, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.4553, Accuracy: 0.9375\n",
      "Batch number: 005, Training: Loss: 0.5032, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.5971, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5631, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6251, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5543, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7037, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5258, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5972, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5338, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6872, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5942, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6888, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.5425, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5966, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6345, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6570, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5880, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6259, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6020, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5398, Accuracy: 0.8000\n",
      "Epoch : 081, Training: Loss - 0.5989, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6320, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.3815s\n",
      "Epoch: 83/200\n",
      "Batch number: 000, Training: Loss: 0.5226, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6076, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5268, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5566, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6727, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5967, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6776, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5471, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7064, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.5835, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5513, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6208, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5572, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5477, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6819, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.7078, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5614, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.6654, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6272, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5610, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6392, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6034, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6671, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.4738, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5736, Accuracy: 0.6667\n",
      "Epoch : 082, Training: Loss - 0.6015, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6280, Accuracy - 69.0909%, Recall - 0.3500, Time: 82.3274s\n",
      "Epoch: 84/200\n",
      "Batch number: 000, Training: Loss: 0.6332, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6339, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6446, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6154, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6106, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5531, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5665, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6229, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5942, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5750, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5219, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5392, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7330, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.6374, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5010, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5889, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5305, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5860, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5915, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6738, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5636, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5188, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5279, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6084, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6991, Accuracy: 0.5333\n",
      "Epoch : 083, Training: Loss - 0.5946, Accuracy - 69.9248%, \n",
      "\t\tValidation : Loss - 0.6325, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.6173s\n",
      "Epoch: 85/200\n",
      "Batch number: 000, Training: Loss: 0.5815, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6309, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5722, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5051, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5468, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5778, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5265, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6896, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6345, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5732, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5971, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6530, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6048, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.7020, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5456, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5413, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6344, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5899, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5803, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6236, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6541, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5791, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5991, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5658, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5979, Accuracy: 0.8000\n",
      "Epoch : 084, Training: Loss - 0.5962, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6290, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.5894s\n",
      "Epoch: 86/200\n",
      "Batch number: 000, Training: Loss: 0.5406, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6196, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5752, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7054, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.7526, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5551, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5866, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6379, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5685, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5849, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5371, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6433, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5401, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6057, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6484, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5275, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5526, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5009, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5571, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6577, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6634, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6153, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6007, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5284, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5327, Accuracy: 0.8000\n",
      "Epoch : 085, Training: Loss - 0.5936, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6316, Accuracy - 65.4545%, Recall - 0.4000, Time: 82.1849s\n",
      "Epoch: 87/200\n",
      "Batch number: 000, Training: Loss: 0.5905, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.8253, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.5807, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5674, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6166, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6054, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5648, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6245, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6938, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5627, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6977, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.5447, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6081, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.4815, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5855, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5830, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5132, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.4779, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5119, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5772, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6093, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6192, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6689, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.4846, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5558, Accuracy: 0.6667\n",
      "Epoch : 086, Training: Loss - 0.5901, Accuracy - 72.6817%, \n",
      "\t\tValidation : Loss - 0.6352, Accuracy - 63.6364%, Recall - 0.4000, Time: 82.1571s\n",
      "Epoch: 88/200\n",
      "Batch number: 000, Training: Loss: 0.6393, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.7260, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.5910, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6379, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6680, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.5716, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.7030, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6169, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5862, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5171, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5560, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6153, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.4936, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.5220, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6558, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.4977, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.7722, Accuracy: 0.3750\n",
      "Batch number: 017, Training: Loss: 0.5544, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5996, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6025, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6335, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5995, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5213, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5610, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6227, Accuracy: 0.6667\n",
      "Epoch : 087, Training: Loss - 0.6025, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6236, Accuracy - 70.9091%, Recall - 0.3500, Time: 82.2733s\n",
      "Epoch: 89/200\n",
      "Batch number: 000, Training: Loss: 0.5717, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6204, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5276, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.4684, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.5193, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6249, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6032, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5419, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5695, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.8968, Accuracy: 0.3125\n",
      "Batch number: 010, Training: Loss: 0.5618, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5437, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.6322, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.4914, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6282, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.4371, Accuracy: 0.9375\n",
      "Batch number: 016, Training: Loss: 0.7870, Accuracy: 0.3750\n",
      "Batch number: 017, Training: Loss: 0.7987, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.7381, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7275, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5593, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5748, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6667, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5564, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5419, Accuracy: 0.8000\n",
      "Epoch : 088, Training: Loss - 0.6077, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6373, Accuracy - 63.6364%, Recall - 0.4500, Time: 82.9999s\n",
      "Epoch: 90/200\n",
      "Batch number: 000, Training: Loss: 0.6192, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7188, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6245, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5176, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6876, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6134, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6258, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5578, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6606, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.4850, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5670, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6195, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5529, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6673, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5875, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6198, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5227, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6292, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6149, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7844, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.5997, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5662, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6371, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5145, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.4872, Accuracy: 0.8667\n",
      "Epoch : 089, Training: Loss - 0.6035, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6290, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.1693s\n",
      "Epoch: 91/200\n",
      "Batch number: 000, Training: Loss: 0.7022, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.6086, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5995, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6345, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5310, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5901, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5091, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5785, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7294, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6090, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5722, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5310, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6118, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5944, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6056, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6277, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5808, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.7330, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.6347, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6173, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5582, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5915, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6052, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5527, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5435, Accuracy: 0.8000\n",
      "Epoch : 090, Training: Loss - 0.6022, Accuracy - 67.1679%, \n",
      "\t\tValidation : Loss - 0.6262, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.1483s\n",
      "Epoch: 92/200\n",
      "Batch number: 000, Training: Loss: 0.7685, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.5478, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5546, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5123, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6188, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5705, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6964, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.5260, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6213, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6050, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7186, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.5573, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6547, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5524, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5561, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5390, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.7620, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.5610, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5967, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5515, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5978, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5636, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5964, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5015, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6322, Accuracy: 0.5333\n",
      "Epoch : 091, Training: Loss - 0.5984, Accuracy - 66.4160%, \n",
      "\t\tValidation : Loss - 0.6438, Accuracy - 63.6364%, Recall - 0.5500, Time: 82.2274s\n",
      "Epoch: 93/200\n",
      "Batch number: 000, Training: Loss: 0.6432, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6062, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6793, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6281, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6244, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5780, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5048, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5737, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5907, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.4638, Accuracy: 0.9375\n",
      "Batch number: 010, Training: Loss: 0.6508, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.5606, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5465, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5603, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5482, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.7688, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5616, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5707, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5069, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5945, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6470, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5355, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.6039, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5582, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6341, Accuracy: 0.6667\n",
      "Epoch : 092, Training: Loss - 0.5895, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6300, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.3171s\n",
      "Epoch: 94/200\n",
      "Batch number: 000, Training: Loss: 0.5636, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.4355, Accuracy: 0.9375\n",
      "Batch number: 002, Training: Loss: 0.5390, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5355, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.7168, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6887, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5510, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7537, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6795, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6615, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.5373, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.7046, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6497, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5228, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6325, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6438, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6494, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.4663, Accuracy: 0.9375\n",
      "Batch number: 018, Training: Loss: 0.5636, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.4770, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.7218, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5384, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5124, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6413, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6095, Accuracy: 0.7333\n",
      "Epoch : 093, Training: Loss - 0.5998, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6190, Accuracy - 69.0909%, Recall - 0.2500, Time: 82.0976s\n",
      "Epoch: 95/200\n",
      "Batch number: 000, Training: Loss: 0.5030, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.7485, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6610, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6760, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.4735, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.6041, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6232, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5710, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6293, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6324, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5883, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5205, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6553, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5540, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5842, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5378, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5432, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5567, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5960, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6464, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6249, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6327, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5871, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7054, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5720, Accuracy: 0.7333\n",
      "Epoch : 094, Training: Loss - 0.6011, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6368, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.3751s\n",
      "Epoch: 96/200\n",
      "Batch number: 000, Training: Loss: 0.7580, Accuracy: 0.3750\n",
      "Batch number: 001, Training: Loss: 0.6387, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5758, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6481, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6520, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5158, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6691, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6047, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5436, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5670, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5484, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5746, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.4932, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5978, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6427, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5317, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.4986, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.6908, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6047, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5948, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6502, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6560, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5549, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6226, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5786, Accuracy: 0.7333\n",
      "Epoch : 095, Training: Loss - 0.6005, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6328, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.2347s\n",
      "Epoch: 97/200\n",
      "Batch number: 000, Training: Loss: 0.5863, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5880, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6145, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5989, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.7240, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.4953, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6875, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6993, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5532, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6898, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.5234, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.5255, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5782, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5307, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5683, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5761, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.7203, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.4629, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5999, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5674, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.4485, Accuracy: 1.0000\n",
      "Batch number: 021, Training: Loss: 0.6026, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5684, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6978, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.7086, Accuracy: 0.5333\n",
      "Epoch : 096, Training: Loss - 0.5963, Accuracy - 70.9273%, \n",
      "\t\tValidation : Loss - 0.6285, Accuracy - 69.0909%, Recall - 0.3500, Time: 82.3799s\n",
      "Epoch: 98/200\n",
      "Batch number: 000, Training: Loss: 0.4785, Accuracy: 0.9375\n",
      "Batch number: 001, Training: Loss: 0.5602, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5387, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6530, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5797, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5799, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6671, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6047, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6353, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6221, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5776, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6153, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5615, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5551, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6518, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5465, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5315, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6410, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6139, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6738, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6097, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5632, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5739, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6512, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5804, Accuracy: 0.6667\n",
      "Epoch : 097, Training: Loss - 0.5947, Accuracy - 70.4261%, \n",
      "\t\tValidation : Loss - 0.6350, Accuracy - 69.0909%, Recall - 0.5500, Time: 82.1400s\n",
      "Epoch: 99/200\n",
      "Batch number: 000, Training: Loss: 0.6392, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5841, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5973, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5147, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.8973, Accuracy: 0.3125\n",
      "Batch number: 005, Training: Loss: 0.4742, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.7433, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.4976, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.7250, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6683, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.5701, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5197, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6659, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5270, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6073, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6044, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5900, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6027, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6585, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5313, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6773, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.4721, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.4989, Accuracy: 0.9375\n",
      "Batch number: 023, Training: Loss: 0.5965, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5088, Accuracy: 0.8000\n",
      "Epoch : 098, Training: Loss - 0.5991, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6310, Accuracy - 67.2727%, Recall - 0.4500, Time: 82.1983s\n",
      "Epoch: 100/200\n",
      "Batch number: 000, Training: Loss: 0.5669, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5391, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5388, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5351, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6024, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5884, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5888, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6387, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.4744, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5118, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.6202, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6428, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6937, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.7446, Accuracy: 0.3750\n",
      "Batch number: 014, Training: Loss: 0.6361, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.4757, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6393, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6690, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5671, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5379, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5130, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6030, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6816, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6274, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6834, Accuracy: 0.5333\n",
      "Epoch : 099, Training: Loss - 0.5966, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6286, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.2322s\n",
      "Epoch: 101/200\n",
      "Batch number: 000, Training: Loss: 0.5417, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.7259, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.5869, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6109, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5011, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6833, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6545, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5102, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.4718, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.5752, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5916, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5796, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5713, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6060, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6506, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6355, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6533, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6704, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6232, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5231, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6503, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5971, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7378, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6610, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5338, Accuracy: 0.7333\n",
      "Epoch : 100, Training: Loss - 0.6060, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6262, Accuracy - 65.4545%, Recall - 0.3000, Time: 82.5395s\n",
      "Epoch: 102/200\n",
      "Batch number: 000, Training: Loss: 0.6440, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6730, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5582, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5119, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6072, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6867, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.6620, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5684, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5967, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.4894, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.5009, Accuracy: 0.9375\n",
      "Batch number: 011, Training: Loss: 0.5494, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6170, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5870, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5827, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5287, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6186, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5005, Accuracy: 0.9375\n",
      "Batch number: 018, Training: Loss: 0.6623, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6468, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5901, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5267, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6183, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5729, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6977, Accuracy: 0.5333\n",
      "Epoch : 101, Training: Loss - 0.5916, Accuracy - 72.4311%, \n",
      "\t\tValidation : Loss - 0.6231, Accuracy - 69.0909%, Recall - 0.2500, Time: 82.2881s\n",
      "Epoch: 103/200\n",
      "Batch number: 000, Training: Loss: 0.7402, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.7080, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6156, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5583, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6559, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5995, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5247, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.4588, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.5206, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5007, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6881, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6387, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6145, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6574, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5590, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6151, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5726, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5794, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6398, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5589, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6903, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.6432, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5137, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5525, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5095, Accuracy: 0.8667\n",
      "Epoch : 102, Training: Loss - 0.5968, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6373, Accuracy - 63.6364%, Recall - 0.4500, Time: 82.5427s\n",
      "Epoch: 104/200\n",
      "Batch number: 000, Training: Loss: 0.6468, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5792, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5520, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5613, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5221, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.7189, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.5752, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5751, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6501, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6235, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6572, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6706, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5551, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.4545, Accuracy: 1.0000\n",
      "Batch number: 014, Training: Loss: 0.5155, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5589, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6819, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6666, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5746, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6740, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6023, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5968, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6098, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6375, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6021, Accuracy: 0.6667\n",
      "Epoch : 103, Training: Loss - 0.6025, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6291, Accuracy - 70.9091%, Recall - 0.4000, Time: 82.1378s\n",
      "Epoch: 105/200\n",
      "Batch number: 000, Training: Loss: 0.5854, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.4575, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.6158, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6507, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6219, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6046, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6265, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.7538, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.5066, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5617, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5454, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6064, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.4919, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6142, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.7357, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.7412, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5260, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5588, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6494, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5398, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6357, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5205, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7117, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6238, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.4911, Accuracy: 0.8000\n",
      "Epoch : 104, Training: Loss - 0.5993, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6270, Accuracy - 70.9091%, Recall - 0.4000, Time: 82.3473s\n",
      "Epoch: 106/200\n",
      "Batch number: 000, Training: Loss: 0.5847, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5580, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.7543, Accuracy: 0.4375\n",
      "Batch number: 003, Training: Loss: 0.5388, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5622, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5795, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5958, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7224, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.5250, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6013, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.4641, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5713, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5762, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6489, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6011, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5386, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5413, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6045, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6872, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6177, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6174, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6025, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6621, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6131, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6286, Accuracy: 0.6000\n",
      "Epoch : 105, Training: Loss - 0.5998, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6348, Accuracy - 63.6364%, Recall - 0.4000, Time: 82.6060s\n",
      "Epoch: 107/200\n",
      "Batch number: 000, Training: Loss: 0.5409, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6119, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5763, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7611, Accuracy: 0.3750\n",
      "Batch number: 004, Training: Loss: 0.5764, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6232, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5248, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6136, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5829, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5794, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5875, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5261, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5961, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.7179, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.7506, Accuracy: 0.4375\n",
      "Batch number: 015, Training: Loss: 0.5826, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5565, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5320, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5673, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5956, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5926, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5398, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6648, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.4950, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.6106, Accuracy: 0.7333\n",
      "Epoch : 106, Training: Loss - 0.5962, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6303, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.6728s\n",
      "Epoch: 108/200\n",
      "Batch number: 000, Training: Loss: 0.6382, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5876, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5850, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5764, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5729, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6583, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6696, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7804, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.5590, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5684, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5781, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5447, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6831, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5467, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5038, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5574, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6698, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.5786, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.4234, Accuracy: 0.9375\n",
      "Batch number: 019, Training: Loss: 0.6062, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5240, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6021, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5476, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.4685, Accuracy: 0.9375\n",
      "Batch number: 024, Training: Loss: 0.6776, Accuracy: 0.5333\n",
      "Epoch : 107, Training: Loss - 0.5881, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6254, Accuracy - 70.9091%, Recall - 0.4000, Time: 82.4299s\n",
      "Epoch: 109/200\n",
      "Batch number: 000, Training: Loss: 0.4678, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.5258, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5772, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5668, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7060, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6389, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5936, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5699, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.4910, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6713, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5133, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5397, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6582, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.7536, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5653, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6182, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.7193, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.4878, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5547, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5165, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4553, Accuracy: 0.9375\n",
      "Batch number: 021, Training: Loss: 0.6403, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5447, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6095, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6196, Accuracy: 0.6667\n",
      "Epoch : 108, Training: Loss - 0.5841, Accuracy - 70.4261%, \n",
      "\t\tValidation : Loss - 0.6294, Accuracy - 67.2727%, Recall - 0.4000, Time: 82.2684s\n",
      "Epoch: 110/200\n",
      "Batch number: 000, Training: Loss: 0.6605, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6344, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6038, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7091, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6312, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.4923, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.7024, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5723, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5849, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5689, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5842, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5809, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6553, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6715, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5679, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6145, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5181, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5587, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5520, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5667, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5295, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6398, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6092, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5040, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5627, Accuracy: 0.6667\n",
      "Epoch : 109, Training: Loss - 0.5951, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6287, Accuracy - 72.7273%, Recall - 0.4000, Time: 82.2091s\n",
      "Epoch: 111/200\n",
      "Batch number: 000, Training: Loss: 0.5577, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.4946, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5495, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5620, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5451, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6938, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.5334, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.7087, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5559, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5914, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7410, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6315, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5931, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5457, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5488, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5362, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5814, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5007, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5752, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5163, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6066, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6454, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6444, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6605, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6243, Accuracy: 0.6667\n",
      "Epoch : 110, Training: Loss - 0.5896, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6385, Accuracy - 67.2727%, Recall - 0.5500, Time: 82.2180s\n",
      "Epoch: 112/200\n",
      "Batch number: 000, Training: Loss: 0.7199, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.5350, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6126, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.4912, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.5328, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5436, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5988, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6155, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5711, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.4914, Accuracy: 0.9375\n",
      "Batch number: 010, Training: Loss: 0.6514, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6012, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6676, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6159, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6541, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6850, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5374, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7150, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5895, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5656, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5625, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5978, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6138, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5255, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.4874, Accuracy: 0.8667\n",
      "Epoch : 111, Training: Loss - 0.5915, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6272, Accuracy - 72.7273%, Recall - 0.4000, Time: 82.1724s\n",
      "Epoch: 113/200\n",
      "Batch number: 000, Training: Loss: 0.6093, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5569, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5516, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5605, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5423, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6616, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5988, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6143, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5622, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6558, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6007, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6299, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5201, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.4687, Accuracy: 1.0000\n",
      "Batch number: 014, Training: Loss: 0.7105, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6111, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5716, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6120, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7460, Accuracy: 0.3750\n",
      "Batch number: 019, Training: Loss: 0.6935, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.7143, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5660, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5811, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5820, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6091, Accuracy: 0.6667\n",
      "Epoch : 112, Training: Loss - 0.6052, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6421, Accuracy - 65.4545%, Recall - 0.5500, Time: 82.2817s\n",
      "Epoch: 114/200\n",
      "Batch number: 000, Training: Loss: 0.6119, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6758, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6126, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5963, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5989, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5239, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.4914, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5170, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5556, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5481, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6109, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6039, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7475, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.5592, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6383, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5362, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6205, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6555, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6870, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6591, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6445, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5899, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5483, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.4771, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5465, Accuracy: 0.8000\n",
      "Epoch : 113, Training: Loss - 0.5944, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6360, Accuracy - 65.4545%, Recall - 0.4500, Time: 82.2200s\n",
      "Epoch: 115/200\n",
      "Batch number: 000, Training: Loss: 0.5959, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.4874, Accuracy: 0.9375\n",
      "Batch number: 002, Training: Loss: 0.5836, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6120, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5545, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.4990, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.5034, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.4672, Accuracy: 1.0000\n",
      "Batch number: 008, Training: Loss: 0.5943, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5603, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6420, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6196, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5636, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5445, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6361, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5820, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6702, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6472, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7348, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6160, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7916, Accuracy: 0.3750\n",
      "Batch number: 021, Training: Loss: 0.6476, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.7428, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6117, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5772, Accuracy: 0.8000\n",
      "Epoch : 114, Training: Loss - 0.6035, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6194, Accuracy - 69.0909%, Recall - 0.2500, Time: 82.1943s\n",
      "Epoch: 116/200\n",
      "Batch number: 000, Training: Loss: 0.5697, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6109, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.7783, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6559, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6190, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6959, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6341, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5245, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6226, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5472, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5276, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5242, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.4834, Accuracy: 0.9375\n",
      "Batch number: 013, Training: Loss: 0.6221, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5699, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5361, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.7042, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.6497, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6872, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5876, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5410, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.4829, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.6436, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5127, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5817, Accuracy: 0.6667\n",
      "Epoch : 115, Training: Loss - 0.5965, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6362, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.2106s\n",
      "Epoch: 117/200\n",
      "Batch number: 000, Training: Loss: 0.6468, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5068, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5286, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5666, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5360, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5738, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6201, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6157, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6656, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.8007, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.6069, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5827, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6517, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.7040, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5827, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6668, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6649, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5332, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6127, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6724, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6976, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6213, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5982, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5467, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5405, Accuracy: 0.7333\n",
      "Epoch : 116, Training: Loss - 0.6139, Accuracy - 67.1679%, \n",
      "\t\tValidation : Loss - 0.6302, Accuracy - 70.9091%, Recall - 0.4000, Time: 82.2853s\n",
      "Epoch: 118/200\n",
      "Batch number: 000, Training: Loss: 0.6020, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5210, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6128, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7077, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6671, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5185, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6204, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5246, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5904, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6711, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5815, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5559, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5661, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5952, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5476, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5084, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6291, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6962, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.4295, Accuracy: 1.0000\n",
      "Batch number: 019, Training: Loss: 0.5468, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6581, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6602, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6279, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6628, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6257, Accuracy: 0.6667\n",
      "Epoch : 117, Training: Loss - 0.5970, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6276, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.1689s\n",
      "Epoch: 119/200\n",
      "Batch number: 000, Training: Loss: 0.5985, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5711, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6537, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.4989, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6331, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6881, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.5261, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5732, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6617, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6718, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6248, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5254, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5631, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5478, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5454, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.7480, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6943, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.4848, Accuracy: 0.9375\n",
      "Batch number: 018, Training: Loss: 0.5704, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6316, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6011, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5393, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5352, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.7148, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6906, Accuracy: 0.5333\n",
      "Epoch : 118, Training: Loss - 0.6035, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6370, Accuracy - 63.6364%, Recall - 0.4500, Time: 82.2514s\n",
      "Epoch: 120/200\n",
      "Batch number: 000, Training: Loss: 0.6064, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6981, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.4951, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.7539, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.5208, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6109, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5019, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6221, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5253, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.4806, Accuracy: 0.9375\n",
      "Batch number: 010, Training: Loss: 0.5006, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5250, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5754, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6344, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5438, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5269, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5596, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6355, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5563, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.5458, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5453, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6511, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6174, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6539, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.7666, Accuracy: 0.4667\n",
      "Epoch : 119, Training: Loss - 0.5857, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6370, Accuracy - 67.2727%, Recall - 0.4500, Time: 82.2134s\n",
      "Epoch: 121/200\n",
      "Batch number: 000, Training: Loss: 0.5922, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5442, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.7131, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5402, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6075, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6847, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5535, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5752, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.4927, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.4882, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.6103, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5087, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.7836, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.5159, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5294, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5758, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6785, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5211, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6875, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5171, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4679, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.5043, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.7819, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.8156, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.6217, Accuracy: 0.6000\n",
      "Epoch : 120, Training: Loss - 0.5964, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6293, Accuracy - 70.9091%, Recall - 0.4500, Time: 82.3978s\n",
      "Epoch: 122/200\n",
      "Batch number: 000, Training: Loss: 0.6160, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.7332, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.5893, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5042, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.7132, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5197, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6674, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.4645, Accuracy: 0.9375\n",
      "Batch number: 008, Training: Loss: 0.5887, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4769, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.5956, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6319, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6042, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5783, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5097, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5870, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5851, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6907, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5139, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6254, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5280, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5953, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5674, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.4673, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5418, Accuracy: 0.8000\n",
      "Epoch : 121, Training: Loss - 0.5799, Accuracy - 72.6817%, \n",
      "\t\tValidation : Loss - 0.6341, Accuracy - 70.9091%, Recall - 0.4500, Time: 82.2244s\n",
      "Epoch: 123/200\n",
      "Batch number: 000, Training: Loss: 0.4996, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.7295, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6349, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5728, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6053, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5864, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5252, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5533, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6323, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6630, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6282, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6734, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.5583, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6225, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.4873, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.5934, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.4886, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.5401, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5702, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6371, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5591, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.8038, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.6785, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6569, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5238, Accuracy: 0.8000\n",
      "Epoch : 122, Training: Loss - 0.6011, Accuracy - 69.9248%, \n",
      "\t\tValidation : Loss - 0.6327, Accuracy - 70.9091%, Recall - 0.4500, Time: 82.1409s\n",
      "Epoch: 124/200\n",
      "Batch number: 000, Training: Loss: 0.6858, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.4801, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5426, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6352, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.7519, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6068, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5794, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.4729, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.4951, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6208, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6324, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.4419, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5148, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.5581, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5944, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6749, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5846, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6851, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5599, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6185, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4625, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6742, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5198, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6568, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5967, Accuracy: 0.6667\n",
      "Epoch : 123, Training: Loss - 0.5858, Accuracy - 72.1805%, \n",
      "\t\tValidation : Loss - 0.6425, Accuracy - 65.4545%, Recall - 0.4500, Time: 82.2487s\n",
      "Epoch: 125/200\n",
      "Batch number: 000, Training: Loss: 0.7068, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5460, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5907, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6319, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6117, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6654, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.7299, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.4460, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.5180, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5243, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5272, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5667, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5041, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6086, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5837, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.7294, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.7089, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.5197, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5984, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5490, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5829, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5943, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5465, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5278, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6152, Accuracy: 0.6000\n",
      "Epoch : 124, Training: Loss - 0.5893, Accuracy - 70.9273%, \n",
      "\t\tValidation : Loss - 0.6393, Accuracy - 65.4545%, Recall - 0.5000, Time: 83.0881s\n",
      "Epoch: 126/200\n",
      "Batch number: 000, Training: Loss: 0.6407, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5641, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.4684, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.5007, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5394, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5847, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5197, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6557, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5692, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5994, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5379, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5071, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6824, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6014, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5748, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6043, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6741, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6315, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5951, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5093, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6539, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6581, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6226, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6424, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6605, Accuracy: 0.5333\n",
      "Epoch : 125, Training: Loss - 0.5917, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6356, Accuracy - 67.2727%, Recall - 0.4500, Time: 82.3849s\n",
      "Epoch: 127/200\n",
      "Batch number: 000, Training: Loss: 0.5906, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5955, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6031, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6094, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6209, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5954, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5518, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6403, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6399, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4955, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6583, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5094, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.4680, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.5509, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6469, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6044, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6215, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5084, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.7337, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6223, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6233, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.4705, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.7321, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.5359, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.4798, Accuracy: 0.8000\n",
      "Epoch : 126, Training: Loss - 0.5886, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6277, Accuracy - 72.7273%, Recall - 0.4500, Time: 82.5602s\n",
      "Epoch: 128/200\n",
      "Batch number: 000, Training: Loss: 0.4916, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.6593, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6452, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5328, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6266, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.4651, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6528, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5751, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5563, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5429, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5670, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6883, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.7715, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5987, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5768, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5517, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.4756, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.5541, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6969, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.5513, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5392, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.7304, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.7360, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6077, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5561, Accuracy: 0.7333\n",
      "Epoch : 127, Training: Loss - 0.5981, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6293, Accuracy - 70.9091%, Recall - 0.3500, Time: 82.7183s\n",
      "Epoch: 129/200\n",
      "Batch number: 000, Training: Loss: 0.4957, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.7221, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.4744, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5765, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6286, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5570, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7404, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.6853, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5633, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5437, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5849, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6311, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6325, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5148, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5955, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.4939, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5856, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5448, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.4653, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.7490, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5937, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5353, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.7434, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.5954, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6174, Accuracy: 0.5333\n",
      "Epoch : 128, Training: Loss - 0.5947, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6348, Accuracy - 69.0909%, Recall - 0.4500, Time: 82.3617s\n",
      "Epoch: 130/200\n",
      "Batch number: 000, Training: Loss: 0.5747, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.4992, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6555, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6142, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6083, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6206, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5663, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6495, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6167, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6247, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6308, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6184, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5594, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.7062, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5999, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6470, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5168, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5614, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5439, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5815, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7044, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6077, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5714, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5866, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.4338, Accuracy: 1.0000\n",
      "Epoch : 129, Training: Loss - 0.5964, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6358, Accuracy - 65.4545%, Recall - 0.4500, Time: 82.2460s\n",
      "Epoch: 131/200\n",
      "Batch number: 000, Training: Loss: 0.5712, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.4509, Accuracy: 0.9375\n",
      "Batch number: 002, Training: Loss: 0.6092, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5390, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6174, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6041, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5748, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6811, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6268, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4792, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5770, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7220, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.5295, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6857, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5645, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6188, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5737, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5244, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6030, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5454, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5652, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5147, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5913, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5919, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6255, Accuracy: 0.6667\n",
      "Epoch : 130, Training: Loss - 0.5833, Accuracy - 71.6792%, \n",
      "\t\tValidation : Loss - 0.6294, Accuracy - 70.9091%, Recall - 0.3000, Time: 82.3131s\n",
      "Epoch: 132/200\n",
      "Batch number: 000, Training: Loss: 0.6494, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5212, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5668, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.5482, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6514, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6647, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5596, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6094, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.8171, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5157, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5461, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.4906, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6583, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.4527, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.7106, Accuracy: 0.4375\n",
      "Batch number: 015, Training: Loss: 0.5141, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6008, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6100, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5679, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5575, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5305, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5487, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6212, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7912, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.5873, Accuracy: 0.6667\n",
      "Epoch : 131, Training: Loss - 0.5957, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6460, Accuracy - 61.8182%, Recall - 0.5000, Time: 82.2457s\n",
      "Epoch: 133/200\n",
      "Batch number: 000, Training: Loss: 0.6933, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6562, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.4791, Accuracy: 0.9375\n",
      "Batch number: 003, Training: Loss: 0.5777, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.4958, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6053, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5203, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6553, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5402, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6631, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6246, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7035, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.5534, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5052, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6236, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6202, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5938, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6375, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6942, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6063, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6187, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.4447, Accuracy: 1.0000\n",
      "Batch number: 022, Training: Loss: 0.6223, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6615, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6169, Accuracy: 0.6667\n",
      "Epoch : 132, Training: Loss - 0.6005, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6376, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.3095s\n",
      "Epoch: 134/200\n",
      "Batch number: 000, Training: Loss: 0.5942, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6136, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5510, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6514, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5079, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5121, Accuracy: 0.9375\n",
      "Batch number: 006, Training: Loss: 0.5786, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5637, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6094, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6867, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5726, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6278, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5556, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6951, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5607, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5921, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5606, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.4999, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6942, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6000, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5719, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.8115, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.6065, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6645, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6313, Accuracy: 0.7333\n",
      "Epoch : 133, Training: Loss - 0.6044, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6219, Accuracy - 69.0909%, Recall - 0.2500, Time: 82.1936s\n",
      "Epoch: 135/200\n",
      "Batch number: 000, Training: Loss: 0.5897, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5860, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5441, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5602, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6970, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6158, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6003, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6482, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5101, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6534, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6540, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5476, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.4911, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5286, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.4638, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.6403, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5673, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6257, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7298, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.5030, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6329, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5356, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6734, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6242, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6234, Accuracy: 0.7333\n",
      "Epoch : 134, Training: Loss - 0.5937, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6379, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.2215s\n",
      "Epoch: 136/200\n",
      "Batch number: 000, Training: Loss: 0.6975, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5092, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.6466, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5997, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5170, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5631, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5415, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5998, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6739, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.7339, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5011, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5806, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5932, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5527, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5941, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6120, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5762, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5102, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5950, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6632, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6059, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5532, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6258, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5955, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6374, Accuracy: 0.5333\n",
      "Epoch : 135, Training: Loss - 0.5950, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6288, Accuracy - 70.9091%, Recall - 0.3000, Time: 82.3172s\n",
      "Epoch: 137/200\n",
      "Batch number: 000, Training: Loss: 0.5434, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5916, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6183, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5227, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5669, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5802, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5534, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5372, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6245, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6049, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5542, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5601, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6280, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5587, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5818, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7324, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.5278, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.7394, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6070, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6825, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5981, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6010, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6770, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6145, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.4942, Accuracy: 0.8667\n",
      "Epoch : 136, Training: Loss - 0.5962, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6450, Accuracy - 61.8182%, Recall - 0.5000, Time: 82.5081s\n",
      "Epoch: 138/200\n",
      "Batch number: 000, Training: Loss: 0.6929, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.5060, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5498, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5601, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5489, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5573, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6277, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6225, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6310, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6622, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5930, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5783, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5428, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6300, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6116, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6256, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6272, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6633, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5404, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5464, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6862, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.4677, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.7596, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.6851, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6106, Accuracy: 0.7333\n",
      "Epoch : 137, Training: Loss - 0.6050, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6227, Accuracy - 69.0909%, Recall - 0.2500, Time: 82.2415s\n",
      "Epoch: 139/200\n",
      "Batch number: 000, Training: Loss: 0.5922, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5276, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.4983, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5581, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.4737, Accuracy: 0.9375\n",
      "Batch number: 005, Training: Loss: 0.6201, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7592, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5074, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6301, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5612, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6164, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.5726, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6084, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5802, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6399, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7233, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5384, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6298, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5538, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6657, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6134, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.4543, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.4799, Accuracy: 0.9375\n",
      "Batch number: 023, Training: Loss: 0.6885, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6723, Accuracy: 0.6000\n",
      "Epoch : 138, Training: Loss - 0.5904, Accuracy - 69.4236%, \n",
      "\t\tValidation : Loss - 0.6264, Accuracy - 72.7273%, Recall - 0.3500, Time: 82.2050s\n",
      "Epoch: 140/200\n",
      "Batch number: 000, Training: Loss: 0.5363, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5288, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6446, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5371, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.4869, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.4965, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6518, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6150, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6432, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5679, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6201, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5174, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5850, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6417, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6529, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6420, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6164, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6140, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6100, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5942, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6054, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6170, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6374, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5239, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5465, Accuracy: 0.8000\n",
      "Epoch : 139, Training: Loss - 0.5894, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6334, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.0569s\n",
      "Epoch: 141/200\n",
      "Batch number: 000, Training: Loss: 0.5675, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6571, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6470, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5831, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5989, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6031, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5391, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6741, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6404, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6148, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5184, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.5383, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6583, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6025, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6088, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5571, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5151, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.5448, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5118, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6755, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5080, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6685, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.5161, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5227, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5050, Accuracy: 0.8000\n",
      "Epoch : 140, Training: Loss - 0.5832, Accuracy - 71.6792%, \n",
      "\t\tValidation : Loss - 0.6290, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.2330s\n",
      "Epoch: 142/200\n",
      "Batch number: 000, Training: Loss: 0.5649, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5533, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5399, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.4261, Accuracy: 1.0000\n",
      "Batch number: 004, Training: Loss: 0.5415, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5878, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6470, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6439, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6143, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5546, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5648, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5875, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6595, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.4823, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5978, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7172, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5528, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.4704, Accuracy: 0.9375\n",
      "Batch number: 018, Training: Loss: 0.6015, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5712, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.4759, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6676, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5188, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5772, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6167, Accuracy: 0.7333\n",
      "Epoch : 141, Training: Loss - 0.5733, Accuracy - 75.1880%, \n",
      "\t\tValidation : Loss - 0.6387, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.1954s\n",
      "Epoch: 143/200\n",
      "Batch number: 000, Training: Loss: 0.5003, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6808, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6279, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5196, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5480, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.4788, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.7356, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5497, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6407, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.4870, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.4882, Accuracy: 0.9375\n",
      "Batch number: 011, Training: Loss: 0.5396, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6733, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.7266, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.5666, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5904, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5436, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.4938, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6044, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6101, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6117, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6338, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.5990, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5795, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.7022, Accuracy: 0.6000\n",
      "Epoch : 142, Training: Loss - 0.5890, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6309, Accuracy - 70.9091%, Recall - 0.4500, Time: 82.2245s\n",
      "Epoch: 144/200\n",
      "Batch number: 000, Training: Loss: 0.5526, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5562, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.7054, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6572, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.5172, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5550, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6357, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.7312, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.5367, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5506, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.4638, Accuracy: 0.9375\n",
      "Batch number: 011, Training: Loss: 0.5191, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6229, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5593, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6115, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6136, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6256, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6151, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5604, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5888, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5432, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6218, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5852, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6384, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5928, Accuracy: 0.7333\n",
      "Epoch : 143, Training: Loss - 0.5904, Accuracy - 71.9298%, \n",
      "\t\tValidation : Loss - 0.6318, Accuracy - 70.9091%, Recall - 0.4500, Time: 82.2359s\n",
      "Epoch: 145/200\n",
      "Batch number: 000, Training: Loss: 0.5764, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5625, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5453, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5016, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5728, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6391, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6857, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7435, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.5468, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5386, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5833, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5673, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6251, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6673, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5376, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5261, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6192, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6580, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5855, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7253, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.5895, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5750, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5391, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5447, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5062, Accuracy: 0.8667\n",
      "Epoch : 144, Training: Loss - 0.5907, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6272, Accuracy - 70.9091%, Recall - 0.3500, Time: 82.4601s\n",
      "Epoch: 146/200\n",
      "Batch number: 000, Training: Loss: 0.6277, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5574, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.4183, Accuracy: 1.0000\n",
      "Batch number: 003, Training: Loss: 0.5060, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.5346, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6258, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5998, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6093, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6218, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6824, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5555, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5943, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.4791, Accuracy: 0.9375\n",
      "Batch number: 013, Training: Loss: 0.4890, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5919, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5645, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5897, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.4908, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5701, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6035, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5610, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5176, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6511, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7767, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.6408, Accuracy: 0.7333\n",
      "Epoch : 145, Training: Loss - 0.5782, Accuracy - 72.6817%, \n",
      "\t\tValidation : Loss - 0.6322, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.2205s\n",
      "Epoch: 147/200\n",
      "Batch number: 000, Training: Loss: 0.5487, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6750, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6223, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6042, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5916, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6337, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6244, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.4778, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.5925, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4788, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.5814, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5090, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5059, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.5433, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7211, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5485, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5614, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5910, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5782, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6558, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5182, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5237, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5256, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6044, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6341, Accuracy: 0.6000\n",
      "Epoch : 146, Training: Loss - 0.5779, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6443, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.1207s\n",
      "Epoch: 148/200\n",
      "Batch number: 000, Training: Loss: 0.5911, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5734, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5605, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6299, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6371, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6782, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.5199, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.4905, Accuracy: 0.9375\n",
      "Batch number: 008, Training: Loss: 0.6526, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.4571, Accuracy: 0.9375\n",
      "Batch number: 010, Training: Loss: 0.6075, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.4976, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6065, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5830, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6059, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5584, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6447, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5802, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6301, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5475, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.7213, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.7052, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5340, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6349, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.4684, Accuracy: 0.9333\n",
      "Epoch : 147, Training: Loss - 0.5889, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6328, Accuracy - 69.0909%, Recall - 0.4500, Time: 82.0616s\n",
      "Epoch: 149/200\n",
      "Batch number: 000, Training: Loss: 0.5481, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5901, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6035, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6588, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5769, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5395, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6438, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5425, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.7539, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.7094, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.7559, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.6193, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5647, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5792, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6193, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5884, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6325, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5081, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6786, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5814, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5713, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5432, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6041, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5999, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.4706, Accuracy: 0.9333\n",
      "Epoch : 148, Training: Loss - 0.6037, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6233, Accuracy - 74.5455%, Recall - 0.4500, Time: 83.5636s\n",
      "Epoch: 150/200\n",
      "Batch number: 000, Training: Loss: 0.5693, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6115, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5769, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5372, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5282, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6003, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6803, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.4328, Accuracy: 0.9375\n",
      "Batch number: 008, Training: Loss: 0.4568, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.5983, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5662, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6366, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6553, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6011, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5879, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.7925, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.6833, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.7558, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.4173, Accuracy: 1.0000\n",
      "Batch number: 019, Training: Loss: 0.6697, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5525, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6913, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6724, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5415, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.4912, Accuracy: 0.8667\n",
      "Epoch : 149, Training: Loss - 0.5965, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6230, Accuracy - 74.5455%, Recall - 0.4000, Time: 82.9976s\n",
      "Epoch: 151/200\n",
      "Batch number: 000, Training: Loss: 0.5244, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5689, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6731, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5455, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6403, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6186, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5053, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6500, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5331, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6495, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5675, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5796, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5206, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5301, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6109, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6564, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6040, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5542, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5804, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5869, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5969, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6535, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5501, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5669, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.7413, Accuracy: 0.5333\n",
      "Epoch : 150, Training: Loss - 0.5919, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6264, Accuracy - 70.9091%, Recall - 0.3000, Time: 82.7922s\n",
      "Epoch: 152/200\n",
      "Batch number: 000, Training: Loss: 0.6114, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5003, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5246, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6817, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6128, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6403, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.4321, Accuracy: 0.9375\n",
      "Batch number: 007, Training: Loss: 0.7524, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.5612, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6382, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5099, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5716, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5558, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5812, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5712, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.7247, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5918, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5811, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.4827, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.5487, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6202, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5631, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5408, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.7064, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.5171, Accuracy: 0.8000\n",
      "Epoch : 151, Training: Loss - 0.5850, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6281, Accuracy - 74.5455%, Recall - 0.4500, Time: 82.8001s\n",
      "Epoch: 153/200\n",
      "Batch number: 000, Training: Loss: 0.7199, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5519, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5233, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5100, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5682, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5972, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5291, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.6081, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5870, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5633, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6342, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6138, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.4871, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.5647, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5503, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6632, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6011, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5979, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6049, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5864, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.7094, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.6242, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5306, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6920, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6473, Accuracy: 0.6667\n",
      "Epoch : 152, Training: Loss - 0.5945, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6244, Accuracy - 69.0909%, Recall - 0.2500, Time: 82.8029s\n",
      "Epoch: 154/200\n",
      "Batch number: 000, Training: Loss: 0.5405, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5204, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.4848, Accuracy: 0.9375\n",
      "Batch number: 003, Training: Loss: 0.5810, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6197, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5792, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7062, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.6714, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6022, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5534, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5876, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5867, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5800, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5896, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6063, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5641, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6214, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5569, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5200, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5697, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6047, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5415, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5227, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5496, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5962, Accuracy: 0.6667\n",
      "Epoch : 153, Training: Loss - 0.5782, Accuracy - 71.6792%, \n",
      "\t\tValidation : Loss - 0.6315, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.7731s\n",
      "Epoch: 155/200\n",
      "Batch number: 000, Training: Loss: 0.6665, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5683, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5703, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5944, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6643, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5907, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6172, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6915, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5160, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5389, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5557, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5930, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5735, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6195, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.4999, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6947, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.7301, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.6041, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6301, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7242, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.4736, Accuracy: 0.9375\n",
      "Batch number: 021, Training: Loss: 0.5228, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.5814, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5596, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6350, Accuracy: 0.6667\n",
      "Epoch : 154, Training: Loss - 0.6005, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6276, Accuracy - 70.9091%, Recall - 0.4000, Time: 82.8129s\n",
      "Epoch: 156/200\n",
      "Batch number: 000, Training: Loss: 0.6388, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5758, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.4932, Accuracy: 0.9375\n",
      "Batch number: 003, Training: Loss: 0.6369, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5733, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6150, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5049, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5067, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6196, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5369, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6997, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.5195, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5590, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6275, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5731, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6149, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5263, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6557, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6648, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7322, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6818, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5402, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5456, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6983, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6454, Accuracy: 0.6667\n",
      "Epoch : 155, Training: Loss - 0.5993, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6341, Accuracy - 72.7273%, Recall - 0.5000, Time: 82.7285s\n",
      "Epoch: 157/200\n",
      "Batch number: 000, Training: Loss: 0.5659, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6925, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5605, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5286, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5453, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6852, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6391, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5411, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5313, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5206, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.5348, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.5814, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5310, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5103, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6790, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6025, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6296, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6544, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6150, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5215, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6955, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6132, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.4338, Accuracy: 0.9375\n",
      "Batch number: 023, Training: Loss: 0.6527, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6101, Accuracy: 0.6667\n",
      "Epoch : 156, Training: Loss - 0.5869, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6242, Accuracy - 74.5455%, Recall - 0.4500, Time: 82.8903s\n",
      "Epoch: 158/200\n",
      "Batch number: 000, Training: Loss: 0.5179, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6732, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5154, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.4657, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6802, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5688, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6843, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5656, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5796, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6460, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5765, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6239, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5878, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5797, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5445, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.4776, Accuracy: 0.9375\n",
      "Batch number: 016, Training: Loss: 0.6943, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6383, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5637, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.4304, Accuracy: 0.9375\n",
      "Batch number: 020, Training: Loss: 0.5991, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6300, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5153, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5466, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6730, Accuracy: 0.5333\n",
      "Epoch : 157, Training: Loss - 0.5829, Accuracy - 70.4261%, \n",
      "\t\tValidation : Loss - 0.6308, Accuracy - 70.9091%, Recall - 0.5000, Time: 82.7665s\n",
      "Epoch: 159/200\n",
      "Batch number: 000, Training: Loss: 0.5513, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5503, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5291, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5273, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6713, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5662, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6159, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6933, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5345, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6875, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5686, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.4798, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5171, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6963, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5534, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.7598, Accuracy: 0.3125\n",
      "Batch number: 016, Training: Loss: 0.5546, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5791, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5397, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6095, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6937, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.5997, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5662, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5648, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6172, Accuracy: 0.6667\n",
      "Epoch : 158, Training: Loss - 0.5930, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6447, Accuracy - 60.0000%, Recall - 0.5000, Time: 82.6882s\n",
      "Epoch: 160/200\n",
      "Batch number: 000, Training: Loss: 0.6124, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6916, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6003, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5601, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5911, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.4418, Accuracy: 1.0000\n",
      "Batch number: 006, Training: Loss: 0.6148, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6398, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5762, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6204, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5392, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5681, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5546, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6291, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5167, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5318, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.6644, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5614, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6617, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6526, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5635, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.7163, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.7051, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6248, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5405, Accuracy: 0.8667\n",
      "Epoch : 159, Training: Loss - 0.5993, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6250, Accuracy - 72.7273%, Recall - 0.4000, Time: 82.7003s\n",
      "Epoch: 161/200\n",
      "Batch number: 000, Training: Loss: 0.5584, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6001, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5099, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5925, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5602, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6520, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6694, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6282, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.4970, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.5535, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5780, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5890, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5581, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5244, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6342, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5910, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5762, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.4841, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6939, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6788, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5786, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5670, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5414, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5119, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5951, Accuracy: 0.6667\n",
      "Epoch : 160, Training: Loss - 0.5809, Accuracy - 70.4261%, \n",
      "\t\tValidation : Loss - 0.6324, Accuracy - 69.0909%, Recall - 0.5000, Time: 82.9134s\n",
      "Epoch: 162/200\n",
      "Batch number: 000, Training: Loss: 0.6888, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.6509, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5684, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5558, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5629, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6647, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5109, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5868, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6167, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4636, Accuracy: 1.0000\n",
      "Batch number: 010, Training: Loss: 0.5035, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.5037, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.4989, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5354, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5564, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6673, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5847, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.7141, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5010, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5843, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5875, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5712, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5191, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.7446, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6220, Accuracy: 0.8000\n",
      "Epoch : 161, Training: Loss - 0.5824, Accuracy - 72.4311%, \n",
      "\t\tValidation : Loss - 0.6289, Accuracy - 74.5455%, Recall - 0.5000, Time: 82.7134s\n",
      "Epoch: 163/200\n",
      "Batch number: 000, Training: Loss: 0.5598, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5224, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7012, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5574, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6129, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5243, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5686, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5896, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5125, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6429, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5861, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5547, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.4265, Accuracy: 0.9375\n",
      "Batch number: 013, Training: Loss: 0.6017, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6402, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5240, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6027, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6202, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5621, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5948, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5505, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5437, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7044, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6786, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.5040, Accuracy: 0.7333\n",
      "Epoch : 162, Training: Loss - 0.5796, Accuracy - 70.9273%, \n",
      "\t\tValidation : Loss - 0.6401, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.8233s\n",
      "Epoch: 164/200\n",
      "Batch number: 000, Training: Loss: 0.6691, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5814, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.7562, Accuracy: 0.3750\n",
      "Batch number: 003, Training: Loss: 0.5890, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5597, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5532, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5114, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6572, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5739, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5757, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6648, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6046, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5186, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.5043, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.4690, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.5044, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.6151, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.4771, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5446, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6115, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6132, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5639, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.4384, Accuracy: 0.9375\n",
      "Batch number: 023, Training: Loss: 0.5537, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.7387, Accuracy: 0.5333\n",
      "Epoch : 163, Training: Loss - 0.5775, Accuracy - 73.1830%, \n",
      "\t\tValidation : Loss - 0.6286, Accuracy - 69.0909%, Recall - 0.3500, Time: 82.6846s\n",
      "Epoch: 165/200\n",
      "Batch number: 000, Training: Loss: 0.5325, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6223, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6779, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5330, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6125, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5512, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6908, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.6069, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5783, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6733, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.5608, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5339, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6013, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6112, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5711, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6301, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6452, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5694, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5411, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5715, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5578, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5338, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5903, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6409, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.4969, Accuracy: 0.8000\n",
      "Epoch : 164, Training: Loss - 0.5896, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6345, Accuracy - 70.9091%, Recall - 0.5000, Time: 82.8171s\n",
      "Epoch: 166/200\n",
      "Batch number: 000, Training: Loss: 0.4808, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5849, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5441, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.4771, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6341, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.7713, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6484, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5283, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5037, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5547, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6315, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5343, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6344, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5481, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.7100, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6106, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.7793, Accuracy: 0.3750\n",
      "Batch number: 017, Training: Loss: 0.6187, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6811, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6852, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5405, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5897, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.4983, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5223, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5585, Accuracy: 0.8000\n",
      "Epoch : 165, Training: Loss - 0.5949, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6348, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.8182s\n",
      "Epoch: 167/200\n",
      "Batch number: 000, Training: Loss: 0.5815, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5126, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5483, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5391, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5517, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5803, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6089, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6445, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.7262, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.7065, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.5861, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6110, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5493, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6240, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5253, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.4864, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5748, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6767, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.4986, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.4609, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.6576, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5926, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7088, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6008, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5167, Accuracy: 0.7333\n",
      "Epoch : 166, Training: Loss - 0.5869, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6371, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.6206s\n",
      "Epoch: 168/200\n",
      "Batch number: 000, Training: Loss: 0.5704, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5365, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6539, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5917, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5368, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6327, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6680, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.5302, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.5478, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6467, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5899, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6842, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6263, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5067, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6327, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6306, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6667, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5103, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5767, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6124, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4402, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6426, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5422, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6266, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.7083, Accuracy: 0.6000\n",
      "Epoch : 167, Training: Loss - 0.5962, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6256, Accuracy - 70.9091%, Recall - 0.3500, Time: 82.9790s\n",
      "Epoch: 169/200\n",
      "Batch number: 000, Training: Loss: 0.5209, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5977, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5867, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5095, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5708, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5329, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.4859, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5327, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5697, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.7703, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.7023, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6549, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.7063, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5478, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6157, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.4350, Accuracy: 1.0000\n",
      "Batch number: 016, Training: Loss: 0.6212, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5278, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6151, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5064, Accuracy: 0.9375\n",
      "Batch number: 020, Training: Loss: 0.5380, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5809, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5691, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5045, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.6450, Accuracy: 0.6667\n",
      "Epoch : 168, Training: Loss - 0.5777, Accuracy - 72.4311%, \n",
      "\t\tValidation : Loss - 0.6476, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.9537s\n",
      "Epoch: 170/200\n",
      "Batch number: 000, Training: Loss: 0.5588, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6380, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6126, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6286, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6242, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5082, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6561, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6129, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5203, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6257, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6204, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5737, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.4696, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.5571, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5898, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5974, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5307, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6003, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5609, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7838, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.5025, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5689, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6493, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5410, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5889, Accuracy: 0.7333\n",
      "Epoch : 169, Training: Loss - 0.5888, Accuracy - 71.4286%, \n",
      "\t\tValidation : Loss - 0.6361, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.9631s\n",
      "Epoch: 171/200\n",
      "Batch number: 000, Training: Loss: 0.5569, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6008, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6041, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6222, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6504, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5001, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6124, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5871, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5843, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6795, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5572, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6311, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5494, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.4434, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6153, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5333, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5587, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6380, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5802, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5178, Accuracy: 0.9375\n",
      "Batch number: 020, Training: Loss: 0.5544, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.7158, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.4964, Accuracy: 0.9375\n",
      "Batch number: 023, Training: Loss: 0.5510, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5888, Accuracy: 0.6667\n",
      "Epoch : 170, Training: Loss - 0.5811, Accuracy - 72.1805%, \n",
      "\t\tValidation : Loss - 0.6436, Accuracy - 63.6364%, Recall - 0.5000, Time: 83.2717s\n",
      "Epoch: 172/200\n",
      "Batch number: 000, Training: Loss: 0.4326, Accuracy: 0.9375\n",
      "Batch number: 001, Training: Loss: 0.6294, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.4908, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6027, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.4687, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5546, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5507, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6190, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.4769, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6520, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5855, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6200, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6166, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5708, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5531, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6749, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6285, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5185, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5495, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.4575, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.6819, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5009, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.6568, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6743, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5256, Accuracy: 0.8000\n",
      "Epoch : 171, Training: Loss - 0.5718, Accuracy - 73.4336%, \n",
      "\t\tValidation : Loss - 0.6306, Accuracy - 69.0909%, Recall - 0.4000, Time: 83.1145s\n",
      "Epoch: 173/200\n",
      "Batch number: 000, Training: Loss: 0.6560, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5564, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6698, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.4683, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.5196, Accuracy: 0.9375\n",
      "Batch number: 005, Training: Loss: 0.4956, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6453, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5469, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5141, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6208, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6238, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.7423, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.6996, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5616, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5669, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5167, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6076, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.7277, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.6451, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6246, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6289, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.4973, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.5524, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5704, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5556, Accuracy: 0.8667\n",
      "Epoch : 172, Training: Loss - 0.5926, Accuracy - 68.6717%, \n",
      "\t\tValidation : Loss - 0.6305, Accuracy - 74.5455%, Recall - 0.4500, Time: 85.5962s\n",
      "Epoch: 174/200\n",
      "Batch number: 000, Training: Loss: 0.6626, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5830, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.4671, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.5058, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.5977, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5376, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5851, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6473, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6021, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5458, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5897, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5359, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.7068, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5867, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5662, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5956, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.4864, Accuracy: 0.9375\n",
      "Batch number: 017, Training: Loss: 0.5545, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6916, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6558, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5896, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5104, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.6176, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6268, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5782, Accuracy: 0.7333\n",
      "Epoch : 173, Training: Loss - 0.5851, Accuracy - 72.1805%, \n",
      "\t\tValidation : Loss - 0.6263, Accuracy - 70.9091%, Recall - 0.3500, Time: 82.4261s\n",
      "Epoch: 175/200\n",
      "Batch number: 000, Training: Loss: 0.5338, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.4825, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5738, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6221, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.4947, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5062, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6239, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5423, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6908, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6082, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.4504, Accuracy: 0.9375\n",
      "Batch number: 011, Training: Loss: 0.4743, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5935, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5248, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6151, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6666, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6237, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6187, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5215, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6567, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5919, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5798, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5998, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5618, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5462, Accuracy: 0.7333\n",
      "Epoch : 174, Training: Loss - 0.5722, Accuracy - 72.1805%, \n",
      "\t\tValidation : Loss - 0.6423, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.6275s\n",
      "Epoch: 176/200\n",
      "Batch number: 000, Training: Loss: 0.5672, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5513, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5492, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.4876, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5237, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6580, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7490, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.6797, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.5027, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5666, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5133, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.4908, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.4792, Accuracy: 0.9375\n",
      "Batch number: 013, Training: Loss: 0.4863, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5546, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7105, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5311, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6830, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6283, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5622, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5386, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7156, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5032, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5878, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5992, Accuracy: 0.6667\n",
      "Epoch : 175, Training: Loss - 0.5767, Accuracy - 71.9298%, \n",
      "\t\tValidation : Loss - 0.6321, Accuracy - 70.9091%, Recall - 0.4000, Time: 82.4397s\n",
      "Epoch: 177/200\n",
      "Batch number: 000, Training: Loss: 0.5665, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5921, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.7038, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5533, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6369, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6260, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6149, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6235, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5505, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6076, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5489, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5463, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5975, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5111, Accuracy: 0.9375\n",
      "Batch number: 014, Training: Loss: 0.5899, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6166, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5918, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5465, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6556, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.5335, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4769, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.7735, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.5656, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5674, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5161, Accuracy: 0.8000\n",
      "Epoch : 176, Training: Loss - 0.5887, Accuracy - 69.9248%, \n",
      "\t\tValidation : Loss - 0.6313, Accuracy - 72.7273%, Recall - 0.4500, Time: 83.0835s\n",
      "Epoch: 178/200\n",
      "Batch number: 000, Training: Loss: 0.4756, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.6584, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6765, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5618, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.7491, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5204, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6131, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6155, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6814, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6350, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5733, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6183, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5554, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6298, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5388, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5763, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5600, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5765, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.4325, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6777, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5570, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5923, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.4875, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5722, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5934, Accuracy: 0.6667\n",
      "Epoch : 177, Training: Loss - 0.5891, Accuracy - 70.4261%, \n",
      "\t\tValidation : Loss - 0.6350, Accuracy - 72.7273%, Recall - 0.5000, Time: 82.5444s\n",
      "Epoch: 179/200\n",
      "Batch number: 000, Training: Loss: 0.5356, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.4974, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.4816, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5533, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7016, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.4931, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.5609, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.4312, Accuracy: 1.0000\n",
      "Batch number: 008, Training: Loss: 0.5948, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6968, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6025, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5795, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5447, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5117, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.7144, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.6147, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.7195, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.5480, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6126, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7936, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5365, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6168, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6346, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6666, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5732, Accuracy: 0.6667\n",
      "Epoch : 178, Training: Loss - 0.5927, Accuracy - 69.1729%, \n",
      "\t\tValidation : Loss - 0.6442, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.4018s\n",
      "Epoch: 180/200\n",
      "Batch number: 000, Training: Loss: 0.5797, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5232, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5432, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5906, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6201, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6205, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5523, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5758, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6391, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.4609, Accuracy: 0.9375\n",
      "Batch number: 010, Training: Loss: 0.5765, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5528, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6443, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6042, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6012, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7020, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5643, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6212, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5119, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6229, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6514, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6512, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6946, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6389, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5600, Accuracy: 0.8000\n",
      "Epoch : 179, Training: Loss - 0.5962, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6471, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.4697s\n",
      "Epoch: 181/200\n",
      "Batch number: 000, Training: Loss: 0.5860, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5586, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6437, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5920, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5113, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.4924, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5991, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.4704, Accuracy: 0.9375\n",
      "Batch number: 008, Training: Loss: 0.5730, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5960, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6116, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5986, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5746, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.7499, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.4642, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.5167, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5100, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6004, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5408, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6888, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5744, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7959, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.5299, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6240, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6977, Accuracy: 0.6000\n",
      "Epoch : 180, Training: Loss - 0.5877, Accuracy - 68.9223%, \n",
      "\t\tValidation : Loss - 0.6329, Accuracy - 70.9091%, Recall - 0.5000, Time: 82.5068s\n",
      "Epoch: 182/200\n",
      "Batch number: 000, Training: Loss: 0.5640, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5366, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5659, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5136, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5288, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5676, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6039, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5463, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.4871, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.7810, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.5999, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6473, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6215, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6227, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5425, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6291, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6010, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5215, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5666, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6422, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6142, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.7094, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.6540, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6213, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6025, Accuracy: 0.6000\n",
      "Epoch : 181, Training: Loss - 0.5956, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6423, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.3478s\n",
      "Epoch: 183/200\n",
      "Batch number: 000, Training: Loss: 0.4595, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6422, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5384, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5641, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6168, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6906, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5460, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6095, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5786, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6487, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6266, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6631, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.5779, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5173, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.7471, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.4852, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.5722, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5588, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6206, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6576, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5566, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5623, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5240, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.4379, Accuracy: 0.9375\n",
      "Batch number: 024, Training: Loss: 0.5672, Accuracy: 0.8000\n",
      "Epoch : 182, Training: Loss - 0.5828, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6334, Accuracy - 69.0909%, Recall - 0.4500, Time: 82.3919s\n",
      "Epoch: 184/200\n",
      "Batch number: 000, Training: Loss: 0.5838, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5424, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6010, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6571, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5622, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5780, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6437, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5462, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6463, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5684, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6959, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5629, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7028, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5156, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6204, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.4769, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5990, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5105, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5766, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5850, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5353, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6224, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.4915, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.6302, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6148, Accuracy: 0.8000\n",
      "Epoch : 183, Training: Loss - 0.5867, Accuracy - 72.1805%, \n",
      "\t\tValidation : Loss - 0.6399, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.5089s\n",
      "Epoch: 185/200\n",
      "Batch number: 000, Training: Loss: 0.5525, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6752, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6610, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5583, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5093, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.6413, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6112, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5155, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.5181, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5592, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5136, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5773, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6216, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6511, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5922, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6355, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5113, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6472, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.4896, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.4702, Accuracy: 0.9375\n",
      "Batch number: 020, Training: Loss: 0.5702, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5122, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6624, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5082, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.6795, Accuracy: 0.4667\n",
      "Epoch : 184, Training: Loss - 0.5775, Accuracy - 72.6817%, \n",
      "\t\tValidation : Loss - 0.6373, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.5496s\n",
      "Epoch: 186/200\n",
      "Batch number: 000, Training: Loss: 0.5173, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.6213, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.4713, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.5226, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.5572, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.4745, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5755, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6576, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5893, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5075, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5374, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6784, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6079, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6735, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6730, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.7840, Accuracy: 0.3750\n",
      "Batch number: 016, Training: Loss: 0.6431, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6530, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5341, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.4984, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5301, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.4680, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.6815, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7186, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6033, Accuracy: 0.6667\n",
      "Epoch : 185, Training: Loss - 0.5911, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6385, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.4319s\n",
      "Epoch: 187/200\n",
      "Batch number: 000, Training: Loss: 0.5391, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5804, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5659, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6146, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6410, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5644, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5370, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6504, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6567, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.6089, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5801, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.7066, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5012, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.7408, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.4747, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.5073, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5933, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5456, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5897, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5677, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5688, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5697, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5351, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6951, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.5448, Accuracy: 0.7333\n",
      "Epoch : 186, Training: Loss - 0.5873, Accuracy - 70.9273%, \n",
      "\t\tValidation : Loss - 0.6361, Accuracy - 69.0909%, Recall - 0.5000, Time: 83.7994s\n",
      "Epoch: 188/200\n",
      "Batch number: 000, Training: Loss: 0.6943, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5923, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5660, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5233, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.4935, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5095, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5065, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5301, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.4984, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6272, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5741, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6114, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5698, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5804, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5441, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5567, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6649, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5096, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5486, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.5875, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6679, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.4923, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.7146, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.7047, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.4936, Accuracy: 0.8000\n",
      "Epoch : 187, Training: Loss - 0.5746, Accuracy - 73.4336%, \n",
      "\t\tValidation : Loss - 0.6332, Accuracy - 67.2727%, Recall - 0.4500, Time: 83.0329s\n",
      "Epoch: 189/200\n",
      "Batch number: 000, Training: Loss: 0.6334, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5298, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5038, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.5761, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5988, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5065, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.4826, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.6466, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5089, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6108, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6974, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5659, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5816, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6708, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.6098, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7200, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5271, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5995, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5154, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5892, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5169, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.5184, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5754, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6894, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.5417, Accuracy: 0.7333\n",
      "Epoch : 188, Training: Loss - 0.5807, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6329, Accuracy - 72.7273%, Recall - 0.5000, Time: 82.5626s\n",
      "Epoch: 190/200\n",
      "Batch number: 000, Training: Loss: 0.5594, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5674, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6484, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5908, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5979, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6550, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5335, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.4877, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.5830, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6315, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6035, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5027, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.4834, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6262, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5920, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5297, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5432, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6370, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.4992, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5866, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5553, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6158, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6454, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5434, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5540, Accuracy: 0.8000\n",
      "Epoch : 189, Training: Loss - 0.5749, Accuracy - 72.9323%, \n",
      "\t\tValidation : Loss - 0.6318, Accuracy - 72.7273%, Recall - 0.4500, Time: 82.4705s\n",
      "Epoch: 191/200\n",
      "Batch number: 000, Training: Loss: 0.6055, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5106, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5001, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6069, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6009, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5290, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6162, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5976, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6566, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5218, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6563, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6105, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6290, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6655, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5209, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5563, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5635, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5955, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7623, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.4958, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.5181, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.4701, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.5790, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5219, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5731, Accuracy: 0.6667\n",
      "Epoch : 190, Training: Loss - 0.5785, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6308, Accuracy - 72.7273%, Recall - 0.4500, Time: 82.4687s\n",
      "Epoch: 192/200\n",
      "Batch number: 000, Training: Loss: 0.6205, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7044, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.5243, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5312, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5310, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.6048, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5602, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.4515, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6137, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6745, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6543, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5424, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6694, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5379, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.5151, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6524, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5044, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6773, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.5560, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6310, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7286, Accuracy: 0.3750\n",
      "Batch number: 021, Training: Loss: 0.5399, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5593, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5941, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5942, Accuracy: 0.8000\n",
      "Epoch : 191, Training: Loss - 0.5909, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6362, Accuracy - 69.0909%, Recall - 0.5000, Time: 83.6627s\n",
      "Epoch: 193/200\n",
      "Batch number: 000, Training: Loss: 0.5879, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6018, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6606, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6106, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5574, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5730, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5120, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5770, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6607, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5454, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5382, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5917, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5050, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6078, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5768, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5578, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6852, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.5601, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6777, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6321, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5187, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6304, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5308, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.7447, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6766, Accuracy: 0.5333\n",
      "Epoch : 192, Training: Loss - 0.5966, Accuracy - 69.6742%, \n",
      "\t\tValidation : Loss - 0.6297, Accuracy - 70.9091%, Recall - 0.4000, Time: 83.2893s\n",
      "Epoch: 194/200\n",
      "Batch number: 000, Training: Loss: 0.4971, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.5787, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5220, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5775, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6098, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5595, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.4563, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5514, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.7484, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.5365, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6719, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.4757, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.6104, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5889, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5474, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6591, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6195, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5592, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5327, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5383, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5674, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6164, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6501, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7280, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.5317, Accuracy: 0.8000\n",
      "Epoch : 193, Training: Loss - 0.5815, Accuracy - 71.6792%, \n",
      "\t\tValidation : Loss - 0.6366, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.2834s\n",
      "Epoch: 195/200\n",
      "Batch number: 000, Training: Loss: 0.6004, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5058, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5876, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6374, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.4818, Accuracy: 0.9375\n",
      "Batch number: 005, Training: Loss: 0.6354, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5713, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5554, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.4628, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6792, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6734, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5915, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5537, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.4912, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.4897, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.6467, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.4871, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6076, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5714, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5844, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6461, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6452, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5699, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5346, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.6408, Accuracy: 0.5333\n",
      "Epoch : 194, Training: Loss - 0.5778, Accuracy - 70.6767%, \n",
      "\t\tValidation : Loss - 0.6366, Accuracy - 67.2727%, Recall - 0.5000, Time: 82.2459s\n",
      "Epoch: 196/200\n",
      "Batch number: 000, Training: Loss: 0.5358, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5525, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.4553, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.6880, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6664, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5860, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6252, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6331, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6854, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5221, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5863, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6679, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.7107, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5719, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7116, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5810, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5361, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.7646, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.4854, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5179, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6466, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5918, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5199, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5254, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5967, Accuracy: 0.6000\n",
      "Epoch : 195, Training: Loss - 0.5985, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6340, Accuracy - 67.2727%, Recall - 0.4500, Time: 83.8879s\n",
      "Epoch: 197/200\n",
      "Batch number: 000, Training: Loss: 0.6626, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.4629, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.5336, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5392, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.4872, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5859, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5221, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6092, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6402, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5922, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5204, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6385, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5680, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5134, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6848, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.6568, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6981, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.6494, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6350, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5597, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5734, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5079, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.6208, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5668, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5147, Accuracy: 0.8000\n",
      "Epoch : 196, Training: Loss - 0.5819, Accuracy - 70.1754%, \n",
      "\t\tValidation : Loss - 0.6398, Accuracy - 63.6364%, Recall - 0.5000, Time: 82.1679s\n",
      "Epoch: 198/200\n",
      "Batch number: 000, Training: Loss: 0.5485, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.4735, Accuracy: 0.9375\n",
      "Batch number: 002, Training: Loss: 0.6201, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5101, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6808, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6068, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5246, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.5901, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6650, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.4932, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5616, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6018, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6749, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5282, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5097, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6697, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.7226, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5426, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5816, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5953, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.4887, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.5680, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6090, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5687, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5367, Accuracy: 0.8000\n",
      "Epoch : 197, Training: Loss - 0.5790, Accuracy - 72.1805%, \n",
      "\t\tValidation : Loss - 0.6356, Accuracy - 69.0909%, Recall - 0.4000, Time: 82.3060s\n",
      "Epoch: 199/200\n",
      "Batch number: 000, Training: Loss: 0.4987, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5560, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5331, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.4730, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6491, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5113, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5982, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7243, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.5423, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6087, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5263, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5907, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7374, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5228, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6763, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5191, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6081, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5595, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5663, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5832, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5898, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.7785, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.6844, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.4232, Accuracy: 0.9375\n",
      "Batch number: 024, Training: Loss: 0.6489, Accuracy: 0.6667\n",
      "Epoch : 198, Training: Loss - 0.5882, Accuracy - 70.4261%, \n",
      "\t\tValidation : Loss - 0.6346, Accuracy - 67.2727%, Recall - 0.4500, Time: 82.4596s\n",
      "Epoch: 200/200\n",
      "Batch number: 000, Training: Loss: 0.5020, Accuracy: 0.8750\n",
      "Batch number: 001, Training: Loss: 0.5066, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5954, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5718, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5021, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6840, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6139, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5614, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6599, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5504, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6166, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5772, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5498, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5599, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5864, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5842, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6026, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6587, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5334, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.5626, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5651, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6834, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.6048, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6541, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5266, Accuracy: 0.8000\n",
      "Epoch : 199, Training: Loss - 0.5847, Accuracy - 71.1779%, \n",
      "\t\tValidation : Loss - 0.6423, Accuracy - 65.4545%, Recall - 0.5000, Time: 82.3153s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "trained_model, history, best_epoch = train_and_validate(model, loss_func, optimizer, num_epochs)\n",
    "torch.save(history, '_chexnet_history.pt') #chestxray_chexnet_history.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "NhdDpiBxY3yL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Train Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3UQo58sWY3yL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Train Accuracy', 'Validation Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2uRG9vljjCA"
   },
   "source": [
    "###torchxrayvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjT2WhLtjjCA"
   },
   "source": [
    "####transfer learning tradicional (s√≥ fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkNd2CcCjjCA"
   },
   "source": [
    "https://mlmed.org/torchxrayvision/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-NPHMeO9jjCA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_data_loader_for_custom_networks))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "O0tC0Rv4jjCA"
   },
   "outputs": [],
   "source": [
    "#modelo DenseNet121 com os pesos do CheXpert\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-chex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "gYFI7SmAjjCA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.conv0.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "4J_uL9p8jjCB"
   },
   "outputs": [],
   "source": [
    "#congela todos os pesos, dai altera a fully connected e descongela s√≥ ela\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(n_features, 2) # 2 saidas: COVID / n√£o-COVID | CheXpert tem 18\n",
    "\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "-pc_z-VgjjCB"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JEQIJ546jjCB"
   },
   "outputs": [],
   "source": [
    "class DenseNetWrapper(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.shape[1] == 3:\n",
    "        # Converte de 3 canais pra 1 canal - ta forcando isso, gambiarra pq eu nao achei o problema k)\n",
    "            x = x.mean(dim=1, keepdim=True)\n",
    "        features = self.base_model.features(x)  # sa√≠da 4D: [batch, canais, H, W]\n",
    "        features = nn.functional.adaptive_avg_pool2d(features, (1, 1))  # reduz para [batch, canais, 1, 1]\n",
    "        features = torch.flatten(features, 1)  # achata para [batch, canais]\n",
    "        out = self.base_model.classifier(features)  # passa na camada linear\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vwoGNp32jjCB"
   },
   "outputs": [],
   "source": [
    "model = DenseNetWrapper(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "_hWgg2iFjjCB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "Batch number: 000, Training: Loss: 0.7717, Accuracy: 0.1875\n",
      "Batch number: 001, Training: Loss: 0.7375, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6749, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.9243, Accuracy: 0.3750\n",
      "Batch number: 004, Training: Loss: 0.7574, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.7631, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.6628, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.7011, Accuracy: 0.3750\n",
      "Batch number: 008, Training: Loss: 0.6822, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6713, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6815, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5975, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5352, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.7165, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.4325, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.6540, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5388, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6701, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.9120, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6724, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6612, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7448, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6318, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7240, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.7349, Accuracy: 0.4667\n",
      "Epoch : 000, Training: Loss - 0.6900, Accuracy - 59.6491%, \n",
      "\t\tValidation : Loss - 0.6673, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.0727s\n",
      "Epoch: 2/100\n",
      "Batch number: 000, Training: Loss: 0.7020, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.7227, Accuracy: 0.3125\n",
      "Batch number: 002, Training: Loss: 0.6591, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.8039, Accuracy: 0.2500\n",
      "Batch number: 004, Training: Loss: 0.7285, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.7497, Accuracy: 0.3125\n",
      "Batch number: 006, Training: Loss: 0.6761, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7377, Accuracy: 0.2500\n",
      "Batch number: 008, Training: Loss: 0.6900, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.6502, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6649, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5625, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.7236, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.7063, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6411, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6829, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5172, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.4831, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6759, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6839, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6079, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.4867, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5506, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6223, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.9198, Accuracy: 0.4000\n",
      "Epoch : 001, Training: Loss - 0.6653, Accuracy - 59.6491%, \n",
      "\t\tValidation : Loss - 0.6793, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.2595s\n",
      "Epoch: 3/100\n",
      "Batch number: 000, Training: Loss: 0.7563, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.6062, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.7117, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7348, Accuracy: 0.3125\n",
      "Batch number: 004, Training: Loss: 0.7099, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.7404, Accuracy: 0.3750\n",
      "Batch number: 006, Training: Loss: 0.6714, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7860, Accuracy: 0.2500\n",
      "Batch number: 008, Training: Loss: 0.7073, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.8107, Accuracy: 0.1250\n",
      "Batch number: 010, Training: Loss: 0.6617, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6243, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6779, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6083, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.8212, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.8443, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6309, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6061, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7443, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.8153, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5478, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5351, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7276, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5548, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6289, Accuracy: 0.8000\n",
      "Epoch : 002, Training: Loss - 0.6907, Accuracy - 56.1404%, \n",
      "\t\tValidation : Loss - 0.6608, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.2970s\n",
      "Epoch: 4/100\n",
      "Batch number: 000, Training: Loss: 0.6438, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6289, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6042, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6712, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6662, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6717, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.6317, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5489, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6121, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.7003, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6084, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5969, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7448, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.6206, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6140, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7677, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5620, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6233, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6489, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.7441, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.7417, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5567, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6476, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6790, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6191, Accuracy: 0.6667\n",
      "Epoch : 003, Training: Loss - 0.6462, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6879, Accuracy - 58.1818%, Recall - 0.1000, Time: 78.1880s\n",
      "Epoch: 5/100\n",
      "Batch number: 000, Training: Loss: 0.7261, Accuracy: 0.3125\n",
      "Batch number: 001, Training: Loss: 0.7497, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6917, Accuracy: 0.4375\n",
      "Batch number: 003, Training: Loss: 0.7028, Accuracy: 0.4375\n",
      "Batch number: 004, Training: Loss: 0.6828, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6793, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6710, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6324, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6055, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5437, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6766, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7061, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5925, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 1.0064, Accuracy: 0.3750\n",
      "Batch number: 014, Training: Loss: 0.7745, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6653, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5034, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.4712, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5733, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7743, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6057, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6184, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5712, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5979, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6569, Accuracy: 0.5333\n",
      "Epoch : 004, Training: Loss - 0.6591, Accuracy - 61.9048%, \n",
      "\t\tValidation : Loss - 1.3132, Accuracy - 36.3636%, Recall - 1.0000, Time: 78.3211s\n",
      "Epoch: 6/100\n",
      "Batch number: 000, Training: Loss: 0.6504, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6049, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6595, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5531, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.8181, Accuracy: 0.3750\n",
      "Batch number: 005, Training: Loss: 0.5975, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6677, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6725, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6237, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6873, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6100, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.7208, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.6515, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5584, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6965, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5436, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6555, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5364, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5881, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.8448, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.7837, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5639, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7724, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6052, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.5065, Accuracy: 0.8000\n",
      "Epoch : 005, Training: Loss - 0.6472, Accuracy - 64.4110%, \n",
      "\t\tValidation : Loss - 0.6926, Accuracy - 63.6364%, Recall - 0.1500, Time: 78.1653s\n",
      "Epoch: 7/100\n",
      "Batch number: 000, Training: Loss: 0.5810, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.7473, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.7565, Accuracy: 0.4375\n",
      "Batch number: 003, Training: Loss: 0.6194, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6805, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5974, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6046, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6733, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.7339, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.6676, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6663, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.5879, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5841, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6446, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.4247, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.5586, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.7782, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.8492, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6949, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6774, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5331, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6698, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6107, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6678, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5828, Accuracy: 0.7333\n",
      "Epoch : 006, Training: Loss - 0.6478, Accuracy - 63.6591%, \n",
      "\t\tValidation : Loss - 0.6742, Accuracy - 65.4545%, Recall - 0.0500, Time: 78.4967s\n",
      "Epoch: 8/100\n",
      "Batch number: 000, Training: Loss: 0.7283, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.6600, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6066, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6369, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7157, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6781, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5805, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6207, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5985, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4905, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.7413, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.8042, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.5630, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5812, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5091, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6746, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6335, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.8773, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.6462, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6444, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6649, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.7192, Accuracy: 0.4375\n",
      "Batch number: 022, Training: Loss: 0.7193, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6292, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6073, Accuracy: 0.7333\n",
      "Epoch : 007, Training: Loss - 0.6533, Accuracy - 61.6541%, \n",
      "\t\tValidation : Loss - 0.6491, Accuracy - 60.0000%, Recall - 0.1500, Time: 78.7226s\n",
      "Epoch: 9/100\n",
      "Batch number: 000, Training: Loss: 0.6092, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.7116, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.7009, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5382, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.7287, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.5603, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6497, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7744, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6655, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5025, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.7271, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.7293, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.6314, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6683, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5681, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6549, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6053, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5814, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5993, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5883, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.8190, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.7033, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.4510, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5895, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6727, Accuracy: 0.6000\n",
      "Epoch : 008, Training: Loss - 0.6411, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6525, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.4013s\n",
      "Epoch: 10/100\n",
      "Batch number: 000, Training: Loss: 0.7146, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5404, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5160, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5529, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7861, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5833, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6525, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5965, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6317, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6365, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6737, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6084, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7213, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6533, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6553, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6371, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.7065, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6289, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7073, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6649, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6640, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5714, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6580, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7201, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.8730, Accuracy: 0.4000\n",
      "Epoch : 009, Training: Loss - 0.6536, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6636, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.2807s\n",
      "Epoch: 11/100\n",
      "Batch number: 000, Training: Loss: 0.7711, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5298, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6069, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5863, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.7319, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.6191, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6709, Accuracy: 0.3750\n",
      "Batch number: 007, Training: Loss: 0.6904, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5921, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.7571, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6800, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6111, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.6314, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6030, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5658, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6046, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6162, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5865, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6527, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6333, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5123, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 1.0218, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.7454, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.4802, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.6668, Accuracy: 0.5333\n",
      "Epoch : 010, Training: Loss - 0.6466, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.6405, Accuracy - 63.6364%, Recall - 0.1000, Time: 78.3860s\n",
      "Epoch: 12/100\n",
      "Batch number: 000, Training: Loss: 0.6203, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6015, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6418, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6897, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7207, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.6296, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6444, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6682, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.7615, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.6709, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6635, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5563, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.7619, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.9233, Accuracy: 0.3125\n",
      "Batch number: 014, Training: Loss: 0.6185, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6570, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5730, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.7878, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.6189, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5896, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6225, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6132, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6721, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5194, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5342, Accuracy: 0.8000\n",
      "Epoch : 011, Training: Loss - 0.6547, Accuracy - 62.1554%, \n",
      "\t\tValidation : Loss - 0.6613, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.5130s\n",
      "Epoch: 13/100\n",
      "Batch number: 000, Training: Loss: 0.6687, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7726, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.7135, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.4259, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.7679, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5507, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6523, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.7582, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.7111, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5851, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6609, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5997, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7065, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6484, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7243, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5964, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6417, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5465, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5075, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 1.0450, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.7554, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5769, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7773, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5444, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6356, Accuracy: 0.6000\n",
      "Epoch : 012, Training: Loss - 0.6630, Accuracy - 64.4110%, \n",
      "\t\tValidation : Loss - 0.6450, Accuracy - 65.4545%, Recall - 0.0500, Time: 78.5599s\n",
      "Epoch: 14/100\n",
      "Batch number: 000, Training: Loss: 0.6640, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.8125, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6489, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6561, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7389, Accuracy: 0.3750\n",
      "Batch number: 005, Training: Loss: 0.6595, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6904, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6393, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6557, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6327, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6750, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6833, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5573, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.4778, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.4087, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.9791, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.6188, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6533, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6492, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.4864, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6558, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.8612, Accuracy: 0.4375\n",
      "Batch number: 022, Training: Loss: 0.6193, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5369, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6521, Accuracy: 0.5333\n",
      "Epoch : 013, Training: Loss - 0.6525, Accuracy - 63.1579%, \n",
      "\t\tValidation : Loss - 0.6506, Accuracy - 65.4545%, Recall - 0.1500, Time: 78.3926s\n",
      "Epoch: 15/100\n",
      "Batch number: 000, Training: Loss: 0.5961, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6754, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6101, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5558, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.7554, Accuracy: 0.3750\n",
      "Batch number: 005, Training: Loss: 0.6805, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5849, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7075, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.7505, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6579, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6967, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7104, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6728, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6261, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7048, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7003, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5647, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6937, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6786, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.7778, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.6155, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6073, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6742, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5876, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5864, Accuracy: 0.8000\n",
      "Epoch : 014, Training: Loss - 0.6590, Accuracy - 63.6591%, \n",
      "\t\tValidation : Loss - 0.6450, Accuracy - 69.0909%, Recall - 0.1500, Time: 79.1249s\n",
      "Epoch: 16/100\n",
      "Batch number: 000, Training: Loss: 0.4476, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5529, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5942, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.8528, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6100, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6304, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.7362, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7001, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6286, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7040, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6560, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.7294, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6394, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6419, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6784, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6102, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.6265, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6611, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.7659, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.6388, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6035, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5978, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6276, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5672, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6836, Accuracy: 0.5333\n",
      "Epoch : 015, Training: Loss - 0.6473, Accuracy - 64.1604%, \n",
      "\t\tValidation : Loss - 0.6560, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.6779s\n",
      "Epoch: 17/100\n",
      "Batch number: 000, Training: Loss: 0.6913, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5117, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.7810, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6082, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6764, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.7027, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6566, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.7503, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6085, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6629, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6536, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7759, Accuracy: 0.3750\n",
      "Batch number: 012, Training: Loss: 0.6244, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.7089, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6211, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5352, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.5026, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5493, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.4328, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6691, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.8005, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6313, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5457, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 1.0116, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.6383, Accuracy: 0.6667\n",
      "Epoch : 016, Training: Loss - 0.6540, Accuracy - 64.6617%, \n",
      "\t\tValidation : Loss - 0.6693, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.5065s\n",
      "Epoch: 18/100\n",
      "Batch number: 000, Training: Loss: 0.7027, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5774, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7047, Accuracy: 0.4375\n",
      "Batch number: 003, Training: Loss: 0.6503, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6173, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6922, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6615, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6749, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6744, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6267, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5370, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5123, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6896, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5067, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5101, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6409, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6274, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.7144, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.9119, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.8373, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6166, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7994, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6461, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6823, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.7042, Accuracy: 0.5333\n",
      "Epoch : 017, Training: Loss - 0.6606, Accuracy - 62.4060%, \n",
      "\t\tValidation : Loss - 0.7533, Accuracy - 45.4545%, Recall - 0.9500, Time: 78.3168s\n",
      "Epoch: 19/100\n",
      "Batch number: 000, Training: Loss: 0.7712, Accuracy: 0.3750\n",
      "Batch number: 001, Training: Loss: 0.8091, Accuracy: 0.2500\n",
      "Batch number: 002, Training: Loss: 0.6399, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6456, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6287, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5619, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7835, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.6894, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.8734, Accuracy: 0.3750\n",
      "Batch number: 009, Training: Loss: 0.5012, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5621, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.4746, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6513, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.8214, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6217, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5864, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6319, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5944, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6141, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7285, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5928, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6686, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6523, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6731, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6725, Accuracy: 0.7333\n",
      "Epoch : 018, Training: Loss - 0.6579, Accuracy - 60.9023%, \n",
      "\t\tValidation : Loss - 0.6490, Accuracy - 63.6364%, Recall - 0.1000, Time: 80.6141s\n",
      "Epoch: 20/100\n",
      "Batch number: 000, Training: Loss: 0.7015, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7242, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.5890, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6021, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6191, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.7865, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.6005, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5006, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.7311, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5748, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6590, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5805, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5008, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.7505, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6484, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6449, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5853, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.7661, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5942, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7251, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6590, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6401, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6742, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.5811, Accuracy: 0.9375\n",
      "Batch number: 024, Training: Loss: 0.6070, Accuracy: 0.6667\n",
      "Epoch : 019, Training: Loss - 0.6419, Accuracy - 64.6617%, \n",
      "\t\tValidation : Loss - 0.6412, Accuracy - 61.8182%, Recall - 0.1000, Time: 78.4669s\n",
      "Epoch: 21/100\n",
      "Batch number: 000, Training: Loss: 0.5477, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6215, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6621, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5851, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5554, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6821, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7622, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.6438, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.7565, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.7052, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6609, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6471, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6961, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5857, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6405, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5363, Accuracy: 0.9375\n",
      "Batch number: 016, Training: Loss: 0.6928, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6178, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6760, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5789, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5337, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6722, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7201, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.6305, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6476, Accuracy: 0.6667\n",
      "Epoch : 020, Training: Loss - 0.6423, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6412, Accuracy - 63.6364%, Recall - 0.1500, Time: 78.6038s\n",
      "Epoch: 22/100\n",
      "Batch number: 000, Training: Loss: 0.6009, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.4843, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.6062, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6034, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5051, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5245, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.7383, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6312, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5537, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.9457, Accuracy: 0.3750\n",
      "Batch number: 010, Training: Loss: 0.7703, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5684, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5575, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6069, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6142, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7865, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.5887, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6383, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7361, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.5682, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6930, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6863, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6232, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5590, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6460, Accuracy: 0.6667\n",
      "Epoch : 021, Training: Loss - 0.6334, Accuracy - 66.1654%, \n",
      "\t\tValidation : Loss - 0.6451, Accuracy - 63.6364%, Recall - 0.1500, Time: 78.4276s\n",
      "Epoch: 23/100\n",
      "Batch number: 000, Training: Loss: 0.7647, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5805, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.4867, Accuracy: 0.8750\n",
      "Batch number: 003, Training: Loss: 0.5832, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6134, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.7785, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.7890, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.6918, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6207, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5433, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5938, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.7245, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6868, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.6709, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5837, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6707, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.4152, Accuracy: 0.9375\n",
      "Batch number: 017, Training: Loss: 0.6391, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7847, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.9479, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.4831, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.4834, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.7342, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.5814, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6820, Accuracy: 0.6000\n",
      "Epoch : 022, Training: Loss - 0.6452, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6470, Accuracy - 63.6364%, Recall - 0.1500, Time: 78.4514s\n",
      "Epoch: 24/100\n",
      "Batch number: 000, Training: Loss: 0.5713, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5796, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6423, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7709, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6273, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6617, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6155, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6675, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6378, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6961, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.5543, Accuracy: 0.9375\n",
      "Batch number: 011, Training: Loss: 0.6862, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.4562, Accuracy: 0.9375\n",
      "Batch number: 013, Training: Loss: 0.7491, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6476, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5286, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5841, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5974, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6698, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6735, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5630, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5675, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6373, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6465, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6484, Accuracy: 0.7333\n",
      "Epoch : 023, Training: Loss - 0.6271, Accuracy - 65.6642%, \n",
      "\t\tValidation : Loss - 0.6623, Accuracy - 65.4545%, Recall - 0.0500, Time: 78.4777s\n",
      "Epoch: 25/100\n",
      "Batch number: 000, Training: Loss: 0.6607, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5923, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6092, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6113, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5780, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6985, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.5597, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6939, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6443, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6494, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5899, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6311, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6018, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5648, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6231, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5366, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6169, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6629, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6254, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.8365, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.8231, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6210, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6025, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7839, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.5673, Accuracy: 0.8000\n",
      "Epoch : 024, Training: Loss - 0.6395, Accuracy - 64.6617%, \n",
      "\t\tValidation : Loss - 0.6741, Accuracy - 56.3636%, Recall - 0.4500, Time: 78.6106s\n",
      "Epoch: 26/100\n",
      "Batch number: 000, Training: Loss: 0.6852, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6797, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.7492, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.7386, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6337, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6382, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6893, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5259, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6576, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.7585, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.8787, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.4586, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5524, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6100, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 1.0104, Accuracy: 0.3125\n",
      "Batch number: 015, Training: Loss: 0.6723, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6059, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.7056, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6924, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6581, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6598, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6664, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6801, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6327, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5476, Accuracy: 0.8000\n",
      "Epoch : 025, Training: Loss - 0.6718, Accuracy - 60.4010%, \n",
      "\t\tValidation : Loss - 0.6634, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.4352s\n",
      "Epoch: 27/100\n",
      "Batch number: 000, Training: Loss: 0.5244, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5706, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.7064, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6171, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7670, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6873, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.7946, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5603, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.7390, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6549, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6274, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6200, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6922, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6110, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6843, Accuracy: 0.3750\n",
      "Batch number: 015, Training: Loss: 0.6107, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6933, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.7271, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.6728, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.7191, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.6040, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5913, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6931, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7041, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.8198, Accuracy: 0.5333\n",
      "Epoch : 026, Training: Loss - 0.6673, Accuracy - 61.6541%, \n",
      "\t\tValidation : Loss - 0.7150, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.3919s\n",
      "Epoch: 28/100\n",
      "Batch number: 000, Training: Loss: 0.6993, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.8044, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.7287, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6149, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5859, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.7348, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6779, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6315, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5808, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.5773, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.7173, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.6141, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6039, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6363, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.7166, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6652, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5556, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.4040, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.7576, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.9576, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.7280, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.7557, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.4277, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.7063, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.4257, Accuracy: 0.8667\n",
      "Epoch : 027, Training: Loss - 0.6529, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6646, Accuracy - 67.2727%, Recall - 0.1000, Time: 78.5070s\n",
      "Epoch: 29/100\n",
      "Batch number: 000, Training: Loss: 0.7398, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.6536, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6452, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6312, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5574, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5186, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5951, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6513, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6148, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6394, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.9053, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.7036, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6881, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.4533, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.4890, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.4967, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.7819, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.7048, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.7067, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5986, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6972, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5068, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6107, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5850, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6873, Accuracy: 0.4667\n",
      "Epoch : 028, Training: Loss - 0.6343, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6605, Accuracy - 56.3636%, Recall - 0.3000, Time: 78.4919s\n",
      "Epoch: 30/100\n",
      "Batch number: 000, Training: Loss: 0.6210, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6000, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6457, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6455, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6619, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6303, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6157, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6678, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6381, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7020, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.5793, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.7394, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.6157, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6031, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6295, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5793, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6132, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.3607, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.6406, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7270, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.8817, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.6559, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.4222, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5734, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6310, Accuracy: 0.6667\n",
      "Epoch : 029, Training: Loss - 0.6272, Accuracy - 67.6692%, \n",
      "\t\tValidation : Loss - 0.6510, Accuracy - 67.2727%, Recall - 0.1500, Time: 78.4269s\n",
      "Epoch: 31/100\n",
      "Batch number: 000, Training: Loss: 0.6425, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6388, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5878, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5977, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6102, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6776, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5945, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6161, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5342, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5520, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.8929, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.5235, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6030, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5614, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.7473, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.9060, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6648, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5879, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7320, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5988, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5967, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7226, Accuracy: 0.4375\n",
      "Batch number: 022, Training: Loss: 0.7549, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7639, Accuracy: 0.2500\n",
      "Batch number: 024, Training: Loss: 0.7102, Accuracy: 0.5333\n",
      "Epoch : 030, Training: Loss - 0.6566, Accuracy - 62.4060%, \n",
      "\t\tValidation : Loss - 0.6556, Accuracy - 56.3636%, Recall - 0.2500, Time: 78.7563s\n",
      "Epoch: 32/100\n",
      "Batch number: 000, Training: Loss: 0.6226, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6404, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5417, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.4198, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6272, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6465, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.9439, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6115, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.4907, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5616, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6301, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.7565, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.4880, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.8140, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.5983, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6746, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6628, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5860, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6746, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.7328, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.7355, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.6603, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6661, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.7012, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5338, Accuracy: 0.8000\n",
      "Epoch : 031, Training: Loss - 0.6411, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6600, Accuracy - 67.2727%, Recall - 0.1000, Time: 78.5599s\n",
      "Epoch: 33/100\n",
      "Batch number: 000, Training: Loss: 0.5650, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6338, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.4883, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.7271, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 1.0245, Accuracy: 0.3125\n",
      "Batch number: 005, Training: Loss: 0.8182, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6676, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6421, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5791, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6417, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6786, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7669, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.5826, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6154, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.4813, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.7012, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5997, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6619, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7110, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6636, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6045, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6760, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6219, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6687, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6378, Accuracy: 0.6000\n",
      "Epoch : 032, Training: Loss - 0.6584, Accuracy - 62.1554%, \n",
      "\t\tValidation : Loss - 0.6521, Accuracy - 63.6364%, Recall - 0.2000, Time: 78.5104s\n",
      "Epoch: 34/100\n",
      "Batch number: 000, Training: Loss: 0.6578, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5880, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6541, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6175, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6998, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6109, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6102, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7280, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6496, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5855, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6954, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6993, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5331, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.7321, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5528, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5903, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6585, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6037, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6212, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5980, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6918, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5700, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5281, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6410, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5611, Accuracy: 0.8667\n",
      "Epoch : 033, Training: Loss - 0.6273, Accuracy - 66.1654%, \n",
      "\t\tValidation : Loss - 0.6782, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.5510s\n",
      "Epoch: 35/100\n",
      "Batch number: 000, Training: Loss: 0.8503, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.6568, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6286, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.8163, Accuracy: 0.3750\n",
      "Batch number: 004, Training: Loss: 0.5112, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6279, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5497, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5980, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6445, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6277, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6338, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.4987, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.6364, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.8091, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5660, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6538, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6739, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6041, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6566, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5613, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6235, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5737, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5161, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5244, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6312, Accuracy: 0.6667\n",
      "Epoch : 034, Training: Loss - 0.6269, Accuracy - 67.1679%, \n",
      "\t\tValidation : Loss - 0.6763, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.4098s\n",
      "Epoch: 36/100\n",
      "Batch number: 000, Training: Loss: 0.5712, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6907, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.5942, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6195, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7165, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6800, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6042, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6515, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6476, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5774, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5753, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.5874, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6910, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5718, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5366, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.7141, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5953, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6114, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.7203, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.5601, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6726, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.8714, Accuracy: 0.4375\n",
      "Batch number: 022, Training: Loss: 0.6675, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5545, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.7361, Accuracy: 0.5333\n",
      "Epoch : 035, Training: Loss - 0.6405, Accuracy - 65.6642%, \n",
      "\t\tValidation : Loss - 0.6811, Accuracy - 54.5455%, Recall - 0.5000, Time: 78.3405s\n",
      "Epoch: 37/100\n",
      "Batch number: 000, Training: Loss: 0.6157, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6435, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6896, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.5818, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6102, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5719, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.4769, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7170, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.7603, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.6614, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5326, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6990, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5740, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6763, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6903, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6137, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6408, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5959, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6720, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6613, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6194, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6322, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5515, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6908, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5834, Accuracy: 0.6667\n",
      "Epoch : 036, Training: Loss - 0.6306, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6579, Accuracy - 69.0909%, Recall - 0.2000, Time: 78.5982s\n",
      "Epoch: 38/100\n",
      "Batch number: 000, Training: Loss: 0.5250, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5643, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5705, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.4719, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6815, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6519, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.8286, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5698, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5057, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6404, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.7259, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.5204, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5035, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6375, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6719, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.7759, Accuracy: 0.3125\n",
      "Batch number: 016, Training: Loss: 0.6489, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6260, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.8427, Accuracy: 0.3750\n",
      "Batch number: 019, Training: Loss: 0.6758, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7235, Accuracy: 0.3750\n",
      "Batch number: 021, Training: Loss: 0.6578, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6662, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5170, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5489, Accuracy: 0.7333\n",
      "Epoch : 037, Training: Loss - 0.6303, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6646, Accuracy - 65.4545%, Recall - 0.0500, Time: 79.6426s\n",
      "Epoch: 39/100\n",
      "Batch number: 000, Training: Loss: 0.4903, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6011, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5086, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7329, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.8085, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.9731, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6048, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.3916, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6567, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6644, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.7862, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6517, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5887, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6996, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.8128, Accuracy: 0.3750\n",
      "Batch number: 015, Training: Loss: 0.6830, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.6624, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.7255, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.6347, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6524, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5972, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.7151, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5404, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5334, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.4941, Accuracy: 0.8000\n",
      "Epoch : 038, Training: Loss - 0.6488, Accuracy - 63.1579%, \n",
      "\t\tValidation : Loss - 0.6783, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.5168s\n",
      "Epoch: 40/100\n",
      "Batch number: 000, Training: Loss: 0.6475, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6461, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.4374, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5125, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6309, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.7502, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6914, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6037, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6408, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.4431, Accuracy: 0.9375\n",
      "Batch number: 010, Training: Loss: 0.6228, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6443, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.5830, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.7754, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.5882, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5131, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5782, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6585, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5390, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6595, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6442, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5724, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.7167, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.7956, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.5521, Accuracy: 0.6667\n",
      "Epoch : 039, Training: Loss - 0.6180, Accuracy - 64.4110%, \n",
      "\t\tValidation : Loss - 0.6571, Accuracy - 58.1818%, Recall - 0.2000, Time: 78.4674s\n",
      "Epoch: 41/100\n",
      "Batch number: 000, Training: Loss: 0.5156, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6472, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6808, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7354, Accuracy: 0.3750\n",
      "Batch number: 004, Training: Loss: 0.6429, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6717, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5997, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5469, Accuracy: 0.8750\n",
      "Batch number: 008, Training: Loss: 0.6459, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6216, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5648, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5748, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6924, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.4334, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.7196, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.6657, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5122, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7747, Accuracy: 0.4375\n",
      "Batch number: 018, Training: Loss: 0.6773, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6316, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.7114, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.5952, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6074, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7008, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.5814, Accuracy: 0.6667\n",
      "Epoch : 040, Training: Loss - 0.6302, Accuracy - 65.1629%, \n",
      "\t\tValidation : Loss - 0.6848, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.5956s\n",
      "Epoch: 42/100\n",
      "Batch number: 000, Training: Loss: 0.6871, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5999, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5147, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.7754, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.7546, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6432, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6964, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7944, Accuracy: 0.3750\n",
      "Batch number: 008, Training: Loss: 0.6971, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.7142, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6458, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.7058, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6104, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6649, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.6624, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6314, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6889, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6749, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5274, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6272, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6210, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5584, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6819, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.3895, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5413, Accuracy: 0.7333\n",
      "Epoch : 041, Training: Loss - 0.6446, Accuracy - 62.1554%, \n",
      "\t\tValidation : Loss - 0.8124, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.5730s\n",
      "Epoch: 43/100\n",
      "Batch number: 000, Training: Loss: 0.4565, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6077, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.4533, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6199, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.8662, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6568, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6160, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5163, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6426, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.7172, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6766, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6998, Accuracy: 0.5000\n",
      "Batch number: 012, Training: Loss: 0.6633, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5705, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6186, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.7105, Accuracy: 0.3125\n",
      "Batch number: 016, Training: Loss: 0.6241, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6955, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.7668, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6313, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6643, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6786, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.5101, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6384, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.4235, Accuracy: 0.8667\n",
      "Epoch : 042, Training: Loss - 0.6295, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.7180, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.4705s\n",
      "Epoch: 44/100\n",
      "Batch number: 000, Training: Loss: 0.4569, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.3302, Accuracy: 0.9375\n",
      "Batch number: 002, Training: Loss: 0.4464, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 1.1439, Accuracy: 0.4375\n",
      "Batch number: 004, Training: Loss: 1.2532, Accuracy: 0.3750\n",
      "Batch number: 005, Training: Loss: 0.7121, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.8417, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5784, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6264, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6109, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.7066, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.7017, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6958, Accuracy: 0.3750\n",
      "Batch number: 013, Training: Loss: 0.7342, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6684, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7144, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6005, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6290, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5180, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.4719, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5892, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.9770, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.8180, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7938, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.8859, Accuracy: 0.5333\n",
      "Epoch : 043, Training: Loss - 0.6997, Accuracy - 62.9073%, \n",
      "\t\tValidation : Loss - 0.7284, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.3861s\n",
      "Epoch: 45/100\n",
      "Batch number: 000, Training: Loss: 0.4422, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.4237, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6468, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7140, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6189, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6190, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6310, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6487, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6903, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.7615, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6250, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6686, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6680, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.5286, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6573, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.8481, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6552, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5841, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6856, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6615, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5494, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6169, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5965, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6061, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6467, Accuracy: 0.6667\n",
      "Epoch : 044, Training: Loss - 0.6317, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6713, Accuracy - 63.6364%, Recall - 0.0500, Time: 78.6139s\n",
      "Epoch: 46/100\n",
      "Batch number: 000, Training: Loss: 0.7089, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6627, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5972, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6570, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.7331, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.7983, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.5865, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6015, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6602, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6759, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6786, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5545, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5911, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5460, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7136, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6056, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.7619, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.7710, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5772, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5681, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5913, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5860, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6477, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.4931, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.4756, Accuracy: 0.8667\n",
      "Epoch : 045, Training: Loss - 0.6341, Accuracy - 67.1679%, \n",
      "\t\tValidation : Loss - 0.6751, Accuracy - 65.4545%, Recall - 0.0500, Time: 79.6872s\n",
      "Epoch: 47/100\n",
      "Batch number: 000, Training: Loss: 0.7409, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5430, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6499, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6829, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6309, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.4798, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.6306, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7441, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6666, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5987, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.8347, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.5809, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5952, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.7469, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6150, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6817, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5841, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6183, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6706, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6257, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5773, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.4183, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.5867, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.8728, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.7983, Accuracy: 0.5333\n",
      "Epoch : 046, Training: Loss - 0.6466, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.7046, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.6046s\n",
      "Epoch: 48/100\n",
      "Batch number: 000, Training: Loss: 0.7978, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7297, Accuracy: 0.4375\n",
      "Batch number: 002, Training: Loss: 0.5319, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6519, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.5604, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6084, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6568, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5865, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5921, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6860, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6098, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6046, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6872, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6911, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.4740, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.7875, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5380, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.4245, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6747, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6474, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6645, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5881, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.7839, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.5591, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.7318, Accuracy: 0.4000\n",
      "Epoch : 047, Training: Loss - 0.6345, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6607, Accuracy - 58.1818%, Recall - 0.2000, Time: 78.4287s\n",
      "Epoch: 49/100\n",
      "Batch number: 000, Training: Loss: 0.7396, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6733, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.7239, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6515, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.7105, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6115, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5377, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.7834, Accuracy: 0.2500\n",
      "Batch number: 008, Training: Loss: 0.5822, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5275, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6596, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6720, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6686, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.7246, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5469, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6485, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5697, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6415, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5077, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6264, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6632, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6746, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.6114, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5657, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.6579, Accuracy: 0.6000\n",
      "Epoch : 048, Training: Loss - 0.6391, Accuracy - 63.4085%, \n",
      "\t\tValidation : Loss - 0.6569, Accuracy - 54.5455%, Recall - 0.2000, Time: 78.5663s\n",
      "Epoch: 50/100\n",
      "Batch number: 000, Training: Loss: 0.5821, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6139, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6372, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.4908, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6002, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5582, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6786, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6078, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7582, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7430, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.4933, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5376, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6269, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.7037, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5915, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6896, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.4993, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5374, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5924, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5654, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6611, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6386, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.7376, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6857, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6158, Accuracy: 0.5333\n",
      "Epoch : 049, Training: Loss - 0.6178, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6597, Accuracy - 50.9091%, Recall - 0.2000, Time: 78.4765s\n",
      "Epoch: 51/100\n",
      "Batch number: 000, Training: Loss: 0.6191, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6205, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5952, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.7384, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6886, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5045, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.7103, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5674, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5568, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5966, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.7223, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6128, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5917, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.4703, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6906, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6765, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.5614, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.4165, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.8103, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.7044, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5981, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.6136, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7001, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6944, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6068, Accuracy: 0.7333\n",
      "Epoch : 050, Training: Loss - 0.6267, Accuracy - 65.1629%, \n",
      "\t\tValidation : Loss - 0.6626, Accuracy - 58.1818%, Recall - 0.2000, Time: 78.5365s\n",
      "Epoch: 52/100\n",
      "Batch number: 000, Training: Loss: 0.6149, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5942, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6382, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5376, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5142, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.7546, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.4841, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.9644, Accuracy: 0.3125\n",
      "Batch number: 008, Training: Loss: 0.6257, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5207, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6218, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5947, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6878, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6064, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6806, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5720, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6836, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5927, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5579, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.8648, Accuracy: 0.3750\n",
      "Batch number: 020, Training: Loss: 0.6020, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5631, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5890, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.7236, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6733, Accuracy: 0.6667\n",
      "Epoch : 051, Training: Loss - 0.6344, Accuracy - 65.1629%, \n",
      "\t\tValidation : Loss - 0.6568, Accuracy - 67.2727%, Recall - 0.2000, Time: 78.5569s\n",
      "Epoch: 53/100\n",
      "Batch number: 000, Training: Loss: 0.7126, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5275, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.5988, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.4946, Accuracy: 0.9375\n",
      "Batch number: 004, Training: Loss: 0.5534, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5901, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6780, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5264, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7837, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.7324, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6165, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5593, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.4874, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.5324, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5995, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7814, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6724, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6336, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5860, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6171, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6881, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6475, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.7503, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6856, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6032, Accuracy: 0.6667\n",
      "Epoch : 052, Training: Loss - 0.6264, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6919, Accuracy - 52.7273%, Recall - 0.5500, Time: 78.6439s\n",
      "Epoch: 54/100\n",
      "Batch number: 000, Training: Loss: 0.6331, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6146, Accuracy: 0.8125\n",
      "Batch number: 002, Training: Loss: 0.6575, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6196, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5515, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5468, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.4295, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.6872, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5686, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 1.0012, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.6683, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6334, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5525, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6076, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6803, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.5755, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5501, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6542, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5931, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5943, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6730, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6384, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.7045, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6342, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6045, Accuracy: 0.6000\n",
      "Epoch : 053, Training: Loss - 0.6270, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.6528, Accuracy - 65.4545%, Recall - 0.2000, Time: 78.5662s\n",
      "Epoch: 55/100\n",
      "Batch number: 000, Training: Loss: 0.6078, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5688, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7463, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6183, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.8238, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.7752, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.4161, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.6616, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5448, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5444, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6475, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6634, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.6813, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.5980, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.5977, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5491, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6453, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6090, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5808, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6928, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6123, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5608, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6691, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.7779, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.5966, Accuracy: 0.6667\n",
      "Epoch : 054, Training: Loss - 0.6316, Accuracy - 64.6617%, \n",
      "\t\tValidation : Loss - 0.6565, Accuracy - 69.0909%, Recall - 0.2000, Time: 78.5826s\n",
      "Epoch: 56/100\n",
      "Batch number: 000, Training: Loss: 0.5894, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5828, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5496, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5532, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.4690, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.7838, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6283, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.7309, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6688, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.7022, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.5781, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.5970, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6015, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6678, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6500, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6428, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6925, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5630, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.8823, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.6223, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7224, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6019, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5349, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.7245, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6583, Accuracy: 0.6000\n",
      "Epoch : 055, Training: Loss - 0.6399, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6524, Accuracy - 69.0909%, Recall - 0.2000, Time: 78.3968s\n",
      "Epoch: 57/100\n",
      "Batch number: 000, Training: Loss: 0.5935, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5956, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5901, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5965, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5202, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6244, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6385, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5274, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7903, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6969, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5550, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5545, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6965, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.7324, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.6055, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.7173, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6196, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6569, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6250, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5188, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6428, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5280, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7275, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5888, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6290, Accuracy: 0.6667\n",
      "Epoch : 056, Training: Loss - 0.6228, Accuracy - 65.6642%, \n",
      "\t\tValidation : Loss - 0.6896, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.4505s\n",
      "Epoch: 58/100\n",
      "Batch number: 000, Training: Loss: 0.5760, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.8191, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.7955, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.5103, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6161, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5907, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5735, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5609, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6521, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5152, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6448, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6452, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5237, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6565, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5597, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6978, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5301, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6035, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.6930, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6480, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6072, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6914, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5629, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7673, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6432, Accuracy: 0.7333\n",
      "Epoch : 057, Training: Loss - 0.6273, Accuracy - 66.9173%, \n",
      "\t\tValidation : Loss - 0.6687, Accuracy - 69.0909%, Recall - 0.2000, Time: 78.5529s\n",
      "Epoch: 59/100\n",
      "Batch number: 000, Training: Loss: 0.4920, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5229, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6558, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6394, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6869, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.6425, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6745, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.7114, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5965, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6842, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6444, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.6847, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.5717, Accuracy: 0.8750\n",
      "Batch number: 013, Training: Loss: 0.6159, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6869, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.5277, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.9398, Accuracy: 0.2500\n",
      "Batch number: 017, Training: Loss: 0.6339, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6098, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6306, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.7274, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.4633, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.7741, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.6901, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6352, Accuracy: 0.5333\n",
      "Epoch : 058, Training: Loss - 0.6457, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6591, Accuracy - 65.4545%, Recall - 0.2000, Time: 86.0143s\n",
      "Epoch: 60/100\n",
      "Batch number: 000, Training: Loss: 0.7120, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5957, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5656, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6014, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.7009, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.5828, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.7113, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7105, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.5938, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6941, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6520, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7050, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6015, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.5624, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6604, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7735, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5867, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5789, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6208, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6034, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.4055, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5262, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.4491, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5997, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.7815, Accuracy: 0.5333\n",
      "Epoch : 059, Training: Loss - 0.6226, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.7098, Accuracy - 63.6364%, Recall - 0.0000, Time: 80.9350s\n",
      "Epoch: 61/100\n",
      "Batch number: 000, Training: Loss: 0.8299, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5372, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5597, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5309, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.6983, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.7247, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6071, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6371, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6222, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6234, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5590, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.5188, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6172, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6681, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5689, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6446, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.4817, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6534, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7409, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.4939, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5898, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6580, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6335, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7046, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.6633, Accuracy: 0.6000\n",
      "Epoch : 060, Training: Loss - 0.6225, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6732, Accuracy - 49.0909%, Recall - 0.3000, Time: 79.3604s\n",
      "Epoch: 62/100\n",
      "Batch number: 000, Training: Loss: 0.5761, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6352, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.7189, Accuracy: 0.3750\n",
      "Batch number: 003, Training: Loss: 0.6554, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6058, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6428, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6400, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6575, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6605, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.4674, Accuracy: 0.8750\n",
      "Batch number: 010, Training: Loss: 0.7365, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6298, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.7010, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6354, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.7241, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.7073, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.7200, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.6296, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6013, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7030, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.7111, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5851, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5109, Accuracy: 0.8750\n",
      "Batch number: 023, Training: Loss: 0.5976, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 1.0032, Accuracy: 0.3333\n",
      "Epoch : 061, Training: Loss - 0.6574, Accuracy - 60.9023%, \n",
      "\t\tValidation : Loss - 0.7299, Accuracy - 63.6364%, Recall - 0.0000, Time: 80.4499s\n",
      "Epoch: 63/100\n",
      "Batch number: 000, Training: Loss: 0.4422, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6271, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5956, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.8382, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5691, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.9189, Accuracy: 0.4375\n",
      "Batch number: 006, Training: Loss: 0.4719, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.7007, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.4928, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.5598, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6352, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6371, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5796, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6405, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6069, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5612, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6250, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6454, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.7560, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.6223, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5782, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.5576, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.7907, Accuracy: 0.3750\n",
      "Batch number: 023, Training: Loss: 0.7631, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.6815, Accuracy: 0.5333\n",
      "Epoch : 062, Training: Loss - 0.6358, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.6774, Accuracy - 54.5455%, Recall - 0.3500, Time: 79.0363s\n",
      "Epoch: 64/100\n",
      "Batch number: 000, Training: Loss: 0.6909, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.6384, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5106, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6030, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5365, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5730, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5977, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.4601, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6891, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.7461, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.7708, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6892, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.8237, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.7508, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5786, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6162, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6510, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6760, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6341, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6191, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5127, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.6630, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6257, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5867, Accuracy: 0.8125\n",
      "Batch number: 024, Training: Loss: 0.5727, Accuracy: 0.6667\n",
      "Epoch : 063, Training: Loss - 0.6328, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.6872, Accuracy - 63.6364%, Recall - 0.0000, Time: 79.2763s\n",
      "Epoch: 65/100\n",
      "Batch number: 000, Training: Loss: 0.5998, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7032, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.4841, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5868, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.4849, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.5496, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5242, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.7715, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5931, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6869, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6188, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6231, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7416, Accuracy: 0.3750\n",
      "Batch number: 013, Training: Loss: 0.6840, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6569, Accuracy: 0.3750\n",
      "Batch number: 015, Training: Loss: 0.7059, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6794, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6639, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5498, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.6945, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5796, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.6989, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6965, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5398, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.4666, Accuracy: 0.7333\n",
      "Epoch : 064, Training: Loss - 0.6237, Accuracy - 63.4085%, \n",
      "\t\tValidation : Loss - 0.7044, Accuracy - 63.6364%, Recall - 0.0000, Time: 79.3690s\n",
      "Epoch: 66/100\n",
      "Batch number: 000, Training: Loss: 0.4827, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6169, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6744, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.4623, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6580, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.4839, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5471, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5638, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.7570, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6586, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5410, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5631, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.7010, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6454, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.6301, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.5586, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.7856, Accuracy: 0.3125\n",
      "Batch number: 017, Training: Loss: 0.6048, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6291, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5939, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.7607, Accuracy: 0.3750\n",
      "Batch number: 021, Training: Loss: 0.6130, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6468, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7503, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.5980, Accuracy: 0.6000\n",
      "Epoch : 065, Training: Loss - 0.6211, Accuracy - 62.6566%, \n",
      "\t\tValidation : Loss - 0.6608, Accuracy - 58.1818%, Recall - 0.2000, Time: 79.0053s\n",
      "Epoch: 67/100\n",
      "Batch number: 000, Training: Loss: 0.5815, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6190, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.5781, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6972, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6284, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.7986, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.7152, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6691, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.5664, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.6080, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6561, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6119, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6927, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5172, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.6585, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.6821, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.4712, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.6220, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6817, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.4371, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.5328, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5670, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.7055, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7220, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6812, Accuracy: 0.6667\n",
      "Epoch : 066, Training: Loss - 0.6279, Accuracy - 64.6617%, \n",
      "\t\tValidation : Loss - 0.6714, Accuracy - 63.6364%, Recall - 0.0500, Time: 79.2149s\n",
      "Epoch: 68/100\n",
      "Batch number: 000, Training: Loss: 0.7162, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.7381, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6274, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6380, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6219, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6092, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.7856, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7163, Accuracy: 0.4375\n",
      "Batch number: 008, Training: Loss: 0.7098, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6983, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.7152, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.5996, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6184, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5553, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.4994, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.4680, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.9119, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6940, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.7032, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5250, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6537, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.4674, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6319, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5955, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5317, Accuracy: 0.6667\n",
      "Epoch : 067, Training: Loss - 0.6415, Accuracy - 63.1579%, \n",
      "\t\tValidation : Loss - 0.6684, Accuracy - 65.4545%, Recall - 0.2000, Time: 80.1808s\n",
      "Epoch: 69/100\n",
      "Batch number: 000, Training: Loss: 0.5291, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.7295, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6770, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6492, Accuracy: 0.4375\n",
      "Batch number: 004, Training: Loss: 0.5833, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6959, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.5937, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7432, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6015, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6407, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6019, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5785, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.6123, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6045, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6060, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.7033, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.4285, Accuracy: 0.8750\n",
      "Batch number: 017, Training: Loss: 0.6423, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.4837, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6080, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.7775, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5721, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6559, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6326, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.4767, Accuracy: 0.8000\n",
      "Epoch : 068, Training: Loss - 0.6174, Accuracy - 67.4185%, \n",
      "\t\tValidation : Loss - 0.6591, Accuracy - 63.6364%, Recall - 0.2000, Time: 79.1258s\n",
      "Epoch: 70/100\n",
      "Batch number: 000, Training: Loss: 0.6395, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.5896, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5621, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6953, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6458, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5643, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5973, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.5125, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.5586, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5731, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6333, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6408, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5880, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.6816, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5375, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.7380, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.5867, Accuracy: 0.8125\n",
      "Batch number: 017, Training: Loss: 0.5161, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.7206, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.7096, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5955, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5813, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.5480, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.5757, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.5713, Accuracy: 0.8000\n",
      "Epoch : 069, Training: Loss - 0.6066, Accuracy - 67.9198%, \n",
      "\t\tValidation : Loss - 0.6610, Accuracy - 61.8182%, Recall - 0.2000, Time: 79.0775s\n",
      "Epoch: 71/100\n",
      "Batch number: 000, Training: Loss: 0.5890, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6904, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.4764, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6099, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5733, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5872, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.4951, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6371, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6270, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5691, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5866, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5857, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.7765, Accuracy: 0.4375\n",
      "Batch number: 013, Training: Loss: 0.5601, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7062, Accuracy: 0.3125\n",
      "Batch number: 015, Training: Loss: 0.6438, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6924, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.6370, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5898, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6503, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.4845, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.9034, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.8201, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5563, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.8802, Accuracy: 0.3333\n",
      "Epoch : 070, Training: Loss - 0.6365, Accuracy - 63.1579%, \n",
      "\t\tValidation : Loss - 0.6623, Accuracy - 63.6364%, Recall - 0.2000, Time: 79.1885s\n",
      "Epoch: 72/100\n",
      "Batch number: 000, Training: Loss: 0.5234, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.4600, Accuracy: 0.8750\n",
      "Batch number: 002, Training: Loss: 0.4602, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.6384, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6076, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6391, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5582, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6826, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.7341, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5525, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.7309, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.7952, Accuracy: 0.4375\n",
      "Batch number: 012, Training: Loss: 0.7090, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6177, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6863, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6933, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.7152, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.6215, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5789, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5622, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6107, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.9499, Accuracy: 0.4375\n",
      "Batch number: 022, Training: Loss: 0.6405, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7671, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.8799, Accuracy: 0.5333\n",
      "Epoch : 071, Training: Loss - 0.6560, Accuracy - 62.9073%, \n",
      "\t\tValidation : Loss - 0.7435, Accuracy - 63.6364%, Recall - 0.0000, Time: 79.1666s\n",
      "Epoch: 73/100\n",
      "Batch number: 000, Training: Loss: 0.8057, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.5875, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7115, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6705, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.6050, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.6243, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6832, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6376, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.8258, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.6917, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6258, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.6467, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6635, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.5945, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.5905, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6247, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6374, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.8031, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5312, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5200, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.6738, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6735, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.6645, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.7346, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.4958, Accuracy: 0.8000\n",
      "Epoch : 072, Training: Loss - 0.6533, Accuracy - 64.4110%, \n",
      "\t\tValidation : Loss - 0.6658, Accuracy - 67.2727%, Recall - 0.1500, Time: 79.1371s\n",
      "Epoch: 74/100\n",
      "Batch number: 000, Training: Loss: 0.6260, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6197, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5758, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5778, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6766, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5561, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6252, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.6009, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.7728, Accuracy: 0.4375\n",
      "Batch number: 009, Training: Loss: 0.6276, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6855, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6534, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5952, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6547, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.7680, Accuracy: 0.3125\n",
      "Batch number: 015, Training: Loss: 0.7327, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.6879, Accuracy: 0.3750\n",
      "Batch number: 017, Training: Loss: 0.5973, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.6884, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.5687, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.6291, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5495, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.6643, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5848, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.4773, Accuracy: 0.8000\n",
      "Epoch : 073, Training: Loss - 0.6322, Accuracy - 62.4060%, \n",
      "\t\tValidation : Loss - 0.7293, Accuracy - 63.6364%, Recall - 0.0000, Time: 79.7874s\n",
      "Epoch: 75/100\n",
      "Batch number: 000, Training: Loss: 0.7366, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.7344, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.4945, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6482, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.7778, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.5991, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6591, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6040, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5755, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.7088, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.7349, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6806, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6895, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6627, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5720, Accuracy: 0.7500\n",
      "Batch number: 015, Training: Loss: 0.6666, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6114, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.9745, Accuracy: 0.3750\n",
      "Batch number: 018, Training: Loss: 0.5536, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5197, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4614, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.4708, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6827, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.8157, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6852, Accuracy: 0.6667\n",
      "Epoch : 074, Training: Loss - 0.6527, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6667, Accuracy - 65.4545%, Recall - 0.2000, Time: 79.2072s\n",
      "Epoch: 76/100\n",
      "Batch number: 000, Training: Loss: 0.7992, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.6236, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5960, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.7055, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6680, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6038, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5632, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.5195, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.4475, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6525, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 1.2426, Accuracy: 0.3125\n",
      "Batch number: 011, Training: Loss: 0.5334, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5414, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.7003, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.6455, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6068, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6444, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5727, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.6409, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6487, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6930, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.6621, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.6282, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7151, Accuracy: 0.4375\n",
      "Batch number: 024, Training: Loss: 0.5504, Accuracy: 0.8000\n",
      "Epoch : 075, Training: Loss - 0.6484, Accuracy - 63.4085%, \n",
      "\t\tValidation : Loss - 0.6660, Accuracy - 50.9091%, Recall - 0.2500, Time: 79.2334s\n",
      "Epoch: 77/100\n",
      "Batch number: 000, Training: Loss: 0.5771, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6810, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6698, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.4426, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.7583, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.7399, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.8968, Accuracy: 0.4375\n",
      "Batch number: 007, Training: Loss: 0.5342, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5334, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5493, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6083, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5578, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6439, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6616, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.7762, Accuracy: 0.3125\n",
      "Batch number: 015, Training: Loss: 0.6261, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.7539, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6099, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.6243, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.7261, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5071, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.5839, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5340, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6872, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 1.0563, Accuracy: 0.3333\n",
      "Epoch : 076, Training: Loss - 0.6526, Accuracy - 61.1529%, \n",
      "\t\tValidation : Loss - 0.7273, Accuracy - 63.6364%, Recall - 0.0000, Time: 80.2944s\n",
      "Epoch: 78/100\n",
      "Batch number: 000, Training: Loss: 0.7054, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.7133, Accuracy: 0.5000\n",
      "Batch number: 002, Training: Loss: 0.6300, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.6719, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.5362, Accuracy: 0.9375\n",
      "Batch number: 005, Training: Loss: 0.6772, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.7054, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.7113, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6348, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.6238, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.7053, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.6106, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.7950, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.8473, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.7507, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 0.4061, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.6544, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.4577, Accuracy: 0.9375\n",
      "Batch number: 018, Training: Loss: 0.6785, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6423, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5978, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5556, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5507, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.7525, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.4419, Accuracy: 0.9333\n",
      "Epoch : 077, Training: Loss - 0.6427, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6659, Accuracy - 63.6364%, Recall - 0.2000, Time: 79.2862s\n",
      "Epoch: 79/100\n",
      "Batch number: 000, Training: Loss: 0.5497, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.5788, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.4392, Accuracy: 0.8125\n",
      "Batch number: 003, Training: Loss: 0.5235, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6043, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6368, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6498, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7778, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.6678, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4899, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6282, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.4855, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5210, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6999, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6509, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.7526, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.6158, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.6067, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5860, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.6942, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.7214, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.5712, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.5824, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6988, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6596, Accuracy: 0.7333\n",
      "Epoch : 078, Training: Loss - 0.6156, Accuracy - 68.1704%, \n",
      "\t\tValidation : Loss - 0.6679, Accuracy - 61.8182%, Recall - 0.2000, Time: 79.4641s\n",
      "Epoch: 80/100\n",
      "Batch number: 000, Training: Loss: 0.5650, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6566, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6065, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.6721, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.5988, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.7325, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6813, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5622, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5656, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.5623, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.5384, Accuracy: 0.8750\n",
      "Batch number: 011, Training: Loss: 0.5277, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.5791, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.7068, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.7865, Accuracy: 0.4375\n",
      "Batch number: 015, Training: Loss: 0.8672, Accuracy: 0.4375\n",
      "Batch number: 016, Training: Loss: 0.7240, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.4771, Accuracy: 0.8125\n",
      "Batch number: 018, Training: Loss: 0.5815, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5858, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.5456, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.5442, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5758, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.4693, Accuracy: 0.8750\n",
      "Batch number: 024, Training: Loss: 0.5852, Accuracy: 0.7333\n",
      "Epoch : 079, Training: Loss - 0.6120, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6663, Accuracy - 56.3636%, Recall - 0.2000, Time: 79.2478s\n",
      "Epoch: 81/100\n",
      "Batch number: 000, Training: Loss: 0.7875, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.5957, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6415, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5230, Accuracy: 0.8750\n",
      "Batch number: 004, Training: Loss: 0.5995, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6583, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.7948, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.6250, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5592, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5601, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.4990, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.5118, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.4833, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.7031, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6420, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6326, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.7677, Accuracy: 0.4375\n",
      "Batch number: 017, Training: Loss: 0.5595, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6534, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5809, Accuracy: 0.6250\n",
      "Batch number: 020, Training: Loss: 0.6934, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.6288, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5600, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6008, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.7186, Accuracy: 0.4000\n",
      "Epoch : 080, Training: Loss - 0.6230, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6787, Accuracy - 54.5455%, Recall - 0.3500, Time: 78.7177s\n",
      "Epoch: 82/100\n",
      "Batch number: 000, Training: Loss: 0.6785, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5529, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.5751, Accuracy: 0.7500\n",
      "Batch number: 003, Training: Loss: 0.5045, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.4791, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.5945, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.5680, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.6409, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.5876, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.7029, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.9163, Accuracy: 0.5000\n",
      "Batch number: 011, Training: Loss: 0.6017, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5715, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5391, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6285, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6196, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6617, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6431, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5786, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.6681, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6806, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.7701, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.7506, Accuracy: 0.4375\n",
      "Batch number: 023, Training: Loss: 0.5465, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6354, Accuracy: 0.5333\n",
      "Epoch : 081, Training: Loss - 0.6278, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.6714, Accuracy - 67.2727%, Recall - 0.2000, Time: 78.4704s\n",
      "Epoch: 83/100\n",
      "Batch number: 000, Training: Loss: 0.5325, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5162, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.3728, Accuracy: 0.9375\n",
      "Batch number: 003, Training: Loss: 0.6866, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5415, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.8140, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6157, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7028, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.8470, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.6177, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6969, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.6361, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.6894, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.7111, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.7150, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.6828, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6009, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7310, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.6675, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.4923, Accuracy: 0.8750\n",
      "Batch number: 020, Training: Loss: 0.5302, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.5715, Accuracy: 0.6875\n",
      "Batch number: 022, Training: Loss: 0.5472, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.5167, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 1.2090, Accuracy: 0.3333\n",
      "Epoch : 082, Training: Loss - 0.6484, Accuracy - 63.4085%, \n",
      "\t\tValidation : Loss - 0.7117, Accuracy - 63.6364%, Recall - 0.0500, Time: 78.6070s\n",
      "Epoch: 84/100\n",
      "Batch number: 000, Training: Loss: 0.5458, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.6724, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.5148, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5865, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.4715, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.7395, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.7103, Accuracy: 0.5000\n",
      "Batch number: 007, Training: Loss: 0.5601, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6457, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5818, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6509, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.5930, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5883, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6807, Accuracy: 0.5000\n",
      "Batch number: 014, Training: Loss: 0.5279, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.7080, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6299, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.7926, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6912, Accuracy: 0.5625\n",
      "Batch number: 019, Training: Loss: 0.6883, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.8150, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.4428, Accuracy: 0.9375\n",
      "Batch number: 022, Training: Loss: 0.5737, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5981, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6470, Accuracy: 0.7333\n",
      "Epoch : 083, Training: Loss - 0.6262, Accuracy - 64.1604%, \n",
      "\t\tValidation : Loss - 0.6820, Accuracy - 52.7273%, Recall - 0.3500, Time: 78.9567s\n",
      "Epoch: 85/100\n",
      "Batch number: 000, Training: Loss: 0.6808, Accuracy: 0.5000\n",
      "Batch number: 001, Training: Loss: 0.5472, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6391, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5794, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6034, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.6495, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6448, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6973, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.4833, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.6579, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5439, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.7507, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.7209, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.6049, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.6101, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5895, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6253, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5943, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5985, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.5034, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4726, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.7201, Accuracy: 0.5000\n",
      "Batch number: 022, Training: Loss: 0.5697, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.5796, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.8062, Accuracy: 0.6000\n",
      "Epoch : 084, Training: Loss - 0.6184, Accuracy - 65.9148%, \n",
      "\t\tValidation : Loss - 0.7000, Accuracy - 63.6364%, Recall - 0.0500, Time: 79.0147s\n",
      "Epoch: 86/100\n",
      "Batch number: 000, Training: Loss: 0.4425, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5559, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6451, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.8163, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.5836, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5403, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5971, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5071, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.6870, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.5150, Accuracy: 0.8125\n",
      "Batch number: 010, Training: Loss: 0.6463, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.7022, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6374, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.7422, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5357, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.6169, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.6312, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6006, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5187, Accuracy: 0.8750\n",
      "Batch number: 019, Training: Loss: 0.6769, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.5158, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5276, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.7222, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7157, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6044, Accuracy: 0.6667\n",
      "Epoch : 085, Training: Loss - 0.6114, Accuracy - 68.4211%, \n",
      "\t\tValidation : Loss - 0.6824, Accuracy - 65.4545%, Recall - 0.1500, Time: 78.7128s\n",
      "Epoch: 87/100\n",
      "Batch number: 000, Training: Loss: 0.7603, Accuracy: 0.3750\n",
      "Batch number: 001, Training: Loss: 0.5072, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6040, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5889, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5716, Accuracy: 0.8750\n",
      "Batch number: 005, Training: Loss: 0.6614, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.5472, Accuracy: 0.8125\n",
      "Batch number: 007, Training: Loss: 0.6794, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6807, Accuracy: 0.7500\n",
      "Batch number: 009, Training: Loss: 0.5570, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.6579, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5202, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.7152, Accuracy: 0.6250\n",
      "Batch number: 013, Training: Loss: 0.7399, Accuracy: 0.6875\n",
      "Batch number: 014, Training: Loss: 0.5563, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.6023, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.6895, Accuracy: 0.5625\n",
      "Batch number: 017, Training: Loss: 0.5729, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.8371, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.6669, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.6084, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.5943, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5874, Accuracy: 0.5000\n",
      "Batch number: 023, Training: Loss: 0.6280, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.5917, Accuracy: 0.7333\n",
      "Epoch : 086, Training: Loss - 0.6291, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.6720, Accuracy - 58.1818%, Recall - 0.2000, Time: 78.7107s\n",
      "Epoch: 88/100\n",
      "Batch number: 000, Training: Loss: 0.7837, Accuracy: 0.4375\n",
      "Batch number: 001, Training: Loss: 0.5695, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.7790, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7068, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.7190, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.6862, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6002, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5461, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.6634, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5820, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5832, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.4342, Accuracy: 0.8750\n",
      "Batch number: 012, Training: Loss: 0.5034, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.8144, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.4579, Accuracy: 0.8125\n",
      "Batch number: 015, Training: Loss: 0.4431, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.7462, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5397, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.8035, Accuracy: 0.5000\n",
      "Batch number: 019, Training: Loss: 0.7541, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.7836, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.4822, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.5668, Accuracy: 0.6875\n",
      "Batch number: 023, Training: Loss: 0.6387, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.7063, Accuracy: 0.4000\n",
      "Epoch : 087, Training: Loss - 0.6356, Accuracy - 64.1604%, \n",
      "\t\tValidation : Loss - 0.6949, Accuracy - 49.0909%, Recall - 0.5000, Time: 79.7799s\n",
      "Epoch: 89/100\n",
      "Batch number: 000, Training: Loss: 0.7075, Accuracy: 0.3750\n",
      "Batch number: 001, Training: Loss: 0.6824, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.6862, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.6086, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.5379, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5640, Accuracy: 0.6875\n",
      "Batch number: 006, Training: Loss: 0.6120, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6479, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.5760, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.4631, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.8022, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.4903, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.8231, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.6195, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.3945, Accuracy: 0.9375\n",
      "Batch number: 015, Training: Loss: 0.6068, Accuracy: 0.5625\n",
      "Batch number: 016, Training: Loss: 0.6670, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5895, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.5462, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.7009, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.7397, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.5666, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.6751, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7951, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.5559, Accuracy: 0.8000\n",
      "Epoch : 088, Training: Loss - 0.6265, Accuracy - 64.1604%, \n",
      "\t\tValidation : Loss - 0.6860, Accuracy - 49.0909%, Recall - 0.3500, Time: 78.4914s\n",
      "Epoch: 90/100\n",
      "Batch number: 000, Training: Loss: 0.6809, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6554, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5723, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.5515, Accuracy: 0.7500\n",
      "Batch number: 004, Training: Loss: 0.6183, Accuracy: 0.5625\n",
      "Batch number: 005, Training: Loss: 0.4940, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.6852, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.4367, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.7788, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.8264, Accuracy: 0.4375\n",
      "Batch number: 010, Training: Loss: 0.6888, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.5744, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.5702, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.6174, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.7154, Accuracy: 0.3125\n",
      "Batch number: 015, Training: Loss: 0.6639, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.6363, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5290, Accuracy: 0.8750\n",
      "Batch number: 018, Training: Loss: 0.5473, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6329, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.5328, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6037, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.5576, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.5515, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6432, Accuracy: 0.6667\n",
      "Epoch : 089, Training: Loss - 0.6145, Accuracy - 64.1604%, \n",
      "\t\tValidation : Loss - 0.7107, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.4770s\n",
      "Epoch: 91/100\n",
      "Batch number: 000, Training: Loss: 0.4760, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.6720, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.7705, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.5094, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.7729, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.6974, Accuracy: 0.5625\n",
      "Batch number: 006, Training: Loss: 0.6121, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.6505, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6299, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.6283, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.7489, Accuracy: 0.4375\n",
      "Batch number: 011, Training: Loss: 0.5844, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.5002, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.6257, Accuracy: 0.6250\n",
      "Batch number: 014, Training: Loss: 0.5554, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6188, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.5745, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.5127, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.4367, Accuracy: 0.8125\n",
      "Batch number: 019, Training: Loss: 0.8709, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.9018, Accuracy: 0.5000\n",
      "Batch number: 021, Training: Loss: 0.7832, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.7751, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.5730, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.6712, Accuracy: 0.6000\n",
      "Epoch : 090, Training: Loss - 0.6460, Accuracy - 63.4085%, \n",
      "\t\tValidation : Loss - 0.6805, Accuracy - 56.3636%, Recall - 0.2500, Time: 78.7718s\n",
      "Epoch: 92/100\n",
      "Batch number: 000, Training: Loss: 0.6234, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6073, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.7077, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.6778, Accuracy: 0.5625\n",
      "Batch number: 004, Training: Loss: 0.6854, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5054, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.5764, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5580, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.6897, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.6500, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.5490, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.7264, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.5273, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.7625, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.7542, Accuracy: 0.5000\n",
      "Batch number: 015, Training: Loss: 0.4724, Accuracy: 0.8750\n",
      "Batch number: 016, Training: Loss: 0.6463, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6142, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5550, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.7004, Accuracy: 0.5000\n",
      "Batch number: 020, Training: Loss: 0.7071, Accuracy: 0.4375\n",
      "Batch number: 021, Training: Loss: 0.5556, Accuracy: 0.8125\n",
      "Batch number: 022, Training: Loss: 0.5524, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.6102, Accuracy: 0.6875\n",
      "Batch number: 024, Training: Loss: 0.6145, Accuracy: 0.7333\n",
      "Epoch : 091, Training: Loss - 0.6252, Accuracy - 64.4110%, \n",
      "\t\tValidation : Loss - 0.6755, Accuracy - 61.8182%, Recall - 0.2000, Time: 78.4755s\n",
      "Epoch: 93/100\n",
      "Batch number: 000, Training: Loss: 0.5536, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.8255, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.7931, Accuracy: 0.3750\n",
      "Batch number: 003, Training: Loss: 0.4733, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6840, Accuracy: 0.5000\n",
      "Batch number: 005, Training: Loss: 0.4365, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.5037, Accuracy: 0.8750\n",
      "Batch number: 007, Training: Loss: 0.7275, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.5325, Accuracy: 0.8125\n",
      "Batch number: 009, Training: Loss: 0.7303, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.4679, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6049, Accuracy: 0.6875\n",
      "Batch number: 012, Training: Loss: 0.6570, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.7520, Accuracy: 0.5625\n",
      "Batch number: 014, Training: Loss: 0.5770, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.6042, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.6008, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.6195, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.5810, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.6257, Accuracy: 0.7500\n",
      "Batch number: 020, Training: Loss: 0.4967, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.6391, Accuracy: 0.6250\n",
      "Batch number: 022, Training: Loss: 0.4658, Accuracy: 0.8125\n",
      "Batch number: 023, Training: Loss: 0.9152, Accuracy: 0.5000\n",
      "Batch number: 024, Training: Loss: 0.6742, Accuracy: 0.5333\n",
      "Epoch : 092, Training: Loss - 0.6215, Accuracy - 65.4135%, \n",
      "\t\tValidation : Loss - 0.7239, Accuracy - 63.6364%, Recall - 0.0000, Time: 78.6082s\n",
      "Epoch: 94/100\n",
      "Batch number: 000, Training: Loss: 0.5363, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5776, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6200, Accuracy: 0.6875\n",
      "Batch number: 003, Training: Loss: 0.7682, Accuracy: 0.5000\n",
      "Batch number: 004, Training: Loss: 0.7917, Accuracy: 0.4375\n",
      "Batch number: 005, Training: Loss: 0.6260, Accuracy: 0.6250\n",
      "Batch number: 006, Training: Loss: 0.6613, Accuracy: 0.6250\n",
      "Batch number: 007, Training: Loss: 0.7874, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6850, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.7024, Accuracy: 0.5000\n",
      "Batch number: 010, Training: Loss: 0.6832, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6212, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6225, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5584, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.6051, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.5818, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.5724, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.5888, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.4695, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 1.0069, Accuracy: 0.4375\n",
      "Batch number: 020, Training: Loss: 0.7222, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.4643, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.6379, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6337, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5496, Accuracy: 0.8000\n",
      "Epoch : 093, Training: Loss - 0.6432, Accuracy - 63.9098%, \n",
      "\t\tValidation : Loss - 0.6730, Accuracy - 58.1818%, Recall - 0.2000, Time: 78.3587s\n",
      "Epoch: 95/100\n",
      "Batch number: 000, Training: Loss: 0.6721, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6171, Accuracy: 0.5625\n",
      "Batch number: 002, Training: Loss: 0.5934, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6905, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.5406, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.4938, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6449, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.5661, Accuracy: 0.6875\n",
      "Batch number: 008, Training: Loss: 0.6648, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.6273, Accuracy: 0.6250\n",
      "Batch number: 010, Training: Loss: 0.6932, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.4290, Accuracy: 0.8125\n",
      "Batch number: 012, Training: Loss: 0.4919, Accuracy: 0.8125\n",
      "Batch number: 013, Training: Loss: 0.4188, Accuracy: 0.8750\n",
      "Batch number: 014, Training: Loss: 0.7063, Accuracy: 0.5625\n",
      "Batch number: 015, Training: Loss: 1.1209, Accuracy: 0.3125\n",
      "Batch number: 016, Training: Loss: 0.6019, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.7679, Accuracy: 0.5000\n",
      "Batch number: 018, Training: Loss: 0.5561, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.7186, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.5501, Accuracy: 0.8750\n",
      "Batch number: 021, Training: Loss: 0.5801, Accuracy: 0.7500\n",
      "Batch number: 022, Training: Loss: 0.8053, Accuracy: 0.3125\n",
      "Batch number: 023, Training: Loss: 0.7149, Accuracy: 0.6250\n",
      "Batch number: 024, Training: Loss: 0.7326, Accuracy: 0.6000\n",
      "Epoch : 094, Training: Loss - 0.6397, Accuracy - 64.6617%, \n",
      "\t\tValidation : Loss - 0.7330, Accuracy - 52.7273%, Recall - 0.7500, Time: 78.5289s\n",
      "Epoch: 96/100\n",
      "Batch number: 000, Training: Loss: 0.5680, Accuracy: 0.8125\n",
      "Batch number: 001, Training: Loss: 0.5890, Accuracy: 0.7500\n",
      "Batch number: 002, Training: Loss: 0.6584, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.7742, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.5667, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.6496, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.7709, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.4609, Accuracy: 0.8125\n",
      "Batch number: 008, Training: Loss: 0.7196, Accuracy: 0.6250\n",
      "Batch number: 009, Training: Loss: 0.5268, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.6581, Accuracy: 0.5625\n",
      "Batch number: 011, Training: Loss: 0.4633, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 1.0512, Accuracy: 0.3125\n",
      "Batch number: 013, Training: Loss: 0.8159, Accuracy: 0.4375\n",
      "Batch number: 014, Training: Loss: 0.5052, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.5533, Accuracy: 0.8125\n",
      "Batch number: 016, Training: Loss: 0.7004, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6103, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6589, Accuracy: 0.6250\n",
      "Batch number: 019, Training: Loss: 0.5712, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6823, Accuracy: 0.6875\n",
      "Batch number: 021, Training: Loss: 0.8173, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.8943, Accuracy: 0.3750\n",
      "Batch number: 023, Training: Loss: 0.5678, Accuracy: 0.7500\n",
      "Batch number: 024, Training: Loss: 0.6486, Accuracy: 0.8000\n",
      "Epoch : 095, Training: Loss - 0.6593, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6697, Accuracy - 61.8182%, Recall - 0.2000, Time: 79.4597s\n",
      "Epoch: 97/100\n",
      "Batch number: 000, Training: Loss: 0.7101, Accuracy: 0.5625\n",
      "Batch number: 001, Training: Loss: 0.6128, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.6610, Accuracy: 0.5625\n",
      "Batch number: 003, Training: Loss: 0.5464, Accuracy: 0.8125\n",
      "Batch number: 004, Training: Loss: 0.6801, Accuracy: 0.6250\n",
      "Batch number: 005, Training: Loss: 0.5390, Accuracy: 0.7500\n",
      "Batch number: 006, Training: Loss: 0.5922, Accuracy: 0.6875\n",
      "Batch number: 007, Training: Loss: 0.7207, Accuracy: 0.5625\n",
      "Batch number: 008, Training: Loss: 0.7110, Accuracy: 0.5625\n",
      "Batch number: 009, Training: Loss: 0.5484, Accuracy: 0.6875\n",
      "Batch number: 010, Training: Loss: 0.5336, Accuracy: 0.6250\n",
      "Batch number: 011, Training: Loss: 0.6542, Accuracy: 0.6250\n",
      "Batch number: 012, Training: Loss: 0.5287, Accuracy: 0.6875\n",
      "Batch number: 013, Training: Loss: 0.5222, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6541, Accuracy: 0.6250\n",
      "Batch number: 015, Training: Loss: 0.5996, Accuracy: 0.5000\n",
      "Batch number: 016, Training: Loss: 0.5794, Accuracy: 0.6875\n",
      "Batch number: 017, Training: Loss: 0.6043, Accuracy: 0.6250\n",
      "Batch number: 018, Training: Loss: 0.6538, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5479, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.5543, Accuracy: 0.7500\n",
      "Batch number: 021, Training: Loss: 0.6520, Accuracy: 0.5625\n",
      "Batch number: 022, Training: Loss: 0.6059, Accuracy: 0.7500\n",
      "Batch number: 023, Training: Loss: 0.6942, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.5558, Accuracy: 0.7333\n",
      "Epoch : 096, Training: Loss - 0.6106, Accuracy - 65.1629%, \n",
      "\t\tValidation : Loss - 0.6663, Accuracy - 60.0000%, Recall - 0.2000, Time: 78.7130s\n",
      "Epoch: 98/100\n",
      "Batch number: 000, Training: Loss: 0.6632, Accuracy: 0.6875\n",
      "Batch number: 001, Training: Loss: 0.5922, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6184, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.5521, Accuracy: 0.6250\n",
      "Batch number: 004, Training: Loss: 0.6057, Accuracy: 0.7500\n",
      "Batch number: 005, Training: Loss: 0.5269, Accuracy: 0.8125\n",
      "Batch number: 006, Training: Loss: 0.7205, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.6950, Accuracy: 0.5000\n",
      "Batch number: 008, Training: Loss: 0.6925, Accuracy: 0.5000\n",
      "Batch number: 009, Training: Loss: 0.6568, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.6554, Accuracy: 0.6875\n",
      "Batch number: 011, Training: Loss: 0.5897, Accuracy: 0.7500\n",
      "Batch number: 012, Training: Loss: 0.6122, Accuracy: 0.7500\n",
      "Batch number: 013, Training: Loss: 0.5021, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6247, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.4860, Accuracy: 0.6875\n",
      "Batch number: 016, Training: Loss: 0.8602, Accuracy: 0.5000\n",
      "Batch number: 017, Training: Loss: 0.6511, Accuracy: 0.6875\n",
      "Batch number: 018, Training: Loss: 0.5054, Accuracy: 0.7500\n",
      "Batch number: 019, Training: Loss: 0.7130, Accuracy: 0.5625\n",
      "Batch number: 020, Training: Loss: 0.6492, Accuracy: 0.6250\n",
      "Batch number: 021, Training: Loss: 0.4671, Accuracy: 0.8750\n",
      "Batch number: 022, Training: Loss: 0.7729, Accuracy: 0.5625\n",
      "Batch number: 023, Training: Loss: 0.7967, Accuracy: 0.3750\n",
      "Batch number: 024, Training: Loss: 0.5703, Accuracy: 0.6667\n",
      "Epoch : 097, Training: Loss - 0.6313, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6681, Accuracy - 60.0000%, Recall - 0.2000, Time: 78.7585s\n",
      "Epoch: 99/100\n",
      "Batch number: 000, Training: Loss: 0.6751, Accuracy: 0.6250\n",
      "Batch number: 001, Training: Loss: 0.6019, Accuracy: 0.6250\n",
      "Batch number: 002, Training: Loss: 0.7531, Accuracy: 0.5000\n",
      "Batch number: 003, Training: Loss: 0.5396, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6195, Accuracy: 0.8125\n",
      "Batch number: 005, Training: Loss: 0.6650, Accuracy: 0.5000\n",
      "Batch number: 006, Training: Loss: 0.6645, Accuracy: 0.7500\n",
      "Batch number: 007, Training: Loss: 0.5539, Accuracy: 0.6250\n",
      "Batch number: 008, Training: Loss: 0.5498, Accuracy: 0.8750\n",
      "Batch number: 009, Training: Loss: 0.6447, Accuracy: 0.5625\n",
      "Batch number: 010, Training: Loss: 0.5500, Accuracy: 0.8125\n",
      "Batch number: 011, Training: Loss: 0.6986, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.6610, Accuracy: 0.5000\n",
      "Batch number: 013, Training: Loss: 0.4756, Accuracy: 0.8125\n",
      "Batch number: 014, Training: Loss: 0.4540, Accuracy: 0.8750\n",
      "Batch number: 015, Training: Loss: 0.6896, Accuracy: 0.6250\n",
      "Batch number: 016, Training: Loss: 0.4552, Accuracy: 0.7500\n",
      "Batch number: 017, Training: Loss: 0.7274, Accuracy: 0.5625\n",
      "Batch number: 018, Training: Loss: 0.8497, Accuracy: 0.4375\n",
      "Batch number: 019, Training: Loss: 0.5344, Accuracy: 0.6875\n",
      "Batch number: 020, Training: Loss: 0.4817, Accuracy: 0.8125\n",
      "Batch number: 021, Training: Loss: 0.7025, Accuracy: 0.4375\n",
      "Batch number: 022, Training: Loss: 0.6732, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.7066, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.6672, Accuracy: 0.6000\n",
      "Epoch : 098, Training: Loss - 0.6236, Accuracy - 64.9123%, \n",
      "\t\tValidation : Loss - 0.6821, Accuracy - 50.9091%, Recall - 0.3000, Time: 78.6273s\n",
      "Epoch: 100/100\n",
      "Batch number: 000, Training: Loss: 0.5582, Accuracy: 0.7500\n",
      "Batch number: 001, Training: Loss: 0.6342, Accuracy: 0.6875\n",
      "Batch number: 002, Training: Loss: 0.6484, Accuracy: 0.6250\n",
      "Batch number: 003, Training: Loss: 0.6643, Accuracy: 0.6875\n",
      "Batch number: 004, Training: Loss: 0.6771, Accuracy: 0.6875\n",
      "Batch number: 005, Training: Loss: 0.5734, Accuracy: 0.8750\n",
      "Batch number: 006, Training: Loss: 0.6170, Accuracy: 0.5625\n",
      "Batch number: 007, Training: Loss: 0.5363, Accuracy: 0.7500\n",
      "Batch number: 008, Training: Loss: 0.5643, Accuracy: 0.6875\n",
      "Batch number: 009, Training: Loss: 0.5709, Accuracy: 0.7500\n",
      "Batch number: 010, Training: Loss: 0.5683, Accuracy: 0.7500\n",
      "Batch number: 011, Training: Loss: 0.7184, Accuracy: 0.5625\n",
      "Batch number: 012, Training: Loss: 0.8313, Accuracy: 0.5625\n",
      "Batch number: 013, Training: Loss: 0.4449, Accuracy: 0.7500\n",
      "Batch number: 014, Training: Loss: 0.6776, Accuracy: 0.6875\n",
      "Batch number: 015, Training: Loss: 0.6192, Accuracy: 0.7500\n",
      "Batch number: 016, Training: Loss: 0.5674, Accuracy: 0.6250\n",
      "Batch number: 017, Training: Loss: 0.5601, Accuracy: 0.7500\n",
      "Batch number: 018, Training: Loss: 0.5814, Accuracy: 0.6875\n",
      "Batch number: 019, Training: Loss: 0.5968, Accuracy: 0.8125\n",
      "Batch number: 020, Training: Loss: 0.6495, Accuracy: 0.5625\n",
      "Batch number: 021, Training: Loss: 0.7025, Accuracy: 0.3750\n",
      "Batch number: 022, Training: Loss: 0.6956, Accuracy: 0.6250\n",
      "Batch number: 023, Training: Loss: 0.6584, Accuracy: 0.5625\n",
      "Batch number: 024, Training: Loss: 0.7138, Accuracy: 0.5333\n",
      "Epoch : 099, Training: Loss - 0.6249, Accuracy - 66.6667%, \n",
      "\t\tValidation : Loss - 0.6976, Accuracy - 52.7273%, Recall - 0.5500, Time: 78.6764s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "trained_model, history, best_epoch = train_and_validate_for_custom_networks(model, loss_func, optimizer, num_epochs)\n",
    "torch.save(history, '_torchvisiontransferlearning_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "P1A-sUyqjjCB"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Train Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "NydMKQl1jjCB"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Train Accuracy', 'Validation Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G31a6eUsjjCB"
   },
   "source": [
    "####fine tuning (ultima conv + fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "62GAbyNzjjCB"
   },
   "outputs": [],
   "source": [
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-chex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "cBee7OxmjjCB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XRV-DenseNet121-densenet121-res224-chex\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KSOGfRfWjjCB"
   },
   "outputs": [],
   "source": [
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 2),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "HyDUhbhmjjCB"
   },
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "hvtV06cIjjCB"
   },
   "outputs": [],
   "source": [
    "#freeze todos os parametros\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#menos os ultimos\n",
    "for name, param in model.named_parameters():\n",
    "    if \"features.denseblock4\" in name or \"features.norm5\" in name or \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ShpjDBMJjjCB"
   },
   "outputs": [],
   "source": [
    "params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(params_to_update, lr=1e-4)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "I77cTfmejjCB"
   },
   "outputs": [],
   "source": [
    "model = DenseNetWrapper(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yq0urGoAjjCB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_and_validate_for_custom_networks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m----> 2\u001b[0m trained_model, history, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate_for_custom_networks\u001b[49m(model, loss_fn, optimizer, num_epochs)\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(history, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_torchvisionfinetuning_history.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_and_validate_for_custom_networks' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 12\n",
    "trained_model, history, best_epoch = train_and_validate_for_custom_networks(model, loss_fn, optimizer, num_epochs)\n",
    "torch.save(history, '_torchvisionfinetuning_history.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "tr2E7ZvXjjCC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Train Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "Rnft5M_WjjCC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAf5BJREFUeJztnQd4U/X3xg+ltFCgrLL33nsvEUFQFGQoQ5QhiiIqiBMVFBVQVFwguAD/KoL4AwQRkL03lFn2nmUXCrTQ9v+835tvepMmbTrT3r6f5wlNbm5yR0vum3Pec06WmJiYGCGEEEIIsQg+3t4BQgghhJCUhOKGEEIIIZaC4oYQQgghloLihhBCCCGWguKGEEIIIZaC4oYQQgghloLihhBCCCGWguKGEEIIIZaC4oYQQgghloLihhBCCCGWwqviZvXq1dKxY0cpVqyYZMmSRebOnZvga1auXCn16tUTf39/qVChgkybNi1N9pUQQgghGQOvipvw8HCpXbu2TJw40aP1jx07Jo888oi0bt1agoODZejQofLss8/K4sWLU31fCSGEEJIxyJJeBmcicjNnzhzp3Lmz23XeeustWbBggezZs8e+rGfPnnLt2jVZtGhRGu0pIYQQQtIzvpKB2LBhg7Rt29ZhWfv27VUExx0RERHqpomOjpYrV65IgQIFlKAihBBCSPoHsZgbN24oK4uPj491xM358+elcOHCDsvwOCwsTG7fvi05cuSI85qxY8fKqFGj0nAvCSGEEJJanDp1SkqUKGEdcZMUhg8fLsOGDbM/vn79upQqVUqdnMDAQK/uGyGEEEI8A4GMkiVLSu7cuRNcN0OJmyJFisiFCxccluExRIqrqA1AVRVuzuA1FDeEEEJIxsITS0mG6nPTtGlTWbZsmcOyJUuWqOWEEEIIIV4XNzdv3lQl3bjpUm/cP3nypD2l1KdPH/v6L7zwghw9elTefPNN2b9/v3z33Xfy559/yquvvuq1YyCEEEJI+sKr4mbr1q1St25ddQPwxuD+yJEj1eNz587ZhQ4oW7asKgVHtAb9cb744gv56aefVMUUIYQQQki66nOTloakPHnyKGNxfJ6bqKgouXv3bpruGyFpQbZs2SRr1qze3g1CCEmV63eGMxSnBdB6KDlHY0BCrErevHmVQZ+9ngghVoTixgktbAoVKiQBAQH88CeWE++3bt2S0NBQ9bho0aLe3iVCCElxKG6cUlFa2KCDMSFWRLdNgMDB3zpTVIQQq5GhSsFTG+2xQcSGECuj/8bpKyOE/LXttDz3f1slNOyOWAWKGxcwFUWsDv/GCfEeK/aHSvfJG2T1wYve3hU5deWWvDNntyzZd0Fe/2uXSl1bAYobQgghJI2Ytu6YDPhli2w+fkVG/L1HoqK9KyZGLwiRyHvR6j7E1v9tOCFWgOKGuKVMmTLy1VdfeXs3CCHEI2ZsPim1R/0nW45fkfQGRMwH8/bKB/P3CfSMTxaRE5dvyfL9hrk/JbkbZYiVhFh3+JIs2ntesvpkkb5NS6tlY/4NkUMXbtjXuRV5T6K9LMCSAsWNRVIM8d0++OCDJL3vli1bZODAgSmyj3/88Ycyrg4ePDhF3o8QEj837ty1fyPPDNy5GyWf/3dArt++K9PWH5f0xjuzd9v3662Hqshz95VT96esPZai2xn7b4hUem+hPPrtGvl88QHZduKKy1TTvahoGTV/r7r/dJPS8kGn6nJfpYIScS9ahswIli+XHJTHJq6T6u8vlp4/bpQr4ZHxbhfnPT1BcWMB0MlZ3xBpQXMj87LXX3/dvi7+yO/du+fR+xYsWDDFzNU///yzGpsBkXPnjndNa5GR8f8nJSSjc/xSuDQcvVRe+WOHWBEYX6/dcvx/PH/nWbl001i2cn+oEjvuCLtzV85dvy1pxcLd52Tm1lMqWjPxyXoy6P7y0rdpGRUx2XD0suw9ez3FtvXvnnMCLbPnTJhMWHFYuk3aIC/+vl1uRzqej982npCDF25KvoBs8mrbSuqL8GeP15K8Adlk37kw+XrZIdl56pp6r83HrkiX79bJkYs3XW7z+1VHVMRs2Mxgibjn/rynJRQ3FgDN2PQN3RvxR6ofYwYXxsMvXLhQ6tevryakr127Vo4cOSKPPfaYFC5cWHLlyiUNGzaUpUuXxpuWwvti3EWXLl2U6KlYsaLMmzcvwf3DzLD169fL22+/LZUqVZLZs2fHWWfKlClSvXp1tX/ovfLSSy/Zn0N5/vPPP6/2NXv27FKjRg35559/1HOIStWpU8fhvbDP2HdNv379pHPnzjJ69GgpVqyYVK5cWS3/9ddfpUGDBur84Fw9+eST9v4vmr1798qjjz6qBCPWa9mypTp3q1evVp1+0RfJzNChQ9U6hHiTZeriHq1SDkfdXJAyKpdvRkib8auk/Ver1X39pW3KuthoTXhklEq5uAKip+t366X15yvl5OVbqb6/F8LuyPA5u9V9iJpHahm9pYrlzSEP1yii7k817XtyuBlxT05dMUTbR49Vl0drFRW/rD6ycM95FX0JvXFHRfTGLgyRMf/uV+u93r6y5AnIpu4XDswuX/WoI+WCcqp9G9etlswc2ERK5MuhUmg4bxuOXI5jSB6/5KC6P3vHGXn6p81yNYEoT1pAceNJ07PIe165paRrHcLik08+kZCQEKlVq5YaWtqhQwc1ZX3Hjh3y0EMPSceOHR1mebli1KhR0r17d9m1a5d6fe/eveXKlfjz21OnTpVHHnlECa+nnnpKRXHMTJo0SaWrkALbvXu3EkwVKlRQz0VHR8vDDz8s69atk99++0327dunjiOxvVlwnAcOHFBzybQwQhn0Rx99JDt37pS5c+fK8ePHlRDSnDlzRu677z4luJYvXy7btm2TZ555RkW+sLxcuXJKIGnwfr///rtahxBvstXkOflz6+lU3daaQxflkk1kpAX/7bsgN+7ckwthEfL27N3qc3Lj0SsSci5McmTLKo/VKabWW7zX8YuH5ue1x+Rw6E0l/mbvSN1zA6/K67N2yrVbd6VG8UAZ0qaSw/PPtCirfs4LPisXb8R/DpFGwjEdvHDD7bUBz4GCuf3l6aZlZMKT9eTXAY1UNAZRmM4T1ilR9/2qoxIZFS3tqxeWng1LObzH/ZULyfLX75dJT9WX7g1LSuNyBWTu4OZSt1RelXrqO3Wzw98XPDpIZVUpklty+/sqo3TXSevl2KVw8SZs4pcAt+9GSbWRi72y7X0ftpcAv5T5FX344Yfy4IMP2h/nz59fDR/V4CI/Z84cJSzMURNncPHv1auXuj9mzBj55ptvZPPmzUocuQLiZNq0afLtt9+qxz179pTXXntNRXMwCBV8/PHHatmQIUPsr0MkCSCahPeHKEPUB0BUJJacOXOqqJOfn599mVmE4D1xLNguhB+iWRMnTlSCbMaMGSpKA/Q+gAEDBijh9sYbb6jH8+fPVyk3iD9CvAUufFuOX7U//t/20/Jau0qSLatPqpQ095+2RSoVziULXmmZpG2sP3xJAvx9pU7JvB6tbxYtKF+eueWUilSBbvWLS4caReXv4LPqOQgCX9M+nb9+RyauOGx/PG/nWRnSpqLb1ggrD4RKUC5/qVE8jyQFCKk1hy6Jv6+Pioj4+Tqen3ql8qnjDj51TX7fdEKGtnUUP2YmrTwiX9giJMXyZJdWlQtJn6alpWrR2BlLB88b4qZy4dz2ZRAnc15sLv2nbpbjtkgVIjPvPVpVWlcu5FFbCJyDP55rotJbMECjJ87sF5vLuWu3VVQI6bWvetaRLJJFnpm2RQmb7t9vkFVv3J9i17DEwshNJgHpFzO4gMOLU7VqVTVnCBdzCIiEIjeI+pgFA9I1zqkcM4iUhIeHqygPCAoKUiILaSiA1549e1batGnj8vXBwcFSokQJB1GRFGrWrOkgbAAiMYhWlSpVSqWcWrVqpZbrc4BtI8WkhY0roXf48GHZuHGjegwRB2GD80KIt0D6AJEUpCMK5PRTEQGIkNQA4gDAuwEPR1Kaxz350ybpNmm9rDiQ8D7CK6PTTT0bllQ/R83fJ0tDLqj7/ZqVlUZl86tIxdVbdx1EHvhkYYjcioyS2iXyKMFx9GK47D0b5nJbfwefkX5TtyhT7a+JPDZUG/WdsllG/xuiHr/7SFWpUChWcLiK3kCkuYvIoNLqj83G5xJ8O2ev31GPX5q+3WG9/VrcFHHcVtmgnErgoCJqVKfqsmjoffJAlcKJ6neVPVtWmfBkXXXucG77Td0s788zDMlPNS4lVYoEqu3OGdxMapfMK2+2r+w1YQMYuUkAhDkRQfHWtlMK5wsuhA2Ex+eff65SQGjJ//jjjydotnW+0OM/B6Iz7kAKCmkr3fIfYH2ktZDiMi93RULP+/j4xPlAcNV11/n4Ibjat2+vbkglwTwNUYPH+hwktG2MLoA4QvQGUSj4mlauXBnvawhJbXQZdK0SeaR+6Xzy/eqj8ufWU9KuuuHvSClQibXMJioAfBedaheTArn8PU5nvf2/XfaL9+Dft8ufzzeNN0oCkXY3KkbKF8wpY7rUlOOXw1VKCtxfuaBUKJRL3W9btbASTojyNC1vjNJBKmVu8FnB9Xx0l5oqErJg9zklYpy3efbabXlv7h77vo2Yu0dOXAqX4R2qqiiFO+A1+WrpQflt00n1umxZs8jA+8qpaiR3tKtWWLJn85Fz1+9IyLkbUq1YoMtzBUGTJ0c2Wf1Ga9l64oo8+39b5cjFcOWjKZQ7u1rvgBtxA/Ll9JNRj9WQ5ACx8lPfhtJ10jolotX7wpD8YOyXT+zL/15o6hAx8waM3CQALt74hXrjlppdZOFhQeQB5mBENWCoheckJbl8+bL8/fffKq2DKIi+weNz9epV+e+//1TEBOZfeGLcRYpOnz4tBw8a4VhnIEpg6jULHGwjIWC0xv7Bv4PoTJUqVeJEoLDtNWvWxDui4Nlnn5WZM2fKDz/8IOXLl5fmzZsnuG1CUpOttmhFgzL55YkGRnQDqQSkZFKSjUcvS9ideyplUa1ooPLBfP6f6/+nzsAfM+i37XIvOkYJohYVglREBSmu01dvJZiSal+9iPj4ZJEvuteR3NmN7+gDbBEQ8JBNyP231/hsQHXViL+NKEOPBiWVmOlY2/DmzN95zqGPC+6/9udOdTyIQAyzXbh/WntMun63TqVkcHv5jx0qogNDLfrKoKS71Wcr5JcNJ5SwgWhZ8moreaN9lXg/yxERaV4+SN13F72COAVd6hZX5t82VQvbU0/bbL9vHOcBm+emigtxk1LAzzOtv+HjAcPaVZa8AY5RcW8LG7UP3t4B4h1Q6YSqJUQe8B9vxIgR8UZgkgLMthhAilSN839upKkQ1YFXBxVPL7zwgoqEwDx848YNJb5efvlllSqCebdbt24yfvx4FWWCMMH74bX333+/XLx4UcaNG6ciT4sWLVIRFKTL4gOpKKSp4AXCtvfs2aN8R2bgPcLz8AkNHz5c+W+QgmrUqJG94gqRHmwLviH4mgjxNvhWDxqUzqciGQ3L5FPpGXhvBrc2jPopASqxwIPVCkvXesXlickbZMaWk9K7cal4oy8owe4/dYuq7GlSLr989kQtZUjFOAKkVZ76aZP0aVpGRWKQTtGfHahyWnnAGFfwkK3KqHjeHCrac/LKLWlZsaB9Gy0qBkmAX1YV7Xhnzh4VnYF4ghBCdRDA++Px+bA7ygTbpJwR4Zmy7pgqz0bkHD4Z7EOZoJzKGLzzNEq2rzuUnwO8D8SQFhYjH60mzSoYgsUTWlcppHxDiEw5/45QEQb/EOhhS8WBBmXyqfO19cRVebhmUbl4M0L1osHpqugmBZZSlC+YS/56oZnsOXPdbuBOb3hfXhGvAKGQL18+adasmRI4uEjXq1cvRbcBXw0iQ66+tUCswLx86dIl6du3ryrf/u6771Q5OEqvDx06ZF/3f//7nzL6wshcrVo11S8HE9wBPEN4Hcy/MEjDfGzu6+MORHzgkZk1a5Z6T0RwkKIzA2GGKin4kyCyUEr/448/OqTmkBZDBAz706dPn2SeMUKSBy6ESFUApKRAd1v05nfV1yS286wzqIR5/tet8tE/++L0kHEGkYn/9l6wC42GZfKrCAwCqG/+tctt+Tk8MxA2EBQVC+WS759qIP6+WSUwezaZ2r+hFAnMrkyvH/6zTx74YpW66flLMOZCoMBMW9MknmCoRSTHORoCsyyANwWvg3EXplhEmvQ6uhQbBmREPiCCxi06oJbBcAthA3BsC4e0lLFda9pvrz1YSQlHpKkgbOBvwnIYqxMjbLS4AdtPXo1TRj1nxxmVioPXxWwexjkHunJJp6TKFMgpOfxSztLgDgjnznWLp9s5dVlirDIly0PCwsLUN/Dr16/H+XaPShddxYN+KoR4AqqmED3ypOdPeoF/69YEaZiBv25TwmHJMMMgj7YSrT5bqYzFuBA/2aiU8kjkz+kXpxHb2IVG7xN4O15tW1F6NyntsgIKF9THJ29QEYtt7z2oqoAQkWk3frXciLinvCZoUvdym4rqvbRHB5U0aw9fUqmNOS82kxL5HJuEYh/n7jgjKw+GqsZxuKhjnz98rLrsOHlN+Wj6NSujuukmBCqdYAgumie7vP1wFSVQnC/EMCf3/mmT2kf4eLafvGb37PzYp75HF26IQgiLqkVzS+7srosPPOGhr1arSMzXPevIY3WKq2W4PD/45WpVuj66Sw3p3TjWu3Pm2m1p/slydX52f9BOpm86KR8vCFEpuclP15fMdv12hpEbQpII/oOhIeL06dNVCo2Q5JLYGT4Tlh9SF7htJwzfBVIU2m+jgX9v9qBm6qKHiAt8Im2+WCknLoe7rHyClwIXbMxA6vnDRpeDHbX3pU2VQvby5qJ5csjcl5pL68oFlSiBR6XFp8tl8PTtMmvrKWUehrBBumhqv4ZxhA2A6MFYgt+fbSI7RrZT6S5s/905e5ToAc5RGnegX8uaN1vLitfvV2LBlVBBKgrbxPFC2GDfXm9XSVUFeRqRgDBChVZyhI3eX2CubMM+QdggRQZxZgYpOUSxcH6CT16L10ycGaG4ISSJoMNzu3btlGfH3EOIkKTw4fx9UmvUf/aLVELAs/LdyiPqG/yzvxi9RXSlFPw2ZkrmD1Df5qc/11hFKFDKO3nVUfvzh0NvqJJoX58ssnRYKxUlyOmXVYmm1YeMtJAG0QTtt3EWGvBiTO3fSKb1b6jSFkjXLNh1Tt74a5fqXosow8Te9TzqG5PL31e+eKK23dAL8zGiTUgFeQqOG+knd2B/BrYsp8qru9UroYTQSw9UjPc1qcUDttTUqoMXlWDBeZ686oha1qFmUZfiqb5OTZ24ajcTU9wY0FBMSBJh2TdJydlDMLJqk2rlIobpNT7+2XlWeUmA7juCEmazH8OZZuWDVAl1jx82yuztp1UvEpQIo0MuwOBEeFKQ/kDEAGMBZm4+ZfevAJQro8U/+sS0qhxr4nWOQsDgi+Z0qw6EyooDF5Xf56PHaji8V0IgevJKm4pSukCAjPx7r/RvVibFK3GebVlW9ZqJr8Q7LahXKq+KAuF3GXzqqiwLCVVGYghOpOJcAaGHv5dNxy7b/VQUNwYUN4QQ4kXMs4d0ibUzMOgifWL+9j5ji1Ee/GyLsiqSovuOFMrtLyXzu+/RhBRK9WKBKlIzffNJefH+8vaUlLnyBZU5EDdokAcvDLYP5thGFkAIxdekDWIBpmbcUC6cHJBWcuWZSQnwnlnTgScWog3nFGLlvbl7Vbk8gEm5ZgnXka4GpQ0Ri3lPyB5CcMJQTJiWIoSQFAH9TnarUuH4QfnsrtPXlL8GqQekbDB7CNEJsPP0NWUC1uAiB1Np54nr7MuRukJUBN/qB7Yqp/qOaOMuSoTjEwF47pnmRk+Y/9twXFXooEIJjeRgpNWg4yz6vCAdpAUNpo3/sv6EQ4fgtCK9VuWkJPArAS1shrataO9V5IrKtnlO2hZVsXAur0eg0gsUN4QQkkzQxA0jBDpOWKtMvu6KUI9cvCmdJqyVThPWScPRS1WlDkqd8Y37574NlEEUZtztJ4yqHYCoCjwYKPEevSDE3qoftKlaSHWEhb8FpdTo3fJcy4Rnrz1au6hKP2H45BuzjC7BD1YrIjn9HSMxWsAgSoRjQjUOBi62rBhk94iQlKNVpYKqTw14vH4JNfcqPiBk6pn8VZULx19BlJmguCGEkGSC9vihtqnO6NKLaAxKn51BN1n9LftyeKSsP2KkoIY/XEXNHtKN5HRqCoJi8Z7YQZG/bzopi/acs0+zNjd1wxBGRHDqlkrYcIveMnokwFHb9ObHnKpxALr4ooIIM5i+XHJQpagQLXq/Y7VMEUlJazC64v1Hq8lzLcuqdJQn59hsHk/NzsQZDYobQghJJmgCB+BlQVYA/VgwOPG2zfCr2WdLN2CAIRrKvdCqvLzRvrLqyAucxQ1MvRAfGIKpoygvTd+h0lhoeHefqStvYundpJR6X4CUFvweriqWHq1VVN3/ZrkxTbtvszJuh0CS5NOveVl595FqHk9YN5f900wcC8UNIYQkA/hgdLfejzvXkJ/7NVRl1GjhryMszuKmZom8aqAjmsuh3T7mJJnFjfbdLLJFbTBOAI3rME8IHhidtkhO5RDSUp3rGtGaR2oVtferccYcHQrK5SdD2safKiFpCzovI7qGiJq5g3Fmh+KG2MGcpqFDh9ofY6AlxiLEB8Kmc+fOTfa2U+p9CPEUjBgYPnu3GkroqlGdpywNCZXbd6OkVP4AdaFBqbMe4qib6+kUkzaKYtCkK1DlZPbdLN6n+8lgcnRW+bJHHRVtgddCj1VIDiM7VpdRnaorkeUOpLt0ugNRJoxKIOkHjFr4v2caKc+VrmgjFDeWALOhMETSFZhqDeGwa5dhGkwMW7ZskYEDB0pKgiGZderUibP83LlzamhmWnD79m3Jnz+/BAUFSUSE4ZMgmY8f1xxVc4cwCwkm300uSrCdQaM8pJuW2gYZgnnBZ+xl1NojUdfmg0DnWA2a7aGpHUYTwADsCrxeR2/+2nZK9pwJU2kuXcVUrVig/DWoqcwc2ERK2aqrkgPSTkgzxSdYsE8/9mmgDM8pIahIyoPUlHlwKKG4scxsoyVLlsjp044hcDB16lRp0KCB1KpVK9Hvi+GSAQHJ/wD1hCJFioi/f9p868AgTgzorFKlitejRfg2f+9ebNkvSTsW21JJiIKg5wsa2707Z7fbSicsxwgBdJB98fftSgxhyKGeVG1uj1+nRF71E34ZPQgRze90F193KSCgxc1cm48HDflgNNXUKpHXwWeRFqDTb5uqhWkiJhkGihsLgCnaesq1GUyzxtRriJ/Lly+rqdrFixdXgqVmzZryxx9/xPu+zmkpTOq+77771KBFTNKGoHLmrbfekkqVKqltlCtXTkaMGCF3795Vz2H/Ro0aJTt37lQfkrjpfXZOS+3evVseeOAByZEjh5rOjQgSjkeDSdydO3dWk7yLFi2q1hk8eLB9W/Hx888/y1NPPaVuuO/M3r171TnFYLbcuXNLy5Yt5cgRow26nnYOcQQxhm2/9NJLavnx48fVcQQHB9vXvXbtmlqmuxnjJx4vXLhQTRnHe2A+Fd4f4xwKFy4suXLlUlPQly5d6rBfiDLh/JYsWVK9rkKFCmr/cdHFfeep5tgPbOvwYcMISsRh3ADMuoiiLBvWSno3LqUiJKhGghnYFf/uPi+bjhnjDVAO/dz/bZWJKw4rDwy8DhULx5o50fW3nG2idPBpI3qTUErKWdxoMHWbEJI4KG4SAt/iIsO9c/NwYLuvr6/06dNHCQXzt04Im6ioKCVqMAUaF9MFCxbInj17lFh4+umnZfPmzR5tIzo6Wrp27Sp+fn6yadMmmTx5srrQOgMxgP3Yt2+ffP311/Ljjz/Kl19+qZ7r0aOHvPbaa0oYIA2FG5Y5Ex4eLu3bt5d8+fKp1BiOAxd6LSI0K1asUKIAP3/55Re1XWeB5wzW37Bhg3Tv3l3dkLY7ccJoSgbOnDmjBBzEw/Lly2Xbtm3yzDPP2KMrkyZNUiIK5w8CDJPAISwSy9tvvy2ffPKJhISEqKgahFuHDh1k2bJlsmPHDpVmRLrx5MmT9tfgdwxB+s0336jXff/990oIqaZszzyjonRm8BjHkpT9sxKvz9opD45fJZduRsSJ2mAcQZmgnDK6S015zdZFd9T8faohnxlUPY1esE/df75VOdUqP+zOPTUcEjgPNQR1ShnRG0yzBvvOGuImIdOn9t1o2nk4KJIQEgvHLyTE3VsiY+J+cKUJ75wV8fOslTYubp999pmsWrVKGYP1xa1bt25qRDxur7/+un19TLFevHix/Pnnn9KoUaME3x/iYv/+/eo1xYoZ52PMmDFxfDLvvfeeQ+QH25wxY4a8+eabKgqDizHEGNJQ7sCUbYix//u//5OcOY3jnzBhgrrYf/rppyq6ASB+sDxr1qwqxfTII48ocfDcc8+5fW9EXbDPeC2AiMJ5ghcITJw4UZ0r7HO2bIYPAZEozccff6wE2pAhQ+zLEGVJLB9++KHDsE14gGrXrm1//NFHH8mcOXOUeIKoO3jwoPpdIVrWtm1btQ4iY+ZI1siRI5VYxe8TESycR+doTmYDKaH/bT+tvif8sPqovNOhqsNUa3NUBGXZKw+EypbjV+XVmcEy8/mm9m6vGGB49vodNYl5aJtKqpIJTfvQ2Rd0rG2US5tBv5nZ28/IjpOGqTjkvGfiRvtuMGiyVok8apuEkMTByI1FwMW9WbNm6uINkIpAVAIpKYAIDi6YSEfhQgqRAaFijgzEByIFSIdoYQOaNm0aZ72ZM2dK8+bNlXjBNiB2PN2GeVu40GthA/CeiB4dOHDAvgwRIAgbDVJEoaGhbt8X5wARHqSjNLiPaA/eW6dykIbSwsYM3vvs2bPSpk0bSS7wQZlB5AZCsGrVqpI3b1517nAe9LnDfuFYW7Vq5fL98HuBuNO///nz56s01hNPPCGZmXVHLtkDoBg1gOgNjL27Tl9XnWAfrBY7bgBCZnz3OspkiynL4xbvV1O2VxwItU9nhjhCdQo8MGiYV65gTnmifgkpkS+uN61uSSNygzEJN+7ctc9+qlo04V4kTzYuJYUD/ZXgIoQkHkZuEiJbgBFB8da2EwGEDCIyiD4gGlG+fHn7xRBRHaSJ4KGBwIFwQNl3ZKRhdkwJkO7p3bu38tUgIqIjIF988YWkBs4CBN94tUhxBcQc0k7OqTCIHkR8EElBdMkd8T0HfHyM7wrm1KA7D5BZuAEIG0RlEGlBGgnbevzxx+2/n4S2DZ599lmVakQaEL9/HGdaGcLTA5jrhCokiA/N2kOX7Pfv3I1W0ZuitpRPw9L5Va8XZ+Ms+skglfX9qqPqpmlSLr90qBkb6UE6a/lrRpTUFSifxrwmVEj9u/ucWgbBYjYHuwOG4U3vGBE6QkjiYeQmIfD1Dqkhb9wSWZkADwkusEhHIKWDVJWubli3bp0yrCJSgagIUhpIdXgKIgqnTp1SPhnNxo0bHdZZv369lC5dWt59910VmahYsaKDnwXAswMxkdC2YDqG90aD/cexVa6c9OnCMN/27NlTRUHMNyzTxmL4XxDxciVK4CdCqg1CyBUwdQPzOTKbi+MDx4fUUpcuXZT4ROQLBmUNlkG4Ie3oDnh2IJrgC1q0aJH6/WcWIB4w1+nt2bEtDyAy19jETb9mZezRmz+3Gobh9m6Mut3qFVeTtmEI1jekhz7u7Fk7fA0a7KGyCUzfZETg2GSNkLSB4sZCIJWBb+vDhw9XF1hcLDUQGogMQIAg3fH888/LhQuxvToSAj4PeE/69u2rhAcEAESMGWwDaRREa2DchfEVvhEzEAfHjh1TF/1Lly657DOD6A8qsrAtmJ9hGEZEClEJ7bdJLBcvXlSpGrxnjRo1HG4w6qJS68qVK8rfEhYWpgTP1q1bVYXYr7/+ak+HwZuDSBSODc9t375dvv32W3t0pUmTJnajMISI2YMUHzh3s2fPVucF5/fJJ590iELhvGHfIViwrziHqLyCD0eDtBV+5/j94/1cpQ2tCgY7ggW7zslF24wn+GGQgkJFFJrPYcI1oje6aqmdKSVlBgLmvUeryfLX77ff5r3Uwm1vmvioazMV77RNC6e4ISRtoLixGEhNXb16VaWFzP4YXGTr1aunlsNwjMgASqk9BVETCBU0wINhFSmQ0aNHO6zTqVMnefXVV5VAQKM+CCmUgpuBwRmVQK1bt1aRDlfl6EilIIUEsQGzLtIz8LnAPJxUtDnZlV8GyyBMfvvtN1VSjiopeGCQ0kOFGSq+dAoMAgOpve+++055flAyDpGjgecFlVV4HdJ+MCB7wvjx45XJGb4pGKfxe8LvywwiMjgXL774ovJYwThtjm7p3z9SWf379xergBEEetaSKyBm1h02IjQoy5693YjMrD100d5hF9Ouh5rGBtQoHqhSUKlN3ZKOQywpbghJG7LEuOtYZVHwrRxekOvXr6s+JmZQoYNvxGXLllWRA0IyGoioQawhhRhflCuj/K3P23lWXvljh8rQfv9UfZdl0b+sPy7vz9urIjQYW4A00rLXWsnzv26T//ZdkNfbVZKXHqio0lRdvluvDL6I5GCmU2oTGnZHGo2JTWMuHXYfh04SkgrXb2cYuSHEAiC9hw7VSJuhQiqp6bvUBOLi+1VH5ON/9qkuv3fuxu+9Onvttrw3Z7fttSKvzNhhL6t2FkDg5QcqqgGC6AqMoZUbjhjRnha2tvRIN03sXU+GP1zFPvsptSkUmN1eyg1zcdmgxKe2CCGJh+KGEAuA9B7M3OiIPG7cOEmPbD95VcYu3K8a32E+U50P/5Pnf90q+239X8xER8fIa3/uVI3y4JVpXbmg8ss8+8tWOXE5NhWHZnsYTonIDqZXd6xlpGJHzdsnNyLuSZ4c2aRm8Tz29SE0nm9VXg2hTCu07wYTvXXfHEJI6kJxQ4gFgJEYVWjoqIwRG+mRmTbTb/mCOaVIYHYlVtApuMPXa9RMp8umDsJT1h1T0Zcc2bLKVz3qyIQn6ymfzOXwSCWMYBQG83cZUZum5QpI4cDs0r2hMdjxwAVjjlOz8gW8Lijur1zI2MfyQV7dD0IyE+xzQwhJddDEbv5Oo0T+k261pEHpfGqQJGYzLdh9zj7TCZEWABED3nu0qpS1zWia0q+hdJlodAXuPHGdTOnbUObZhktiIjfAWISKhXLJoVBjDlmLit4XFCgtR7O/hGZKEUJSDkZuXJDJPNYkE5Laf+PO7//PrnNy+26UushD2MD/Uq1YoPLAzBzYRKoXC5SIe9ESeiNC3aKiY1T34CcblbK/R6Hc2eXPF5qq9A4qpLpNXi/7z99QRuKHqhvjD/C+SE9pWlYw/DbeBPuEiq20TIURktlh5MaELve9deuWRx1hCcmo4G8cuBoz4SkQILj5+Tp+R0LDulHz96pOv71s4kSnpHo0KBmnEV7jcgVk/kst5OilmxJ5zxBFSCVBCDmvC8/MX4OaykvTdyhTsk775AmIPY5u9UrIz2uPSekCAVKqQObp0EwIiYXixgSaoGGuj55PhH4rielISkh6BxEVCBv8jeNv3TybKzFE3IuS9l+uViJk9qDmdnGB0mdMz0YUBj6agrn8VT8ZlF/7+mSRrvVKuHw/H58sHpdI586eTX7u20A+XhAif249Jf1t3Yc1+XL6yZo3W3vda0MI8R4UN07oadXxDWAkJKMDYRPfZPaEOHD+hn0i9oi/98g3veqq+58uOiDhkVHi7+ujBM7Lf+yQRmXzq+faVi0sBXMnPFfJ09EGiAy937Gayy8geJ4QknmhuHECH5SYLl2oUCG3Qw8JycggFZXUiI1mz5kwhz4zbaoWklL5A+R/tu7A059rLF8vOyyrD160p4/MXpiUgpFVQogrKG7cgA//5F4ACLEqe84as5IQiYG59725e+zN6h6vX0Lql84v3/WuJ90nb5B958JU6fd9lbxv7iWEZA4YuyWEJJq9Zwxx894jVaVOybxy4849VbmUy99X3nzImNyO+9P6N5Su9YrL6C416IEhhKQZFDeEZHBQsfTrhuOy6/S1NNne3ahoCTlvNMmrXSKvfNmjjmq2B15pU0GVbJvHD4zvXkfaVE1/4yAIIdaFaSlCMjgosx7x916VFkKVECqPUpMjF1GyHS25/X2VzwbbQ4O9naevSf/maTOziRBC4oORG0IyMBAZ6PILMJJg64m4gyUTy/L9F+TD+fvk+u278ZqJqxYLtAuppuULyAutyks2VikRQtIB/CQiJAODkQV6zhL4O/hMst4v5FyYvPDrdjXbCUMt0c/GmT02v02NYrEDKQkhJD1BcUOIBaI2basawxn/3X1OeWKSwp27UTJ0RrBE2l6/8egVefOvXXFGKey1VUphkCUhhKRHKG4IyeBRm0K5/eXrnnUlKJefXL11V9YeupSk9/t88QE1TRvvg0nc6Cj8d/BZ+WzxAfs60dExsu+skZaqUZyRG0JI+oTihpAMHrUZdH95yenvK4/WKmZvqpdY1h2+JD+tPabuf9qtlnSuW1zGdq2pHn+38og93XX8crjqQJw9m4+Us03rJoSQ9AbFDSEZEIgNHbXRwyk71jbEzeK95+V2ZFyvTHzpqDdm7VT3n2xcyl62/USDkvJS6wrq/kf/hMiNO3dljy1qU7VoIEccEELSLfx0IiQDsuHoZfWzZ8OSkt3WY6ZeqbxSIl8OuRUZJUtDLnj8XvN3npWz1+9I0TzZVVM+M6+0qagiNJduRsi3yw/bm/dVL0a/DSEk/UJxQ0gGJOTcjTi+F8xZeqxO4lJTMAtPWXdc3e/brIwE+Dm2vvLz9ZERHaup+1PXHZMlNtHESilCSHqG4oaQDOi3ORx6w54eMvNYneLq54r9obL1+JUE3wsVUSj/RodhRIFc0bpyIXmgSiG5GxUjRy+Gq2U0ExNC0jMUN4RkMA6H3lRCI3d2X5WGMlOpcG55qHoRuRcdI8/931Y5evGm/TkMuESF1bVbkfZlP9tMxN3qF5e8AX5utzni0WqSLavRsA8/KxbOlQpHRgghKQPFDSEZDERaQNUigSoV5cz4HrWldok8qiy839Qtcu76bZm86oi0/nylvD5rp3SeuE6JnuOXwmXZfiPN1K9Z/GMTygbllGdsoxWqFAkUf1/D50MIIekRr4ubiRMnSpkyZSR79uzSuHFj2bx5c7zrf/XVV1K5cmXJkSOHlCxZUl599VW5c+dOmu0vIelF3FRzY+qFb+anvg2lZP4ccvLKLWnx6Qr5ZOF+uRlxT0Vdjl++JV0nrZeR8/YK+vPdX7mgVCiUcCRmaNtKMqRNRfmgU/UUPyZCCLGMuJk5c6YMGzZM3n//fdm+fbvUrl1b2rdvL6GhoS7Xnz59urz99ttq/ZCQEPn555/Ve7zzzjtpvu+EpAboLgwhsnD3ObfrhJzX5di53a5TMLe/TOvfSPIGZFNTw1Ey/sUTtWXdWw9I7ZJ55dqtu7L64EW17oAWng27zOGXVV59sJLUL50v0cdFCCGZRtyMHz9ennvuOenfv79Uq1ZNJk+eLAEBATJlyhSX669fv16aN28uTz75pIr2tGvXTnr16pVgtIeQjMK84LMqhTR4+nb5b+95l9VNulLK2UzsTPmCueR/g5rJJ11ryorX75du9UtIocDsMuO5JvJwjSJqnSpFckuLCkGpdDSEEJLJxE1kZKRs27ZN2rZtG7szPj7q8YYNG1y+plmzZuo1WswcPXpU/v33X+nQoYPb7UREREhYWJjDjZD0yswtp9TP6BiRV2bskOBT1xyeD70RIVfCIwXDuGEeTggInJ6NSqkOxuYIzMQn68mvAxrJb882dunbIYSQjIzXxM2lS5ckKipKChc2uqFq8Pj8+bjfWAEiNh9++KG0aNFCsmXLJuXLl5f7778/3rTU2LFjJU+ePPYbfDqEpEdg8t18/IoSLo3L5pc7d6NlwLQtcvLyLfs6eq4TRItu3pcUfHyySMuKBSUol3+K7DshhKQnvG4oTgwrV66UMWPGyHfffac8OrNnz5YFCxbIRx995PY1w4cPl+vXr9tvp04Z34wJ8Ranr96SV/7YIQ98vlL22Dr+gplbT9n7ykzp11BN3b4cHin9pm1WIxLAPl0plUBKihBCMjOO7UjTkKCgIMmaNatcuODYJh6PixQx/ADOjBgxQp5++ml59tln1eOaNWtKeHi4DBw4UN59912V1nLG399f3QjxNuER92TSyiPyw5qjqhEfQOppwcstxTdrFvnfNmM4ZfeGJVUaaUrfhvLot2tV47w/t56SPk3LxJaBU9wQQkj6i9z4+flJ/fr1ZdmyZfZl0dHR6nHTpk1dvubWrVtxBAwEkjZaEpKeq6C6TVovE1YcVsKmSbn8qoIJwmXswhBZvj9UzW9CmgjdgAHMvy+3qajuf7fiiIrexIqbhP02hBCSWfFa5AagDLxv377SoEEDadSokephg0gMqqdAnz59pHjx4so3Azp27KgqrOrWrat64hw+fFhFc7BcixxC0iNztp+R/edvqNLsT7vVknbVCsuaQ5ekz5TN8n8bTsgqW1k2OgVnM03b7t6ghHy34rCcu35Hfll/XI5dMsYfVGPkhhBC0qe46dGjh1y8eFFGjhypTMR16tSRRYsW2U3GJ0+edIjUvPfee6qyAz/PnDkjBQsWVMJm9OjRXjwKQhKO2ny74pC6P/j+CtK+upF2va9SQenXrIxMW39cTthMwz0aOBre0Qn4xdYVZMTcPfLFkoOqiiool5/qY0MIIcQ1WWIyWT4HpeComoK5ODCQ335J6vPnllPy5v92KVGy+s3WDpO3kWrq+O1aORR6UxqVzS9/Ph83JRtxL0ru/2ylit6AlhWD5NcBjdP0GAghJCNdvzNUtRQhGTlq8/x95R2EDUA596Sn6ssjNYvKux2qunwPHb3R0ExMCCHxQ3FDSCp7bU5dua2iNr2blHK5DuY6TexdT41FcAe8N0XzZFf3axTPk2r7SwghVsCrnhtCMiqL9pyXM9duyzPNy7jt8JtQ1CYxIHrzY58GsvJAqHSwjU4ghBDiGoobQpLQrwb9aVDS7euTRfo2K+Nyvd82nkgwapMYELFh1IYQQhKGaSlCEsnaw5fsTfjG/Bsih0ONQZZmLt+MkPFLDqr7wx6snKyoDSGEkMRBcUNIIkFqCCBqE3EvWobMCLaLHc3n/x2UG3fuSfVigdKjIeeZEWIprp4Q2ThJ5F6kt/eEuIHihpBEgM4JK/YbDffGdq2pmvLtPRsmXy01ojQA86JmbDmp7n/QqbpkxSRMQoh1WDJCZNHbItumentPiBsobghxw5J9F6TBx0vl140n7MswuPJ82B3JkS2rdKxdTD7pWlMtn7TqiPSfull1ER759x5B96hOtYtJwzL5vXgEhJBU4dwu4+ex1d7eE+IGihti6SjLzYh7Lp+7FXlPotDu1w3bT16Vl6ZvV/OePlu0X67fvquWrzxgRG2aVyigetQ8VKOo9G1aWomZFQcuyvvz9sr2k9eU+BneoUoqHRkhxGvcvSNyzfaF58R6fNB4e4+ICyhuiGWZsPyw1B71n8zdYUzb1sAA3PyT5fLUT5tcvu7E5XB59petyk8Dwu7ck6nrjqn7GHAJWtuGW+rU08IhLeWth6pI47L5JcAvq7zToYoUzZMjFY+OEOIVLh8WibF57G5fEbl4wNt7RFzAEg5iWZaEXFDRmffm7pH6pfNJyfwByvg7dGawXL11VzYcvSzXb92VPAHZ7K+5Eh4p/aZuUT9rFs8jTzcprUYn/Lz2mHSpW1x2nLyq1mtdOVbcoM8NugbjNuj+8l45VkJIGnHJScycWCdSiFHa9AYjN8SSoIHe/nNGiTZSU6/ODFZC5+tlB2XPmTD7ervPXHd43ScLQ9Tk7eJ5c8jP/RrI4/VLSMVCuVTl0wu/bVeDK6sUyS3F8jIqQ0im5KIuHsgSm5oi6Q6KG2JJDl24KZFR0SpFlMvfV7aeuKoiNpNWHlHPQ7yAnaevObxu7aFL6ueYrjWlUO7s4uOTRYa0raiWhZwLi5OSIoR4wIkNIlMfETm/O/nvFXVXZM4gkeWjxStc3G/8rPhg0n03EEjTHhU5slzSHWe2G/t2ZptkZChuiCXZc9aIyNQqkUdGdaqu7s/feVZFXrrVKyF9m5VWy3aZxA3GKZy9fkeVbjcsk8++vEONoip6o3mA4oaQxLHjV5ETa0V2/Jb899r1p8jO6SKrx4ncuiJpziVb5KbOkyI+viI3zsYajD1l7xyR42tE1n0j6YqYGJEFrxn7tmGiZGQobkiG4NSVW/L10kNuq5+c2WtLN9Uolke61isuHWoa85hK5MshH3SqJrVKGEMqd5+OTUttPW58UNYoFujQUdgcvckXkE3qxjPgkhDigmtG36dkm2+jo0TWfBH7+OQGSVOi7hmGYlCsrkixeklLTd08b/w8tdmIRKUXjiwXObvdEpVgNBSTDFHSjVlOO05ekzv3olRVUkLsOWukkDCLCYbfT7vVkipFAqVDzaKSO3s223JRkZqLNyKkYG5/2WITNw1c9KZ5pGZRudH1npQLyim+WfmdgJAkiRsd9UgqiHhcMVLL9gtwlUckzUCEJipSxDeHSJ5SIqWbiZzebJiKEcnxlBsXjJ93w42eOSXqS7pg9eex92+cE7l6TCR/OcmI8FOapHtWH7qkhA2YF3xWiZ34gHFY+2Mw/gBA0LzSpqJUsKWX4MMpXzCXQ2pq63GjEsqcktJAIPVqVEoalyuQosdGiOVBtCXM1o4BP++EJfF9omOjNoVreMfMqyNPQRUQ0jXEjdqPDUmL3ICT6cSQfHydsS9Z/UQKVMzwZmmKG5KugZAxjzaALwYN9uID1U63IqMkezYfKWcTMK6AHwfsOn1dNek7cMGorqpfml2FCUkxbpwXiTalky8dStr7HFwoErpPxC+3SNcfjGXndopExB1cm+pm4qDKxs+SjY2qKUSTcJyJjdykJwGxxha1qdNbpGrH9LVvSYDihmSIqA2ESqtKBdWyv4PPxvuavTYzcbWigfHOdapt890gcgPBhIBQmQIBKkVFiNeJvCWW4Pqp+PvEOEdncHMG/zlXf2bcb/SsSOHqInlLicREGb4VTyNIyfW36LRaQZu4yZFXpEgio0g4lptO4sZ8zNhHpPH07bZjRafDejimhLgX4f71ehuHlhp+myxZRVoMNUWk4jkm7DO6Nbvi8DLP9i0VobghGSJq81Tj0vJMi7Lq/oJd5+RelIsPQNPgSgBfTXyYIzdbjrn32xCS5uz5n8iYoiLrv5UMzzUncROfqXjOQJFxZRwjGwCelrM7DK9Lk8HGstLNPRcViO58WUNk2iPJu+ja01KVYpfp/fDU3Hz7qki0TWRlCxC5c03kYkisYfn7ViJf1Yy9fVbeKM82c/2MyLhyIn/2Sbiy7OPCItt+cVyOczC5Rew2fu9mLK/VXSRfGZGSjUSy+BiemzA3XyZnP2fsg3N5/8lNIr91FZnUzKtT0yluSIaI2gxsVU6aly8gBXL6yeXwSFl35LLb1+kmfaiUig90FPb1yaLe759d59z6bQhJU3CBWzrKuL/qM5E7jo0mM2zkBhfL+EzFkeGGYRjHi7JxMzo6U/lhkVxGBNej6IIG6SuUbJ/aJLLv76QdByIuOqVW0FTUgCgSuGKMaEkQnb7Kkc+W1jIdw56/REL3Gqku3+xGJAUpvZD5ju9xcJFIRJjI/n8Mr4wr7kXa/o5iRHbPcnzuwt7YFBu2gxsM0q3eNJZlzyNSpKb78wuhiX2FIXrlJ67TWyUaivj6ibeguCHpkujoGBn/3wF71AYN9VCl9EitomrZ38Gx86LC7tyVO3ej7NEenZaqXtwwE7sDgy8rF8mt7p+8YqQA6LchXgcXDd03JeK6yOYfxRLiBhe7+CI3p7fEenOc19GPC1WLGzFBszl36RH7620XcgBTclJKnBHBiLxhCA5zBVEuo82EQ6opPvR6uQo7Rp/MZe5t3xd574JIp29cCwzzYy0mnNk1QyTsdOy5Naen9OsrtDW2g9urux2PK77ImLmqCgLrwr5YEXnoP0PItnhVvAnFDUmXzNlxRnaevi45/bLK861i5zV1ql1M/fxv7wU1sXvswhBp8NFSeeir1aqk+/TV22rQZbasWaRiIUO4xIfud6N72JQvmDOVjoiQRFYEaTGAZmqIamT0tBQupACpDldixHwRdRY32qdT0JQOwoU4ZyGRqIjY3iwJjkxA1GKPEflILFogYbvmiETuwskQN6boU8g8I6qFqEmDAcZy/bwScLeN+xBm5nMFr4xzN+GoeyJrv4x9fO+OEW0xp/nM7++KUk1j981MaIghaEBxWwn72vGOoqdGN5EC3p2zR3FD0h1o1PfJIuOD5OU2FR0MvvVK5VOjE7BOi0+Xy/erjqoxC8cv35IBv2yRzTbvDCIyfr4J/3nXtvlutN8GJd+EeA3zBa73LMP/gMnT26ZJxo/cNBDxDzQmapt71WjMF1Fz6spdOgj/V+3iwE1qxlkcwYQMYE5ObPTG2UysgUgB4Rc98/PotFTuIoY4QOk1SsMXv2ssbzxIJLst6pyvrEjuooZH5/RWY9nV40aKzSebSLXOtuMxNTYE++aKXDkqkiO/SPk2jufILI50dMYV+tzCD2TuBL3GJmSqdhJ59MtYj9j+f42/X9DyNfE2FDck3fHt8kMqCoPKpf7Nyzg8h27BneoY0Zs7d6NVU71Pu9WU/Dn9lDEYE8A98dtoaprEDf02xKvgoqNTDI1fMDwZLYYZj9GmP6HUS3o9Jh25gadDG3GdIzPwhyB1okEXYEQfdG+cyJvGqAPnhnKemop15OahTw1/CSIdR1cm30wMchY00jAQbRA4HkduColkyx4b/cBx+uUSafy8GwG33tG4XLyeSGsIoiwiBxYYPhod/Vtt+ztq+qJpBtaG2HN765JxHtBl2R05g2JL3vU2Lx8x0qbgvtdFitYWqdjeOPZZfY3lKCMvVFW8DcUNSVegR82UtYYxb2THauLvmzXOOs+1LCdd6haX9ztWk0VD75MeDUvJj30aiL+vj9y2eW+qJ1AppalUOLfkyGZsg5VSmQxceFGyiuoVT8GFA2WzrspzcQHdOjX2BnOsq7Jmd8CrgMqTbDkNcQNq9xIJLG58sw9OgblMSQXVS0dXJf51OLcwnYI8JWIjL86mYqRMkDoJCDIqotAFWPuOtKiAsMmazfF1+sIPw7E+77v/cqzSgUEZkQ5QprlI/X5xfSOJitw4dUj3yWoIHE9TU3ZxUyRuaqjhAJEAp88h5+iUOaWENF21x4zHi4Ybx79slBFtQZSs4XOxrz+50Ygs6dcrw28CbS/0a1Fthfde9LYhZCq2M4SNFjkAv7N0ErUBHL9AvErkvWj5ee0xuXbL+I+x4ehluRsVI/dXLigPVLGFe51AlObLHnUcltUvnU++7llHBv2+XV2zankobrJl9ZHPn6gtJ66Ec2ZUZmPXTJE5z4s0eCY2vJ4Q674UWfahSKPnRTqMc3zu1y6xBk7Nw5+JNB7o2XtvtjWma/hM7AUO3o7mQ0QWvmlcXBo+K2kOLoj/95hxwRywVKSkzQuUmLELOW1RioJuIjf2C3ZTI+0CkQePC3wb7iIm2mCcPa9RTv3P0NjlHT4XafSccV+ntCAmkO5r9orIlp+NiixEM7DNhMCHChoIOvt+zKkpiBaIQKPmwT26zB1pKXXMzQyfFSIpTV+Ku34pk4CDaHNOKUFcIA11bJVx0zQaaPTh8c9tCB1UV+G86tdrT018YBvbpoocWmzcNPe9EXsfZeNl7xM5tlqkwoPxR4PSEIobkiYs2XdBDpwPk0H3V3BorPfH5pPyqc1fo0F59ohHTVURHvJQjaLyw9MN5MTlcHsPG0/QFVgkk4FICcBsH0+IuBnbd0b3JTE33NPCptLDxsUWofx1XxmRgoRKYpGC0WkDRGvMoPwZ4gYXezRec45epDbwUejjPbM1ceJG+23yljR+6jSHc+TGfMHGRV6JmwPG3Ci7mdjFTDmMQOj4dWypM7aHih2YbLW40eJIi5I8xY05UNt/MdKApf+X8HFgfxGFwr4VspV+u/LdmMcquEOvo19T7gGR+940Sq+RqnIGx40UJbYPgQEvDVJREBUAr4OINgubgPyGKFbnKKtIqSbG3zvOs/1cx2Mm1lTrJHLqOWPOlAbb1dvWPPqVyLqvRVra0qjpAIobkgaN+A7J18uMb09lgnLKo7UMzwyYayvpblOlkJS3zX1qWq6Afe5TYnmwmutoDyEOKFPlBtcddN2Bb7A6hXUz1HWqARe/Xn8YZbdf1zZ8FDv/EKlv8yO44/xOI32DKERBJ79CYAkjVYXn0UvFVeQgtVCdgU1m1cRO9bb7bWziRu87oimICOHCi5/oP6MvuBCRZgF00Y2RV1O9s3EDp7eJ/PSAISyREoT4cSWOUKa84zeRw0uNBnnwr8SHQyrHhVDVFVPOzQddof92tLjBPj5gMxO7As8jegNfjU6lQdAgCqVBdDC+CGHpZoa4QbQSf+/wLzkLFFcgbfWIB+k7RNh02Xo6gZ4bkmpE3IuSV2cG24UNmLkl9kJy8vIt1aQPgZyxXWvKOx2qqlvrKi6+vRCSkuiKEy1MEjLr4nlzt2DnOULm8l6YQJGCaf5KbJmsNse6w5wqwMXMDB4HVUx4dEFqcHCxyIXdSRc3WjjCbwPylhbJ6m+Ub+N3oEuzkTJB6gQDMZ1TV5fiSUs5U7SWIQQhQnXptqu0Vv6yIjWfMO7r0vv4SCja4WmvG0T4cKxmQeQJervnghOucnJFKafXF60j4mftthcUNyRFzcBP/7xJ2o5fpW73jVshc4PPqjTU0LbGh/Paw5fklK1h3rydRtSmWfkgKRSY3av7TjIZztU1emq1O3b8aly4YHgFSDuZBZG5vFeDdFRAAeMivnd28i6eOmphbkaX2pjnOZW7P2niSntudAk2IjV2oXbQ8djRrVc9b0pdhV8SuWXrRq5fFx9I2em0mY622NNSTpEflULJ4tiEzhUOpdPuxI2HaSn9PEzTEHOe4rxdT1JKZuCDQVQxqa/PgFDckBQBDfX6Ttksaw5dksOhN9XtQliE5Pb3lV/6N5KhbStJ8woF1OfErG2nVbpKD8DUjfkI8Zq40RdhV8DnAj8BaPWWEXkA4aHuUw0A34ybvBgbHXBXOYXlCfUdsZdQuxldkBrAwwGPDS6K8FRACEBohLsffeI+cmNLSzkItQOuG8qhKgppE5R/H1lhe30pzyMN5vJwCFBddaVFk3k/4CkxN6FzBf42IH6xT7qxYlLTUvp5eGsS01OrSC2jTFzjiRnYDFJp5n3PBOKGnhuSbG5HRsmzv2xVIwxK5s8hY7rUFF9baL1q0dySN8DIUaNke93hy/LX1lPSrlphORR6U/yy+kj7GqZvu4SkBfqCisGFd2/F9d3smmVUoACUfeN5CJd6TxvpqesnjQuVjkg4m0Q1MLWiRw0iLogQ6IupGZh1EQnCviCt4gp7CbWHkRNc1FeMNi70lR9yvx6iSuhkC/Opcw8Z7e+o19dI48AUjAs99iGn7eKIrrloPmdOx2Cb6K9i9txoQ7FZZMDDhN42ut+MFiW4EGNfELnRTeHc+W1cYe4Lg54uKF2GP8WVWbclKo3+NprQ6Q7AEDFNB8d6UrTwRPTDncCyp6WcIjd7ZhvCCFVQEDP6PJkjfJ6Q1eaRgVEaQlfP10oMpZuLHF9jiFQYjC0OxQ1JFlHRMTJkxg4JPnVN8gZkk2n9G7k1A0PQYJ2z1+/Iu3OMPH7rKgUlT440rv4gmZuwc8YIAHzIoxIJFzbz5GpEUlBWjMiBGZQQZ8thfEuHuDFfyOzlvU7iBhdVlHZDQCA15Urc2NMyjdxXQumLuzLi2oyy8bHlR5H13xidjYfuNkqCXbHgNcNUC6NyX5uQ0D1RcCFEF1ztHYIogbhBxEULCFy8t/7s+J4Qcbh4Yp/RXdk5cqPNuxBW2neD82QuIcYFHOIG+2Y+fk8wd/3VYxaw764iJRCTqG47uDB2pID2AQ3ebKTJtBCOL1piH8EQaqSxsC34rOa+KHLvtkiZFsbxmb1ZiQVl1hA3+JkUKrQVWfWJ0Ska1VcWh+KGJLub8H/7LqhRB2ikF1+VEwZVdq5TXKatP67mRoFOtYun4d4Sggv3+tiKE0x0hrgxR25wX3XEzSby8KfGhQr+iOpdHC9MZlOxPXLj4hu5uih+6d6M60krfLThx/7ctZWc64hRQuZnmFcxeLOVqS+JuXGeFg9IQZ3aEutX0VGbOr1izcAQGIeXOB6H3vfKHYxOuPvmiRxdYaTh2ow0nsO5M4srXGR7/O6Y1ivRyLEKCduC2MDxemom1kCAFqsncmqj0XxOv587On8nsn+BMeIAwgR9jBDxQUSnRlfPfj/6bwKNCNE0EMeLdBiEjT5PEDeuvFmegs7FqEoq01KSRMmGIv0XGqbuTADFDUkyMAZ/t9KYEfNJ15rS0IMOvz0allTiBmAoZpuqrIwiaYz5YgUvBzBHbrTRFRcSdIx1ax41e27iSTfoC7MeKYAUQ2LMqgCvUQ3t9hu+m/jEjTY/I3qBrrEbJ4o0GSTi7/TFQwsYvR56vjw5U+RssCFinCc76+Mwp8Z0VAONECFuUJXzXZPY6I1z1AZALFZ91P3+u/PHJAacS4gbRNgSej16wiDdqIGJeeUYQ6DhfdQcLKRyGscvqPzzGFPcce4hbpxFIFJddm9WEj73EEWq1F6SRWnre200NBSTJDN6QYjqMNysfAE1DsETqhYNtA+rhNcG0RxC0hSzmNBeEH0RjK+6RqMFjKu0lKuLFoQITLnmkQIaNGTD+0Bg6BlD7vCkYspsfn7wQ8O7grJo+FvMoDpIpWGyiDwxzRAySOGgoaGeb1XjcUcfjn37Bx3Te3it9qcUqhKbelv5qe34ncSNJzif+8REblxFWZzFUnygX4xfbiM1teR9YxlK1BNK5dhNxeddiMD1hpCNL8JHUhSKG5Ik1h2+JIv2nldl3u93rJ6oadqYGYXxCi8/4EFpJyEpCaYb6zb6EDc65RJ2Nnais72vipsLoj0tZRM0iMbogYmuLlr4xl3A9rfunJrSAwmRRsG3//iwl0jHYyrWTdow7gCl6HrwJtJU5tJ1XR0EIYIuwDrl9s+rIiHzXc8I0gIDabGIG47pPXNDOf26yBvGT32OE4O57BvH4jxvKSEgtiC6NIlpfAgR08g25mLXDM8jHs4RPXNlG7xH+N07j14gqQbFDUk0d6OiZdR8YwLt001KS+UiuRP1+vql8yvjcdkgazeRIukQGGX1hRpTj3MXNapjou/FfuNOqCOu/SJmu1BhwrLAROpjvGe8hmDnmUqJaIXvHDlxBuJsjU20NHvZEEu1ehhpIewr0lX2yc7/i60WMgsSlH6Dqp2MKIwZCAwIDXUcB02NB532XU+K1jinpTwBVUk6ZZjYlBTIHmiILt1TRr+XpzQZbLxO48n8KedeN/p3Da+UTuHZIzdMx6c29NyQRPtspq47Lgcv3JR8Adnk1bZp2AreFfg2Or27cbHypE04SRyYmr1gmDFYsvwDKfve/70ncmyNSJ+5nldvILKwc4YR4k8KMI2axQSiKoHFjCogRDxwX6d93KVCcjuJGy2KMBka75cYYWLv8eJBx1mz50VX5JjBFHL4Q3Au4YExD97893VjPtV/IwwhpyY7t48tPYexuvIjRot/86RnV8cBIzCOIz5hhtfrQYtJSUupbVUy0oWJTUlpcE4xZyqoQsLVZc6g1BojMzZNdi3gXKGjMfh7wO9H/67hL8LvBoMl4edR78/ITWrDyE0mZ8vxKzJ+yUG5ftv2oe9ihMKaQxflw/n75IEvVkrLcStkyjqU0Yq83r6y5Anwchk3Jvui0gPlqAm10CeJZ8tPRrnuwrfdN6FLChf2GqkStINHi39PgNF16xSjggZVKEm54cIOn0m1x2Lf12wqRnoJPWewjruOuPaeJqFGtMST8l57Ez6TX+b6GePcmj0r8aH2J4vhodEXSQ1+N3qMABoHms3DdZ8yvDMQNOoc3DWiCfe/7fgeeIzRBRhLgOhLfMeBdJo5vecMjgepLjSeK5nEnioq+pPFqK5KCjUfN46zSsekvR6iEL/Tsq08G5VgjughzYm0XJasxvkHh5YkHOEjKQYjN5mYG3fuquZ7EDb/7j4nU/s1lJL5A9Rze85cl2+WHVIdh2/ftXkRUFjhk0Xql8onHesUk14NExnqTQ308EN8cKMapUgNb++RdcAFU3tCEC3YP99RFCQH8zwfRABq9/TgNbbIHC6abUclfdv+uR09HIgswOeLKIH2xOQr7d4DgwgNLroxUUbHXk/Ke819anTURZ9bdJ9FGiUhsD/YLwgi/D7MjdzQpwViA2XXjQbGfd2LGx1L1+GRce59gyjOm0cMc3NCx6HTWvABubtQd/vZ+H+Z1CnmMPbW7Z30GUgwaL973n00LSEQxUOPoPjOhztxo1NSEJWI+qgy/nBjGVJ7Sd0n4jEUN5mYX9Yft0dsMC6h88R1Mu7xWvLf3gvy57ZT9sh/odz+ygB8f+VC0rxCUPpqumduo48PFIqblANRBj0FW5cOw4uRmLbxrrh02Gj+5m4UgitCQ2KNrq3eNi7yKYX2hCByo42x8VXXoCwbF3REeXAhczV6wZn85Y1v8fg2j2/1eYonzm+jwX5B3OB3g8ZwzjOgGj7rumEfpjt7cs4SNDXbIje6wWF8+64u4Mm8iCd3uKO57D4p4Lx5inkEg9m35Rdg9Lg5vdlYRr9NmkBxk4mjNj+uMdJL73SoouY87T0bJgN+sRkKbTOfnm9VTqoVDUxUNVSagTSUNkAmZWIxiR/tB8EEYUQczu8yQuuV2iXvfdGtF+F5eCJUi/xDhkCI70NfG2VdGV2Ti70c/FTst/SEqmuQmoK4wYXM3egFM3qkAI4VIjyp4gb7BS+L2buDrrVoyAcDLHqppCbO5t5M1DclQcwjGHTkRp8vnCctblgplSbQc5MJxiPM3HJSHvh8pbwzZ7fy0JijNuUL5pQBLcrJn883lba2hnroQ/O/QU3lm151pXqxPOlT2IAz24zeIRqKm5RFX3xRKowRAmD1uKSbeQGMu7q8FqklGFnN23KFqu75K36ja0pFbhIqA49jKj7veddZs6kYwycxUyqxQxBdlYPrZnwN+qe+lwPVZegBo6G4ifs3gQ7FMDKbf19mw3hSRi+QRMPIjYXZePSyMgLvOxemHh+9FC5HQm/K50/UtkdtXmlTUflocvr7qvEJJy7fklL5A8THJ4vI1RPGt+mEQtVpAZqTXT9tDPDT6AtijvxGHwndWTa+12jQgAzhYnN/jvQOIlXweOBbf2rj3DkXfVo2/WAMOkTVR7lWnr9X6P7YGUNbpxqm3nL3G+3g8d5oloZtVe9sek1IbEoM4wNUdU8790bXlBA3iNygf4t5UKUn/gpP0lLO1U7ab4PtJEaQ6P3C+cE5QxNA9JtBxAnl36kNvuhApCFiiuaESelhY1Wy5zUmxkdFGOZ3cwRQdTfGl8QYips0guLGQqBbMATNygMXZeXBUDl60TCw5c7uK70alZLpm07KpmNX5MEvV8mdu9EqavNorWL21yNCU0b3njmyQuS3rsaQtt5/itdZ9anhK+g0IbZVuk6bwHSIyhvn9vbLPzK6tXb5QaR2j9j3Qorl+/uMi9qgdUk3PKY1KING1GPAEmP4XWqCzrPmzrkQuPX6GAMZN0z0XNwc/E9k+hNxl+v+KhA3m39wjNyE/CMys7f716Q0+gKNKiw9yyjBtJTJX3EzsZGbA8YE8MRGbcz7BVE19eHY5XV6GwbYtECLG0/K1zMTEH74u4AxHWZzs6DFlyj03UFql2mpNIHixgLExMTI4r0XZMy/IXLyyq3YX65PFjXLadiDlaRALn/pWq+4DJi2Vc5cu+0QtXHxhiIrxhjflpHfP7XZs1LV1ESbSVd+YjQmQzkl9gvU7C6yBaXgt4z29pjBY37NitEiNbrFih74N7AuvkHv/ssYDpjeQckxjge/E7TNT21xo8WGFjYAHW8hbo6vNaJiCYlC/B1hRo89nWErT0bURpthdf8QRG9uXzMuAivH2l5TLNZQquYWxTPbJzlky25UsOhBjvBOJBTRM49giG/0gsty8AOxIiqxAgH71fQlx/J5RH5avSlpBgY4IiKaFpGijIaeGA/w5clsiEajRLSswJBRkupQ3GRwQs6FqdTThqOX1eMCOf2kbdXCqrqpecUgCcweewGqUiRQ5gxuJu/M3iM5/LI6RG0cOL4m1vymc/rejN6gp4fuD4LW74hewKuB0kp82GPuS4EKxrcirAdxAx8EQvYAggeeDZQbo9IELerNJcm1uqf/0szzu2Pb2XtSXZRc7N1nTZGFQtWM0Dv6wGAGUYkEZiEdWRZrdH1hrev0Cy4GqCRC87lTmwzxBqEDIYSoWmLb7ifHVKzFjSet+rWQgX8GaQi1rIhn4gYdjZFe9LTzrTPtRxs3b4HUYN953tt+esaccnI2XyPtak69klSFhuIMzN/BZ+SxCeuUsPHz9ZGXWleQ1W+2lk8fryUP1yzqIGw0hXJnl5/6NpBve9V1HbUxGxThcUCEBNEbbZDzBtqfYK62ge8DqB4SPo4hf1cCACIGfVuQpkLIGBdtCCNUr4RkgA9q8zk4s13krhF9SzVcdc7FedZiR88Vio/VX3hmdNWmVESE9N8eSprTStg4jwjwZMiiFjLa2Iu/JUSA4gON9ezbiRHJW5qeFSuLm8QM6yQpDsVNBk1DfbvskAyZESyRUdHSunJBWf5aK9UxGMbgZIFUDzr+Yt7OI1+IVO8at+matxr11eppmIcRkVn7leOF0V5FctBR3NR5yrjwYDm8HTt+M5Y/8J5I40GxF+HkVAClBVpsAHSYPW0qgU9p0IfFXedcfb4Tih4dX+e50VULqO3/Z3g5MEE7tUuanTGPCPBklpGujEGkKTHt9M2jBOhZsR5mP01ihnWSFIdpqRQCPpZfN6DNaeqDhntLQ4w8/3Mty8rbD1d1H4VJLPqbM4QEqiGQJ0ZKZ988IyqSlCF2KXVhh+8C6acVH9ta5Jsutu4iN+jJAqMlSpgXvWUsQ/QBFxakWTZMELmw2/AwVH5I0iXmyqV8ZQzhgcdlW6bO9vS2XHXO1RdkrINImLuZPbqbsCdGV52a0b9TeHvSutGZebCiJ3/jzhUvnu4v3hvpuqSmpEj6hpGbdAPFTQpx5ewRybVuXJpsq46I1MuWRVpWDJKaiEocqGcMZ/OU/f86Nr/T3IswUlD4xt7iVWNZ4WoiVR41TKww4nb93vE1t66I7J5lXMTM82w85V6kYVLVHgRQ9j7DdAruhBleGi1KMGdm/TciEWFGxYkuDba3tz9o7FPo3ti0VZmWRoWPbn+OXimobEDao+EAI1WFSqxK7R2776L0Ovg3Y6BgYFHxGuqYLhsRjcYviCx62zGSk9LYS8BdRBbQoh/zhyBE0KdF96lx7j+ExnLoyNtiaMLbQ3omsLhI2BmjTX2zVyTNMUduPLkowSiKfi/aB+VpBQwjN5nXc0PSFIqbFKJQzFV5yffvtN0o/LI2z6wM2mAIEU96jsx40sj5uwOzezBJV4PoDcQNRAyG65n7xvz9kjFJGKbfB95N/DHs/lNk8TuOy9ZPEBlqK5lEmgyhf0QsdH8XzM5BZABiR1fsoPsrUmloC2+fe1Mpdv4OmtChXBzddsu3id0WKk82fW+IPaTjtKjSVVYQUrjYPz5FvIYWMiUaxu4f+s14UrGUFLSZvJSLgYfYHvrTHF1pnBdX4kZ7bWDUxu8tISAoIUBhFEflWlr08XEGpmYQEOR5FAapqcs2ceNp7xJEwwDEHP5mibVAtFtXB6alZ4zEgeImhShcrFSshyOtjaaYrLx2vEi3nxJeH+tB2CDioctwzcAUianCZorXMyImh5eKrPtKpOPXxvLzewxhA5TBNwni5tga4yf2BfuEb/wwaUKIoCLElbH1vjdEcuQTqfyw40UXFwtEObZNs73GdHz3vyMSUMAY/GiOzuBCVq+vyObvjZScFg+I/qC8XB+bHnboTc8RzgGiCrppIUzeKV0SjpJz3drf3Zwu7IcWN42ec3zO/jeRRaTFMM+32/Z9kUJVRRrYOiGnNfBH4O8af0Oe/p7hs0FvpcREblBh1nmS8XtMr52/SdLBF8xHv3SM0BGvQHGTUmAo3cOfpP12cYFDQzpEK+4fHtvjxRUw4iL6AvBBjmFunoIGahA3O34Xue9N49u12WSMVAQqeBLbzVinQJAqqtBG5NBSkd+7iWydYlwcXZUkQ4A1eynue+EDBeIGpcTqNSZxg27EOtXmTPNXjO2hBP7kRiNisXFSbBoLM4RwEQuqKN7x22iBZ6sMw7mAgMDylBY3KJtHaTM6rSJd5AqzqdhZ9Om/CYjIxBgq4cvxJIWVmsDrkxjMEZ7EdJ2tg8gpsSzeEujEAVZLZXQQ7ajY3kjdqKhMPKDCCOuh63BihI02P5ZuYVTqIKqCLr975xjPoSdJUip4MMsHDa/gzdBVORA4SB2hyRmO5+x2z2fYJHWoH8pxdSM/RG8wGwaRHKDn6KSmxyWhWUzKi+JrpKUSU7GUFHTUBkLOXe8fNPZDFdRNUy8hYP6bSI0ZUOkNc7SGLfUJSVdQ3FgBfSHZOcO4GLoCHUWDpzuun+jtvGb8RNrnvxFGegvdNtEPx1U/moTQ60Og+dtEBKIAev9gAsZgTIT/PfEnmI2gqH4xm0QTAlEdGKkPLxGZP8QQOHg/dGNNq8Z5rtDbhRhF9MksbnD+ULGUkjhPM3YFonMQOOb9M0/7rvSQ0Wre6pgFDVvqE5KuoLixAoh6oMIIAwnXfeN6HURbEF2BcdOVUdQTyrU2Lmr3boscXBibrrJHEhIZ3TCnW8ygOqlg1VjTM573xJ9gviAndloxxFONx437OvoAI7UeE+A1cePiHMGUimgZBFjovlSK3CRQ6WEWWABDVnXn59SaAZXeYOSGkHQLPTdWASZbGF8RVTGPTtBgirBaLxkXHhVVeUPkj56xYgcGSe2zQWWTruCBMRUREF3GDdCdtcvk2CiNu5Jj+EogLGY/mzihYvbEJKWHCLaJ6i2AKh/Mo4L/BCkhTIxGVExXQ2D21sFFrt8HKZvW74qUb+3Zdq8cE1k03JgPBPO2GS0ezOcIM7IgaGG+RuVbjryGgReDLVHabmbnTKPSDR4rT6o39JiLhPwyys/0hSEE4XGCAds87TszoD038CdlpOnyhGQCKG6sAiIyuADim767UQkwopb1cJqzO5ByKFbPqNBqZWuKV7CKUb10+2psBc++uSI7fnV8LZ5Dl2CIiJsXY7sJu4okoRwdnhsYecs/4Nm+ofcIfCkX9nr+GjOFqhjRGzQtbPW2ISJwQ9oMhmlULUHcnA02ppTHx4LXRF7a4tnMKjQSRCQM4rHXH7HLMZBRVeNkESnpNDQSPiuIGxiAcQOLQoyeRLp7LgTHgmFGeTz2O6F5RDAHX/IwcoMhlv55RCKum/7essT+TWQG8HcP4YuqMlY+EZKuoLixCvrCiP4nrkYJ4Hlc+JP7IYzXPz3HqCDSkRJVwdPMVsGz3hA/utdJ/f4iVR4xxAGmPcNHg0Z0OiKBLsGuIgoQFf3/NQRTYvqBPPln7MU8KTw20ajaMXtGEDlS4madSO0esRVBlR6OGymBYXvO88YgSEQ1atpSXfGhI1jaQ6O7/ur5TRgMqqIzJlCCjYZ6keGxPXkwpBJCqd1HxjL078G5AFunGtVnOQu43w8MG0VzRHiP4qu6A4i+vbAmVgzpNE1m8NqYK7wGb2Y/E0LSIRQ3VgKhcfSjSW1woXW+2CINpMUNRiSgQzAqjdqMND78kcKCoRlRhm2/xBqf40s5IRqEW2LAtpJzsUGZufMFGhExeJZwbGiCqAdt6t4szqBPEMTGGttsLncjCoDqpmzzzUDIIS2kmzHa03YuzhEiQublEFXTuxu9eWCORkRh0yTjOR1hwWPM1ErITAwx6esvHrU/wC0zk5AIJIRkTkPxxIkTpUyZMpI9e3Zp3LixbN7swi9i4tq1azJ48GApWrSo+Pv7S6VKleTff/9Ns/0lCRlM1xujDACiGlpoIBKj+8yg6y+awJlfl55RabMsxgRx3U25akfXwkZHVSDsIFq08dod6KtjxmzKjk/cOIOKNYgy9ObZNFlky0+2iq9KIp1sTRc3/WAsS66ZmBBC0jleFTczZ86UYcOGyfvvvy/bt2+X2rVrS/v27SU0NNTl+pGRkfLggw/K8ePH5a+//pIDBw7Ijz/+KMWLe6FdO3GkSG3bzKHrRm8a3xzGaAPn5mW5i4ncOGfMJQKuuiSnNxA9QvoM6KGH8A3Ft77u3AuhF9/EcS1mMFPJLGgQxYF3yFNxg3ShrlKCuEH6T+9nVTTUq2JEbzb/mHwzMSGEpHO8Km7Gjx8vzz33nPTv31+qVasmkydPloCAAJkyxfUcHyy/cuWKzJ07V5o3b64iPq1atVKiiHgZRGZgMtWoyc62uU4apDqaD4l9jPSHNwdSJgazwPCkCWLTwYbAgw8Gxl93aDGjmwjqrr8nNxml8AUqej7rqGonI+oCgXnrktFhGAZpXX0GNn4X69NxxlMzMSGEpHO8Jm4Qhdm2bZu0bRvrEfHx8VGPN2xw3Qxu3rx50rRpU5WWKly4sNSoUUPGjBkjUVFRbrcTEREhYWFhDjeSygJATXZ+2fU6KFfGcELz+hkB8756Uk6fM0ikQf/YrseuiLgZW2mESdi66+/VY6b+NokoaVcixjTPCWlAiE4A70++ssZ0cT17y5mLuoEfIzeEkIyN18TNpUuXlCiBSDGDx+fPn3f5mqNHj6p0FF4Hn82IESPkiy++kI8//tjtdsaOHSt58uSx30qWTETXWpI4ECVALxuUA7ub7IwuuyhJzllQpO7TkmHAWAhULdV+0vMmiBB4ECzwIR130eAQ/Yhiooxuyqg8Q5WZjt646wHkye8AbQFKNnGcYWT2PKHR4907jq9DGizclg7m0D9CSAbH64bixBAdHS2FChWSH374QerXry89evSQd999V6Wz3DF8+HC5fv26/Xbq1Kk03edMRf6yIq/uEWn1Rvzr1e4p8sbhpHdK9lYl2qB1Il1sFUielgrX6W3cX+MieuNsGNY/D/1n9BEyL/MUiJh+/4gMWBy34ql2L5HA4kZ0KPh312biwBKxTRYJISSD4jVxExQUJFmzZpULFy44LMfjIkVcz2lBhRSqo/A6TdWqVVWkB2kuV6CiKjAw0OFGSJqBnjkYDArfDXrlxCtubFGakPlGt19EwZLar8cVvn6xnicMUUU3aQ3NxIQQC+E1cePn56eiL8uWLXOIzOAxfDWugIn48OHDaj3NwYMHlejB+xGS7sAYh1o9jPu6sSG4FxE7RV2LG4xUQAM99KwxL09J4HlCShDT2HfPil1OMzEhxEJ4NS2FMnCUcv/yyy8SEhIigwYNkvDwcFU9Bfr06aPSSho8j2qpIUOGKFGzYMECZSiGwZiQdIsy+WYxmhzq8u4z2425VRAaaHoIsgcaQzHN4zJSmmymEn00GcQMMEAzMSHEQni1QzE8MxcvXpSRI0eq1FKdOnVk0aJFdpPxyZMnVQWVBmbgxYsXy6uvviq1atVS/W0gdN56KxPNsyEZD5iFq3c2xjH8955IrZ6x/XKcJ57jsd1vk0gzsaegueLaL425VeikjGjN+d3Gc+iHQwghGZwsMTHxdRizHigFR9UUzMX035A04/wekckuxMrD40QaPx/7GH6bmU8Z5fIwXafWQMaVn4qsHBN3+RtH458/RQghGeD6zdlShKQFmBzd7mPHhn4QMNqPo8EwTqSNkJJKzUnTTV80+uncNBn6y95HYUMIyZyRG3QFfuaZZ6Rfv35SqlQKVnKkEYzcEEIIIWLp63eiDcVDhw6V2bNnS7ly5dScpxkzZqguwIQQQggh6YEkiZvg4GA1vRs9Zl5++WVViv3SSy+p4ZeEEEIIIRnaUHz37l357rvvVMUS7tesWVNeeeUVVc6dJTU9A0mEaSlCCCEk45EmhmIImTlz5sjUqVNlyZIl0qRJExkwYICcPn1a3nnnHVm6dKlMnz49qW9PCCGEEJIkEi1ukHqCoPnjjz9UDxo02vvyyy+lSpXY/hhdunSRhg0bJm2PCCGEEELSUtxAtMBIPGnSJOncubNky5Ytzjply5aVnj17Jme/CCGEEELSRtwcPXpUSpcuHe86OXPmVNEdQgghhJB0Xy0VGhoqmzZtirMcy7ZutQ0CJIQQQgjJKOIGQypPnToVZ/mZM2c4wJIQQgghGU/c7Nu3T+rVqxdned26ddVzhBBCCCEZStz4+/vLhQumeTQ2zp07J76+HFVFCCGEkAwmbtq1ayfDhw9XTXQ0165dU71tUEVFCCGEEOJNEh1q+fzzz+W+++5TFVNIRQGMYyhcuLD8+uuvqbGPhBBCCCGpJ26KFy8uu3btkt9//1127twpOXLkUKMWevXq5bLnDSGEEEJIWpIkkwz62AwcODDl94YQQgghJJkk2QGMyqiTJ09KZGSkw/JOnTold58IIYQQQtK2QzFmR+3evVtN/dZDxfUE8KioqKTvDSGEEEJIWldLDRkyRM2OQqfigIAA2bt3r6xevVoaNGggK1euTO7+EEIIIYSkbeRmw4YNsnz5cgkKClJTwXFr0aKFjB07Vl555RXZsWNH8vaIEEIIISQtIzdIO+XOnVvdh8A5e/asuo/S8AMHDiRnXwghhBBC0j5yU6NGDVUCjtRU48aNZdy4ceLn5yc//PCDlCtXLvl7RAghhBCSluLmvffek/DwcHX/ww8/lEcffVRatmwpBQoUkJkzZyZnXwghhBBCkk2WGF3ulAyuXLki+fLls1dMpWfCwsIkT548anxEYGCgt3eHEEIIISl8/U6U5+bu3btqOOaePXsclufPnz9DCBtCCCGEWJ9EiRuMVyhVqhR72RBCCCHEOtVS7777rpoAjlQUIYQQQkiGNxRPmDBBDh8+LMWKFVPl35gzZWb79u0puX+EEEIIIakrbjp37pzYlxBCCCGEZKxqqYwEq6UIIYSQjEeqVUsRQgghhFguLYVZUvGVfbOSihBCCCEZStzMmTMnTu8bDMv85ZdfZNSoUSm5b4QQQggh3vPcTJ8+XY1f+PvvvyU9Q88NIYQQkvHwiuemSZMmsmzZspR6O0IIIYSQJJEi4ub27dvyzTffSPHixVPi7QghhBBC0s5z4zwgE1mtGzduSEBAgPz2229J3xNCCCGEEG+Imy+//NJB3KB6qmDBgtK4cWMlfAghhBBCMpS46devX+rsCSGEEEKINzw3U6dOlVmzZsVZjmUoByeEEEIIyVDiZuzYsRIUFBRneaFChWTMmDEptV+EEEIIIWkjbk6ePClly5aNsxwTwvEcIYQQQkiGEjeI0OzatSvO8p07d0qBAgVSar8IIYQQQtJG3PTq1UteeeUVWbFihZojhdvy5ctlyJAh0rNnz6TtBSGEEEKIt6qlPvroIzl+/Li0adNGfH2Nl0dHR0ufPn3ouSGEEEJIxp0tdejQIQkODpYcOXJIzZo1lecmI8DZUoQQQkjGIzHX70RHbjQVK1ZUN0IIIYSQDO256datm3z66adxlo8bN06eeOKJlNovQgghhJC0ETerV6+WDh06xFn+8MMPq+cIIYQQQjKUuLl586b4+fnFWZ4tWzaVDyOEEEIIyVDiBubhmTNnxlk+Y8YMqVatWkrtFyGEEEJIkki0oXjEiBHStWtXOXLkiDzwwANq2bJly2T69Ony119/JW0vCCGEEEK8JW46duwoc+fOVT1tIGZQCl67dm3VyC9//vwptV+EEEIIIWnb50YDn80ff/whP//8s2zbtk11LE7PsM8NIYQQkvFIzPU70Z4bDSqj+vbtK8WKFZMvvvhCpag2btyY1LcjhBBCCEn7tNT58+dl2rRpKkoDBdW9e3eJiIhQaSqaiQkhhBCSHvBJjNemcuXKaiL4V199JWfPnpVvv/02dfeOEEIIISS1IjcLFy5U08AHDRrEsQuEEEIIyfiRm7Vr18qNGzekfv360rhxY5kwYYJcunQpdfeOEEIIISS1xE2TJk3kxx9/lHPnzsnzzz+vmvbBTBwdHS1LlixRwocQQgghxNskqxT8wIEDylz866+/yrVr1+TBBx+UefPmSXqGpeCEEEJIxiNNSsEBDMaYBn769GnV64YQQgghxNskS9xosmbNKp07d05y1GbixIlSpkwZyZ49u/LzbN682aPXITWWJUsWtW1CCCGEkBQTN8kBQziHDRsm77//vmzfvl2Ncmjfvr2EhobG+7rjx4/L66+/Li1btkyzfSWEEEJI+sfr4mb8+PHy3HPPSf/+/VUjwMmTJ0tAQIBMmTLF7Wsw4qF3794yatQoKVeuXJruLyGEEELSN14VN5GRkWoeVdu2bWN3yMdHPd6wYYPb13344YdSqFAhGTBgQILbQAdlmJDMN0IIIYRYF6+KG/TJQRSmcOHCDsvxGKMe3PXbQYUWytI9YezYscpdrW8lS5ZMkX0nhBBCSPrE62mpxIBeOk8//bQSNkFBQR69Zvjw4apsTN9OnTqV6vtJCCGEkAwyODOlgUBBpdWFCxccluNxkSJF4qx/5MgRZSTGnCsNmggCX19f1XenfPnyDq/x9/dXN0IIIYRkDrwaufHz81PjHJYtW+YgVvC4adOmcdavUqWK7N69W4KDg+23Tp06SevWrdV9ppwIIYQQ4tXIDUAZeN++faVBgwbSqFEjNXE8PDxcVU+BPn36SPHixZV3Bn1watSo4fD6vHnzqp/OywkhhBCSOfG6uOnRo4dcvHhRRo4cqUzEderUkUWLFtlNxidPnlQVVIQQQgghqT5bKiPC2VKEEEJIxiPNZksRQgghhKQ3KG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKShuCCGEEGIpKG4IIYQQYikobgghhBBiKdKFuJk4caKUKVNGsmfPLo0bN5bNmze7XffHH3+Uli1bSr58+dStbdu28a5PCCGEkMyF18XNzJkzZdiwYfL+++/L9u3bpXbt2tK+fXsJDQ11uf7KlSulV69esmLFCtmwYYOULFlS2rVrJ2fOnEnzfSeEEEJI+iNLTExMjDd3AJGahg0byoQJE9Tj6OhoJVhefvllefvttxN8fVRUlIrg4PV9+vRJcP2wsDDJkyePXL9+XQIDA1PkGAghhBCSuiTm+u3VyE1kZKRs27ZNpZbsO+Tjox4jKuMJt27dkrt370r+/PldPh8REaFOiPlGCCGEEOviVXFz6dIlFXkpXLiww3I8Pn/+vEfv8dZbb0mxYsUcBJKZsWPHKqWnb4gKEUIIIcS6eN1zkxw++eQTmTFjhsyZM0eZkV0xfPhwFcLSt1OnTqX5fhJCCCEk7fAVLxIUFCRZs2aVCxcuOCzH4yJFisT72s8//1yJm6VLl0qtWrXcrufv769uhBBCCMkceDVy4+fnJ/Xr15dly5bZl8FQjMdNmzZ1+7px48bJRx99JIsWLZIGDRqk0d4SQgghJCPg1cgNQBl43759lUhp1KiRfPXVVxIeHi79+/dXz6MCqnjx4so7Az799FMZOXKkTJ8+XfXG0d6cXLlyqRshhBBCMjdeFzc9evSQixcvKsECoVKnTh0VkdEm45MnT6oKKs2kSZNUldXjjz/u8D7ok/PBBx+k+f4TQgghJH3h9T43aQ373BBCCCEZjwzT54YQQgghJKWhuCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoiloLghhBBCiKWguCGEEEKIpaC4IYQQQoilSBfiZuLEiVKmTBnJnj27NG7cWDZv3hzv+rNmzZIqVaqo9WvWrCn//vtvmu0rIYQQQtI3Xhc3M2fOlGHDhsn7778v27dvl9q1a0v79u0lNDTU5frr16+XXr16yYABA2THjh3SuXNndduzZ0+a7zshhBBC0h9ZYmJiYry5A4jUNGzYUCZMmKAeR0dHS8mSJeXll1+Wt99+O876PXr0kPDwcPnnn3/sy5o0aSJ16tSRyZMnJ7i9sLAwyZMnj1y/fl0CAwNT+GgIIYQQkhok5vrtK14kMjJStm3bJsOHD7cv8/HxkbZt28qGDRtcvgbLEekxg0jP3LlzXa4fERGhbhqcFH2SCCGEEJIx0NdtT2IyXhU3ly5dkqioKClcuLDDcjzev3+/y9ecP3/e5fpY7oqxY8fKqFGj4ixHdIgQQgghGYsbN26oCE66FTdpAaJC5kgP0l5XrlyRAgUKSJYsWVJcVUI0nTp1KtOmvHgOeA4y+/EDngOeA8BzICl6DhCxgbApVqxYgut6VdwEBQVJ1qxZ5cKFCw7L8bhIkSIuX4PliVnf399f3czkzZtXUhP8AjPrH7KG54DnILMfP+A54DkAPAeSYucgoYhNuqiW8vPzk/r168uyZcscIit43LRpU5evwXLz+mDJkiVu1yeEEEJI5sLraSmkjPr27SsNGjSQRo0ayVdffaWqofr376+e79OnjxQvXlx5Z8CQIUOkVatW8sUXX8gjjzwiM2bMkK1bt8oPP/zg5SMhhBBCSHrA6+IGpd0XL16UkSNHKlMwSroXLVpkNw2fPHlSVVBpmjVrJtOnT5f33ntP3nnnHalYsaKqlKpRo4Z4G6S/0K/HOQ2WmeA54DnI7McPeA54DgDPgXjtHHi9zw0hhBBCiKU6FBNCCCGEpCQUN4QQQgixFBQ3hBBCCLEUFDeEEEIIsRQUNynExIkTpUyZMpI9e3Y1DHTz5s1iVVCWj2GnuXPnlkKFCqmp7AcOHHBY586dOzJ48GDVCTpXrlzSrVu3OM0XrcQnn3yiOl4PHTo0U52DM2fOyFNPPaWOMUeOHFKzZk3VmkGDegVUQhYtWlQ9j7lxhw4dEquA8TEjRoyQsmXLquMrX768fPTRRw6zb6x2DlavXi0dO3ZUXWLxN+8818+T40WX+N69e6umbmiqOmDAALl586Zk9OO/e/euvPXWW+r/Qc6cOdU6aGdy9uxZyxy/J38DZl544QW1Dtq8pOU5oLhJAWbOnKn69aDcbfv27VK7dm01zDM0NFSsyKpVq9RFe+PGjaqBIv5Dt2vXTvUn0rz66qsyf/58mTVrllof/7m7du0qVmTLli3y/fffS61atRyWW/0cXL16VZo3by7ZsmWThQsXyr59+1T/qXz58tnXGTdunHzzzTcyefJk2bRpk/rAx/8NCD8r8Omnn8qkSZNkwoQJEhISoh7jmL/99lvLngP8P8dnHL7QucKT48VFbe/everz459//lEXy4EDB0pGP/5bt26pawAEL37Onj1bffHr1KmTw3oZ+fg9+RvQzJkzR10nXI1LSPVzgFJwkjwaNWoUM3jwYPvjqKiomGLFisWMHTs2JjMQGhqKr6kxq1atUo+vXbsWky1btphZs2bZ1wkJCVHrbNiwIcZK3LhxI6ZixYoxS5YsiWnVqlXMkCFDMs05eOutt2JatGjh9vno6OiYIkWKxHz22Wf2ZTgv/v7+MX/88UeMFXjkkUdinnnmGYdlXbt2jendu3emOAf4e54zZ479sSfHu2/fPvW6LVu22NdZuHBhTJYsWWLOnDkTk5GP3xWbN29W6504ccJyxx/fOTh9+nRM8eLFY/bs2RNTunTpmC+//NL+XFqcA0ZukklkZKRs27ZNhV41aDqIxxs2bJDMwPXr19XP/Pnzq584H4jmmM9JlSpVpFSpUpY7J4hgoVO2+VgzyzmYN2+e6iz+xBNPqPRk3bp15ccff7Q/f+zYMdWY03wOMBcGaVurnAM0FcU4mIMHD6rHO3fulLVr18rDDz+cac6BGU+OFz+RhsDfjgbr43MTkR4rfj4iLaNnGmaG44+Ojpann35a3njjDalevXqc59PiHHi9Q3FG59KlSyrvrjsqa/B4//79YnXwRwyfCdITuks0PtwwN8x5QCnOCZ6zChj9gdAz0lLOZIZzcPToUZWSQUoW3cJxHl555RV13Bipoo/T1f8Nq5yDt99+W009hnDFEGB8FowePVqF3EFmOAdmPDle/IQYNuPr66u+HFntnCAVBw9Or1697EMjM8Pxf/rpp+qY8HngirQ4BxQ3JNmRiz179qhvq5mJU6dOqTlnyBfDRJ4ZgbDFN68xY8aox4jc4G8BXguIm8zAn3/+Kb///rsaCYNvqMHBwUrsw2OQWc4BcQ0it927d1cGa3wJyCxs27ZNvv76a/XFDxErb8G0VDIJCgpS39icq2DwuEiRImJlXnrpJWUEW7FihZQoUcK+HMeNdN21a9cse07wHxiG8Xr16qlvHLjBNAwjJe7jm6rVzwGqYapVq+awrGrVqmoeHNDHaeX/Gwi7I3rTs2dPVSGDUDyM5HrQb2Y4B2Y8OV78dC62uHfvnqqesco50cLmxIkT6guQjtpkhuNfs2aNOj6k4PVnI87Da6+9piqK0+ocUNwkE4Tg69evr/Lu5m+0eNy0aVOxIvgmAmEDJ/zy5ctVGawZnA9U0JjPCSoGcNGzyjlp06aN7N69W31T1zdEMZCO0Petfg6QinRuAQDvSenSpdV9/F3gg8p8DpDCQU7dKucA1THmwb4AX3bwGZBZzoEZT44XPyH68QVBg88RnDN4c6wibFD+vnTpUtUmwYzVj//pp5+WXbt2OXw2IpKJLwKLFy9Ou3OQIrbkTM6MGTNUNcC0adOUC3zgwIExefPmjTl//nyMFRk0aFBMnjx5YlauXBlz7tw5++3WrVv2dV544YWYUqVKxSxfvjxm69atMU2bNlU3K2OulsoM5wBVIL6+vjGjR4+OOXToUMzvv/8eExAQEPPbb7/Z1/nkk0/U/4W///47ZteuXTGPPfZYTNmyZWNu374dYwX69u2rKkL++eefmGPHjsXMnj07JigoKObNN9+07DlAheCOHTvUDZeQ8ePHq/u6GsiT433ooYdi6tatG7Np06aYtWvXqorDXr16xWT044+MjIzp1KlTTIkSJWKCg4MdPh8jIiIscfye/A0441wtlRbngOImhfj222/VhczPz0+Vhm/cuDHGquCP2dVt6tSp9nXwQfbiiy/G5MuXT13wunTpov6DZyZxkxnOwfz582Nq1KihxH2VKlVifvjhB4fnURo8YsSImMKFC6t12rRpE3PgwIEYqxAWFqZ+5/i/nz179phy5crFvPvuuw4XMqudgxUrVrj8/w+h5+nxXr58WV3IcuXKFRMYGBjTv39/dcHM6McPgevu8xGvs8Lxe/I34Im4Se1zkAX/pEwMiBBCCCHE+9BzQwghhBBLQXFDCCGEEEtBcUMIIYQQS0FxQwghhBBLQXFDCCGEEEtBcUMIIYQQS0FxQwghhBBLQXFDCMn0YMDf3Llzvb0bhJAUguKGEOJV+vXrp8SF8+2hhx7y9q4RQjIovt7eAUIIgZCZOnWqwzJ/f3+v7Q8hJGPDyA0hxOtAyGCatPmWL18+9RyiOJMmTZKHH35YcuTIIeXKlZO//vrL4fWY0P7AAw+o5zGFeeDAgXLz5k2HdaZMmSLVq1dX2ypatKiabG/m0qVL0qVLFwkICJCKFSvKvHnz0uDICSGpAcUNISTdM2LECOnWrZvs3LlTevfuLT179pSQkBD1XHh4uLRv316JoS1btsisWbNk6dKlDuIF4mjw4MFK9EAIQbhUqFDBYRujRo2S7t27y65du6RDhw5qO1euXEnzYyWEpAApNoKTEEKSACYJZ82aNSZnzpwOt9GjR6vn8TH1wgsvOLymcePGMYMGDVL3MYkck9dv3rxpf37BggUxPj4+MefPn1ePixUrpqZ1uwPbeO+99+yP8V5YtnDhwhQ/XkJI6kPPDSHE67Ru3VpFV8zkz5/ffr9p06YOz+FxcHCwuo8ITu3atSVnzpz255s3by7R0dFy4MABldY6e/astGnTJt59qFWrlv0+3iswMFBCQ0OTfWyEkLSH4oYQ4nUgJpzTRCkFfDiekC1bNofHEEUQSISQjAc9N4SQdM/GjRvjPK5ataq6j5/w4sB7o1m3bp34+PhI5cqVJXfu3FKmTBlZtmxZmu83IcQ7MHJDCPE6ERERcv78eYdlvr6+EhQUpO7DJNygQQNp0aKF/P7777J582b5+eef1XMw/r7//vvSt29f+eCDD+TixYvy8ssvy9NPPy2FCxdW62D5Cy+8IIUKFVJVVzdu3FACCOsRQqwHxQ0hxOssWrRIlWebQdRl//799kqmGTNmyIsvvqjW++OPP6RatWrqOZRuL168WIYMGSINGzZUj1FZNX78ePt7QfjcuXNHvvzyS3n99deVaHr88cfT+CgJIWlFFriK02xrhBCSSOB9mTNnjnTu3Nnbu0IIySDQc0MIIYQQS0FxQwghhBBLQc8NISRdw8w5ISSxMHJDCCGEEEtBcUMIIYQQS0FxQwghhBBLQXFDCCGEEEtBcUMIIYQQS0FxQwghhBBLQXFDCCGEEEtBcUMIIYQQS0FxQwghhBCxEv8POzTCb2p11CEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Train Accuracy', 'Validation Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dnQpozSiPMdn",
    "28-nD_mIICXe",
    "f0pv8OiJII8h",
    "PnBwJbq_PXUZ",
    "8g89unIGXWLA",
    "XTyr7fRvV8DU",
    "_e0tTdpsPa2t",
    "EOD8cRbxSsUr",
    "FOmafs9cQcuu"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
